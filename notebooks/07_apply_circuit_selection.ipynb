{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use trained network to select the most fit circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synbio_morpher.utils.data.data_format_tools.common import load_json_as_dict\n",
    "from synbio_morpher.utils.results.analytics.naming import get_true_interaction_cols\n",
    "from synbio_morpher.utils.data.data_format_tools.common import write_json\n",
    "from synbio_morpher.utils.misc.string_handling import prettify_keys_for_label\n",
    "from typing import List\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score  \n",
    "                \n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "__package__ = os.path.basename(module_path)\n",
    "\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.mlp import MLP, MLP_fn\n",
    "from src.losses.losses import loss_fn, compute_accuracy_categorical, compute_accuracy_regression\n",
    "from src.utils.math import custom_round, convert_to_scientific_exponent, arrayise\n",
    "from src.utils.data_preprocessing import drop_duplicates_keep_first_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and previously trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../data/processed/ensemble_mutation_effect_analysis/2023_07_17_105328/tabulated_mutation_info.csv'\n",
    "fn_test_data = '../data/raw/ensemble_mutation_effect_analysis/2023_10_03_204819/tabulated_mutation_info.csv'\n",
    "data = pd.read_csv(fn)\n",
    "try:\n",
    "    data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters used to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "N_BATCHES = 1200\n",
    "TOTAL_DS = BATCH_SIZE * N_BATCHES\n",
    "MAX_TOTAL_DS = TOTAL_DS\n",
    "train_split_perc = 0.8\n",
    "TRAIN_SPLIT = int(train_split_perc * TOTAL_DS)\n",
    "TEST_SPLIT = TOTAL_DS - TRAIN_SPLIT\n",
    "EPOCHS = 1000\n",
    "SEED = 1\n",
    "INPUT_SPECIES = 'RNA_1'\n",
    "target_circ_func = 'sensitivity_wrt_species-6'\n",
    "\n",
    "# MLP Architecture\n",
    "LAYER_SIZES = [64, 64, 64]\n",
    "USE_CATEGORICAL = False\n",
    "USE_DROPOUT = False\n",
    "USE_L2_REG = False\n",
    "USE_WARMUP = False\n",
    "\n",
    "loss_fn = partial(\n",
    "    loss_fn, loss_type='categorical' if USE_CATEGORICAL else 'mse', use_l2_reg=USE_L2_REG)\n",
    "compute_accuracy = compute_accuracy_categorical if USE_CATEGORICAL else compute_accuracy_regression\n",
    "\n",
    "save_path = 'saves_small_ds1'\n",
    "\n",
    "rng = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_convert_to_scientific_exponent = np.vectorize(\n",
    "    convert_to_scientific_exponent)\n",
    "filt = data['sample_name'] == INPUT_SPECIES\n",
    "numerical_resolution = 2\n",
    "\n",
    "# Balance the dataset\n",
    "df = drop_duplicates_keep_first_n(data[filt], get_true_interaction_cols(\n",
    "    data, 'energies', remove_symmetrical=True), n=100)\n",
    "df[target_circ_func] = df[target_circ_func].round(\n",
    "    np.abs(int(f'{df[target_circ_func].min():.0e}'.split('e')[1]))-1)\n",
    "df = drop_duplicates_keep_first_n(\n",
    "    df, column=target_circ_func, n=200)\n",
    "\n",
    "TOTAL_DS = np.min([TOTAL_DS, MAX_TOTAL_DS, len(df)])\n",
    "TOTAL_DS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[get_true_interaction_cols(data, 'energies', remove_symmetrical=True)].iloc[:TOTAL_DS].values\n",
    "x = np.concatenate(x, axis=input_concat_axis+1).squeeze()\n",
    "\n",
    "y = df[target_circ_func].iloc[:TOTAL_DS].to_numpy()\n",
    "\n",
    "zero_log_replacement = -10.0\n",
    "y = np.where(y != 0, np.log10(y), zero_log_replacement)\n",
    "\n",
    "x, y = shuffle(x, y, random_state=SEED)\n",
    "\n",
    "N_HEAD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler, yscaler = MinMaxScaler(), MinMaxScaler()\n",
    "x = xscaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hk.transform(partial(MLP_fn, init_kwargs={\n",
    "                     'layer_sizes': LAYER_SIZES, 'n_head': N_HEAD, 'use_categorical': USE_CATEGORICAL}))\n",
    "\n",
    "params = model.init(rng, x[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_loaded = load_json_as_dict(save_path)\n",
    "\n",
    "step = list(saves_loaded.keys())[-1]\n",
    "p = saves_loaded[str(step)]['params']\n",
    "p = arrayise(p)\n",
    "\n",
    "i = 0\n",
    "pred_y = model.apply(p, rng, x[i], call_kwargs={'inference': True})\n",
    "\n",
    "pred_y.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
