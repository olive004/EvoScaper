{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import jax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "if __package__ is None:\n",
    "\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "    __package__ = os.path.basename(module_path)\n",
    "    \n",
    "\n",
    "from src.utils.gcgp_funcs import load_seq_from_FASTA\n",
    "root_dir = '..'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_fn = 'data/raw/ensemble_mutation_effect_analysis/2023_06_05_164913/tabulated_mutation_info.csv'\n",
    "fn = os.path.join(root_dir, rel_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuit_name</th>\n",
       "      <th>mutation_name</th>\n",
       "      <th>mutation_num</th>\n",
       "      <th>mutation_type</th>\n",
       "      <th>mutation_positions</th>\n",
       "      <th>path_to_template_circuit</th>\n",
       "      <th>name</th>\n",
       "      <th>interacting</th>\n",
       "      <th>self_interacting</th>\n",
       "      <th>num_interacting</th>\n",
       "      <th>...</th>\n",
       "      <th>RMSE_diff_to_base_circuit</th>\n",
       "      <th>steady_states_diff_to_base_circuit</th>\n",
       "      <th>fold_change_ratio_from_mutation_to_base</th>\n",
       "      <th>initial_steady_states_ratio_from_mutation_to_base</th>\n",
       "      <th>max_amount_ratio_from_mutation_to_base</th>\n",
       "      <th>min_amount_ratio_from_mutation_to_base</th>\n",
       "      <th>overshoot_ratio_from_mutation_to_base</th>\n",
       "      <th>RMSE_ratio_from_mutation_to_base</th>\n",
       "      <th>steady_states_ratio_from_mutation_to_base</th>\n",
       "      <th>sample_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>ref_circuit</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>[[1 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNA_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>ref_circuit</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>[[1 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>ref_circuit</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>[[1 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNA_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>data/generate_seqs_flexible/2023_04_17_205800/...</td>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>[[1 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNA_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>data/generate_seqs_flexible/2023_04_17_205800/...</td>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>[[1 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNA_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                circuit_name mutation_name  mutation_num mutation_type  \\\n",
       "0  toy_circuit_combo0_100192   ref_circuit             0            []   \n",
       "1  toy_circuit_combo0_100192   ref_circuit             0            []   \n",
       "2  toy_circuit_combo0_100192   ref_circuit             0            []   \n",
       "3  toy_circuit_combo0_100192    RNA_0_m1-0             1           [0]   \n",
       "4  toy_circuit_combo0_100192    RNA_0_m1-0             1           [0]   \n",
       "\n",
       "  mutation_positions                           path_to_template_circuit  \\\n",
       "0                 []                                                NaN   \n",
       "1                 []                                                NaN   \n",
       "2                 []                                                NaN   \n",
       "3                [2]  data/generate_seqs_flexible/2023_04_17_205800/...   \n",
       "4                [2]  data/generate_seqs_flexible/2023_04_17_205800/...   \n",
       "\n",
       "                        name interacting self_interacting  num_interacting  \\\n",
       "0  toy_circuit_combo0_100192     [[1 2]]               []                1   \n",
       "1  toy_circuit_combo0_100192     [[1 2]]               []                1   \n",
       "2  toy_circuit_combo0_100192     [[1 2]]               []                1   \n",
       "3  toy_circuit_combo0_100192     [[1 2]]               []                1   \n",
       "4  toy_circuit_combo0_100192     [[1 2]]               []                1   \n",
       "\n",
       "   ...  RMSE_diff_to_base_circuit steady_states_diff_to_base_circuit  \\\n",
       "0  ...                        0.0                                0.0   \n",
       "1  ...                        0.0                                0.0   \n",
       "2  ...                        0.0                                0.0   \n",
       "3  ...                        0.0                                0.0   \n",
       "4  ...                        0.0                                0.0   \n",
       "\n",
       "  fold_change_ratio_from_mutation_to_base  \\\n",
       "0                                     1.0   \n",
       "1                                     1.0   \n",
       "2                                     1.0   \n",
       "3                                     1.0   \n",
       "4                                     1.0   \n",
       "\n",
       "  initial_steady_states_ratio_from_mutation_to_base  \\\n",
       "0                                               1.0   \n",
       "1                                               1.0   \n",
       "2                                               1.0   \n",
       "3                                               1.0   \n",
       "4                                               1.0   \n",
       "\n",
       "  max_amount_ratio_from_mutation_to_base  \\\n",
       "0                                    1.0   \n",
       "1                                    1.0   \n",
       "2                                    1.0   \n",
       "3                                    1.0   \n",
       "4                                    1.0   \n",
       "\n",
       "  min_amount_ratio_from_mutation_to_base  \\\n",
       "0                                    1.0   \n",
       "1                                    1.0   \n",
       "2                                    1.0   \n",
       "3                                    1.0   \n",
       "4                                    1.0   \n",
       "\n",
       "  overshoot_ratio_from_mutation_to_base RMSE_ratio_from_mutation_to_base  \\\n",
       "0                                   inf                              inf   \n",
       "1                                   inf                              inf   \n",
       "2                                   inf                              inf   \n",
       "3                                   inf                              inf   \n",
       "4                                   inf                              inf   \n",
       "\n",
       "  steady_states_ratio_from_mutation_to_base sample_name  \n",
       "0                                       1.0       RNA_0  \n",
       "1                                       1.0       RNA_1  \n",
       "2                                       1.0       RNA_2  \n",
       "3                                       1.0       RNA_0  \n",
       "4                                       1.0       RNA_1  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(fn)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_dir = '/home/wadh6511/Kode/gene-circuit-glitch-prediction'\n",
    "# paths = data['path_to_template_circuit'].unique()\n",
    "# for p in paths:\n",
    "#     if type(p) != str:\n",
    "#         continue\n",
    "#     fp = os.path.join(source_dir, p)\n",
    "    \n",
    "#     p_spl = str(p.split('data/')[-1])\n",
    "#     dst = os.path.join(root_dir, 'data', 'raw', p_spl)\n",
    "#     # print(dst)\n",
    "#     shutil.copyfile(fp, dst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode 1 - string of RNA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the actual sequence pre-mutation to as a field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mutation_species'] = data['mutation_name'].str[:5]\n",
    "data['src_sequence'] = np.nan\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load RNA sequences.\n",
    "\n",
    "THIS TAKES WAY TOO LONG USE A DICT FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_species = data['mutation_species'].unique()\n",
    "circuit_name = data['circuit_name'].unique()\n",
    "path_to_template_circuit = list(data[data['mutation_num'] > 0]['path_to_template_circuit'].unique())\n",
    "circuit_paths = jax.tree_util.tree_map(lambda x: os.path.join(root_dir, 'data', 'raw', str(x.split('data/')[-1])), path_to_template_circuit)\n",
    "fastas = jax.tree_util.tree_map(lambda cp: load_seq_from_FASTA(cp, as_type='dict'), circuit_paths)\n",
    "fasta_d = dict(zip(circuit_name, fastas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['src_sequence'] = jax.tree_util.tree_map(lambda cn, ms, sn: fasta_d[cn][ms] if ms != 'ref_c' else fasta_d[cn][sn], data['circuit_name'].to_list(), data['mutation_species'].to_list(), data['sample_name'].to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify mutation_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_to_list_of_int(df_col):\n",
    "    return df_col.apply(lambda x: [int(i) for i in x.split(',') if i.strip().isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mutation_type'] = convert_column_to_list_of_int(data['mutation_type'])\n",
    "data['mutation_positions'] = convert_column_to_list_of_int(data['mutation_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Package name synbio_morpher not found in current working directory /home/wadh6511/Kode/EvoScaper/notebooks. Creating dirs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 3, 2: 4, 3: 1, 4: 3, 5: 4, 6: 1, 7: 2, 8: 4, 9: 1, 10: 2, 11: 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from synbio_morpher.utils.evolution.mutation import get_mutation_type_mapping\n",
    "\n",
    "\n",
    "data['mutation_types_simp'] = data['mutation_type']\n",
    "\n",
    "mutation_type_mapping = get_mutation_type_mapping('RNA')\n",
    "mutation_type_mapping_simp = {k: v for k, v in zip(mutation_type_mapping.keys(), np.arange(1, len(mutation_type_mapping)+1))}\n",
    "mutation_map_translation = {}\n",
    "for (ka, kb), v in jax.tree_util.tree_flatten_with_path(mutation_type_mapping)[0]:\n",
    "    mutation_map_translation[v] = mutation_type_mapping_simp[kb.key]\n",
    "\n",
    "data['mutation_types_simp'] = data['mutation_types_simp'].apply(lambda x: jax.tree_util.tree_map(lambda y: mutation_map_translation[y] if x else [], x))\n",
    "mutation_map_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_values(sequence, indices, values):\n",
    "    # GCG\n",
    "    result = np.zeros(len(sequence))\n",
    "    list(map(lambda idx, val: result.__setitem__(idx, val), indices, values))\n",
    "    return result\n",
    "\n",
    "sequence = 'ABDSAFD'\n",
    "indices = (0, 5, 6)\n",
    "values = (1, 1, 3)\n",
    "\n",
    "output = apply_values(sequence, indices, values)\n",
    "output\n",
    "\n",
    "# Expected output: [1., 0., 0., 0., 0., 1., 3.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mutation_types_seq'] = jax.tree_util.tree_map(lambda seq, typs, pos: apply_values(seq, pos, typs) if typs else np.zeros(len(seq)), data['src_sequence'].to_list(), data['mutation_types_simp'].to_list(), data['mutation_positions'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples(data):\n",
    "    # Samples should be a tuple of joined sequences and joined mutation types/locations\n",
    "    data.groupby(['circuit_name', 'mutation_name', 'mutation_species'])\n",
    "\n",
    "input_data = (data['src_sequence'], data['mutation_types_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuit_name</th>\n",
       "      <th>mutation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toy_circuit_combo0_100192</td>\n",
       "      <td>RNA_0_m1-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361995</th>\n",
       "      <td>toy_circuit_combo0_999765</td>\n",
       "      <td>RNA_2_m5-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361996</th>\n",
       "      <td>toy_circuit_combo0_999765</td>\n",
       "      <td>RNA_2_m5-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361997</th>\n",
       "      <td>toy_circuit_combo0_999765</td>\n",
       "      <td>RNA_2_m5-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361998</th>\n",
       "      <td>toy_circuit_combo0_999765</td>\n",
       "      <td>RNA_2_m5-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361999</th>\n",
       "      <td>toy_circuit_combo0_999765</td>\n",
       "      <td>ref_circuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     circuit_name mutation_name\n",
       "0       toy_circuit_combo0_100192    RNA_0_m1-0\n",
       "1       toy_circuit_combo0_100192    RNA_0_m1-1\n",
       "2       toy_circuit_combo0_100192    RNA_0_m1-2\n",
       "3       toy_circuit_combo0_100192    RNA_0_m1-3\n",
       "4       toy_circuit_combo0_100192    RNA_0_m1-4\n",
       "...                           ...           ...\n",
       "361995  toy_circuit_combo0_999765    RNA_2_m5-6\n",
       "361996  toy_circuit_combo0_999765    RNA_2_m5-7\n",
       "361997  toy_circuit_combo0_999765    RNA_2_m5-8\n",
       "361998  toy_circuit_combo0_999765    RNA_2_m5-9\n",
       "361999  toy_circuit_combo0_999765   ref_circuit\n",
       "\n",
       "[362000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms = data.groupby(['circuit_name', 'mutation_name'], as_index=False).agg({'RMSE': 'sum'})[['circuit_name', 'mutation_name']]\n",
    "cms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine into input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample_names = data['sample_name'].unique()\n",
    "# circuit_names = data['circuit_name'].unique()\n",
    "\n",
    "# input_types = [[None] * len(sample_names)] * len(circuit_names)\n",
    "# for ci, cn in enumerate(circuit_names):\n",
    "#     for si, sn in enumerate(sample_names):\n",
    "        \n",
    "#         input_types[ci, si] = data['mutation_types_seq']\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotide Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.nucleotide_transformer import NucleotideTransformerConfig, build_nucleotide_transformer_fn\n",
    "\n",
    "ncfg = NucleotideTransformerConfig(\n",
    "    alphabet_size= 9,\n",
    "    pad_token_id=3,\n",
    "    mask_token_id=3,\n",
    "    max_positions=199,\n",
    "    embed_scale=2,\n",
    "    emb_layer_norm_before=False,\n",
    "    attention_heads=2,\n",
    "    embed_dim=10,\n",
    "    ffn_embed_dim=5, \n",
    "    num_layers=3,\n",
    "    embeddings_layers_to_save=(1,2)\n",
    ")\n",
    "\n",
    "t = build_nucleotide_transformer_fn(ncfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| Module                                                                                         | Config                                                                                                                                                                                                                                                                                                                                                                                        | Module params           | Input                                       | Output                                                                           |   Param count |   Param bytes |\n",
      "+================================================================================================+===============================================================================================================================================================================================================================================================================================================================================================================================+=========================+=============================================+==================================================================================+===============+===============+\n",
      "| nucleotide_transformer (NucleotideTransformer)                                                 | NucleotideTransformer(                                                                                                                                                                                                                                                                                                                                                                        |                         | attention_mask=None, tokens=s32[4,3]        | {'embeddings_1': f32[4,3,10], 'embeddings_2': f32[4,3,10], 'logits': f32[4,3,9]} |         4,154 |      16.62 KB |\n",
      "|                                                                                                |     config=NucleotideTransformerConfig(alphabet_size=9, pad_token_id=3, mask_token_id=3, max_positions=199, embed_scale=2, emb_layer_norm_before=False, attention_heads=2, key_size=5, embed_dim=10, ffn_embed_dim=5, num_layers=3, token_dropout=False, masking_ratio=0.1, masking_prob=0.8, use_gradient_checkpointing=False, embeddings_layers_to_save=(1, 2), attention_maps_to_save=()), |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/embed (Embed)                                                         | Embed(vocab_size=9, embed_dim=10)                                                                                                                                                                                                                                                                                                                                                             | embeddings: f32[9,10]   | s32[4,3]                                    | f32[4,3,10]                                                                      |            90 |      360.00 B |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/embed (Embed.embeddings)                                              | Embed(vocab_size=9, embed_dim=10)                                                                                                                                                                                                                                                                                                                                                             | embeddings: f32[9,10]   |                                             | f32[9,10]                                                                        |            90 |      360.00 B |\n",
      "|  └ nucleotide_transformer/~/embed (Embed)                                                      |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/esm_learned_positional_embeddings (ESMLearnedPositionalEmbeddings)    | ESMLearnedPositionalEmbeddings(vocab_size=199, embed_dim=10, padding_idx=3)                                                                                                                                                                                                                                                                                                                   |                         | s32[4,3]                                    | f32[4,3,10]                                                                      |         2,030 |       8.12 KB |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/esm_learned_positional_embeddings/~/embed (Embed)                     | Embed(vocab_size=203, embed_dim=10)                                                                                                                                                                                                                                                                                                                                                           | embeddings: f32[203,10] | s32[4,3]                                    | f32[4,3,10]                                                                      |         2,030 |       8.12 KB |\n",
      "|  └ nucleotide_transformer/~/esm_learned_positional_embeddings (ESMLearnedPositionalEmbeddings) |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/esm_learned_positional_embeddings/~/embed (Embed.embeddings)          | Embed(vocab_size=203, embed_dim=10)                                                                                                                                                                                                                                                                                                                                                           | embeddings: f32[203,10] |                                             | f32[203,10]                                                                      |         2,030 |       8.12 KB |\n",
      "|  └ nucleotide_transformer/~/esm_learned_positional_embeddings/~/embed (Embed)                  |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/~/esm_learned_positional_embeddings (ESMLearnedPositionalEmbeddings) |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                                  | SelfAttentionBlock(                                                                                                                                                                                                                                                                                                                                                                           |                         | attention_mask=bool[4,1,3,3], x=f32[4,3,10] | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           595 |       2.38 KB |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     embed_dim=10,                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     ffn_embed_dim=5,                                                                                                                                                                                                                                                                                                                                                                          |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='attention_layer_0',                                                                                                                                                                                                                                                                                                                                                                 |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention_layer_norm (LayerNorm)               | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention_layer_norm',                                                                                                                                                                                                                                                                                                                                                         |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention (MultiHeadAttention)                 | MultiHeadAttention(                                                                                                                                                                                                                                                                                                                                                                           |                         | f32[4,3,10], f32[4,3,10], f32[4,3,10]       | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           440 |       1.76 KB |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         | attention_mask=bool[4,1,3,3]                |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     model_size=10,                                                                                                                                                                                                                                                                                                                                                                            |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention',                                                                                                                                                                                                                                                                                                                                                                    |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention/query (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2a8a230b50>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2a8a2306a0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='query',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention/key (Linear)                         | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b1825ebb0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b447967c0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='key',                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention/value (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2aa058a100>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b44519d30>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='value',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/self_attention/mha_output (Linear)                  | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2aa058a070>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2aa058a880>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='mha_output',                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/final_layer_norm (LayerNorm)                        | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='final_layer_norm',                                                                                                                                                                                                                                                                                                                                                                  |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/fc1 (Linear)                                        | Linear(output_size=5, name='fc1')                                                                                                                                                                                                                                                                                                                                                             | w: f32[10,5]            | f32[4,3,10]                                 | f32[4,3,5]                                                                       |            55 |      220.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[5]               |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_0/~/fc2 (Linear)                                        | Linear(output_size=10, name='fc2')                                                                                                                                                                                                                                                                                                                                                            | w: f32[5,10]            | f32[4,3,5]                                  | f32[4,3,10]                                                                      |            60 |      240.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_0 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                                  | SelfAttentionBlock(                                                                                                                                                                                                                                                                                                                                                                           |                         | attention_mask=bool[4,1,3,3], x=f32[4,3,10] | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           595 |       2.38 KB |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     embed_dim=10,                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     ffn_embed_dim=5,                                                                                                                                                                                                                                                                                                                                                                          |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='attention_layer_1',                                                                                                                                                                                                                                                                                                                                                                 |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention_layer_norm (LayerNorm)               | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention_layer_norm',                                                                                                                                                                                                                                                                                                                                                         |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention (MultiHeadAttention)                 | MultiHeadAttention(                                                                                                                                                                                                                                                                                                                                                                           |                         | f32[4,3,10], f32[4,3,10], f32[4,3,10]       | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           440 |       1.76 KB |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         | attention_mask=bool[4,1,3,3]                |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     model_size=10,                                                                                                                                                                                                                                                                                                                                                                            |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention',                                                                                                                                                                                                                                                                                                                                                                    |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention/query (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f6a30>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f6820>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='query',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention/key (Linear)                         | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2a8a27cb80>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b44519eb0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='key',                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention/value (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f1c40>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f6bb0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='value',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/self_attention/mha_output (Linear)                  | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f0670>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b640f0550>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='mha_output',                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/final_layer_norm (LayerNorm)                        | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='final_layer_norm',                                                                                                                                                                                                                                                                                                                                                                  |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/fc1 (Linear)                                        | Linear(output_size=5, name='fc1')                                                                                                                                                                                                                                                                                                                                                             | w: f32[10,5]            | f32[4,3,10]                                 | f32[4,3,5]                                                                       |            55 |      220.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[5]               |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_1/~/fc2 (Linear)                                        | Linear(output_size=10, name='fc2')                                                                                                                                                                                                                                                                                                                                                            | w: f32[5,10]            | f32[4,3,5]                                  | f32[4,3,10]                                                                      |            60 |      240.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_1 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                                  | SelfAttentionBlock(                                                                                                                                                                                                                                                                                                                                                                           |                         | attention_mask=bool[4,1,3,3], x=f32[4,3,10] | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           595 |       2.38 KB |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     embed_dim=10,                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     ffn_embed_dim=5,                                                                                                                                                                                                                                                                                                                                                                          |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='attention_layer_2',                                                                                                                                                                                                                                                                                                                                                                 |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention_layer_norm (LayerNorm)               | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention_layer_norm',                                                                                                                                                                                                                                                                                                                                                         |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention (MultiHeadAttention)                 | MultiHeadAttention(                                                                                                                                                                                                                                                                                                                                                                           |                         | f32[4,3,10], f32[4,3,10], f32[4,3,10]       | {'attention_weights': f32[4,2,3,3], 'embeddings': f32[4,3,10]}                   |           440 |       1.76 KB |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     num_heads=2,                                                                                                                                                                                                                                                                                                                                                                              |                         | attention_mask=bool[4,1,3,3]                |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     key_size=5,                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     model_size=10,                                                                                                                                                                                                                                                                                                                                                                            |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='self_attention',                                                                                                                                                                                                                                                                                                                                                                    |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention/query (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b607d7f40>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b607d7be0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='query',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention/key (Linear)                         | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b606d6160>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b382b92b0>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='key',                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention/value (Linear)                       | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b382b9f70>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b441dbb50>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='value',                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/self_attention/mha_output (Linear)                  | Linear(                                                                                                                                                                                                                                                                                                                                                                                       | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2/~/self_attention (MultiHeadAttention)              |     output_size=10,                                                                                                                                                                                                                                                                                                                                                                           | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     w_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b6012b790>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     b_init=<haiku._src.initializers.VarianceScaling object at 0x7f2b382b9520>,                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='mha_output',                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/final_layer_norm (LayerNorm)                        | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='final_layer_norm',                                                                                                                                                                                                                                                                                                                                                                  |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/fc1 (Linear)                                        | Linear(output_size=5, name='fc1')                                                                                                                                                                                                                                                                                                                                                             | w: f32[10,5]            | f32[4,3,10]                                 | f32[4,3,5]                                                                       |            55 |      220.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[5]               |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/attention_layer_2/~/fc2 (Linear)                                        | Linear(output_size=10, name='fc2')                                                                                                                                                                                                                                                                                                                                                            | w: f32[5,10]            | f32[4,3,5]                                  | f32[4,3,10]                                                                      |            60 |      240.00 B |\n",
      "|  └ nucleotide_transformer/attention_layer_2 (SelfAttentionBlock)                               |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/roberta_lm_head (RobertaLMHead)                                       | RobertaLMHead(embed_dim=10, alphabet_size=9, name='roberta_lm_head')                                                                                                                                                                                                                                                                                                                          |                         | f32[4,3,10]                                 | {'embeddings': f32[4,3,10], 'logits': f32[4,3,9]}                                |           249 |      996.00 B |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/roberta_lm_head/~/emb_layer_norm_after (LayerNorm)                    | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/~/roberta_lm_head (RobertaLMHead)                                    |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='emb_layer_norm_after',                                                                                                                                                                                                                                                                                                                                                              |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/roberta_lm_head/~/lm_head_fc_1 (Linear)                               | Linear(output_size=10, name='lm_head_fc_1')                                                                                                                                                                                                                                                                                                                                                   | w: f32[10,10]           | f32[4,3,10]                                 | f32[4,3,10]                                                                      |           110 |      440.00 B |\n",
      "|  └ nucleotide_transformer/~/roberta_lm_head (RobertaLMHead)                                    |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[10]              |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/roberta_lm_head/~/lm_head_layer_norm (LayerNorm)                      | LayerNorm(                                                                                                                                                                                                                                                                                                                                                                                    | offset: f32[10]         | f32[4,3,10]                                 | f32[4,3,10]                                                                      |            20 |       80.00 B |\n",
      "|  └ nucleotide_transformer/~/roberta_lm_head (RobertaLMHead)                                    |     axis=-1,                                                                                                                                                                                                                                                                                                                                                                                  | scale: f32[10]          |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |     create_scale=True,                                                                                                                                                                                                                                                                                                                                                                        |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     create_offset=True,                                                                                                                                                                                                                                                                                                                                                                       |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                |     name='lm_head_layer_norm',                                                                                                                                                                                                                                                                                                                                                                |                         |                                             |                                                                                  |               |               |\n",
      "|                                                                                                | )                                                                                                                                                                                                                                                                                                                                                                                             |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n",
      "| nucleotide_transformer/~/roberta_lm_head/~/lm_final_fc (Linear)                                | Linear(output_size=9, name='lm_final_fc')                                                                                                                                                                                                                                                                                                                                                     | w: f32[10,9]            | f32[4,3,10]                                 | f32[4,3,9]                                                                       |            99 |      396.00 B |\n",
      "|  └ nucleotide_transformer/~/roberta_lm_head (RobertaLMHead)                                    |                                                                                                                                                                                                                                                                                                                                                                                               | b: f32[9]               |                                             |                                                                                  |               |               |\n",
      "|  └ nucleotide_transformer (NucleotideTransformer)                                              |                                                                                                                                                                                                                                                                                                                                                                                               |                         |                                             |                                                                                  |               |               |\n",
      "+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+---------------------------------------------+----------------------------------------------------------------------------------+---------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.random.randint(1, 10, [4,3])\n",
    "t_t = hk.transform(t)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "params = t_t.init(rng, x)\n",
    "print(hk.experimental.tabulate(t_t.apply)(x))\n",
    "dot = hk.experimental.to_dot(t_t.apply)(params, None, x)\n",
    "\n",
    "import graphviz\n",
    "# graphviz.Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings_1', 'embeddings_2', 'logits'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = t_t.apply(params, None, x)\n",
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGiCAYAAADa7K1vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv+UlEQVR4nO3deXyU5b338e9kklmyTTYSEhNWrYgIoiwFrAXFBRWFnnq0dUHq8Wl5wELT4yPYUz1WbbT2eGyV4nJUbJUWW40op2ItKIiVRRAVESzKJhCSAJnJOklm5vljSiBNAoTknmsm83m/XvOSue4h10+GMN9c1+++b1soFAoJAADAgATTBQAAgPhFEAEAAMYQRAAAgDEEEQAAYAxBBAAAGEMQAQAAxhBEAACAMQQRAABgDEEEAAAYQxABAADGRCyIPPjgg7LZbJozZ06kpgQAAFEuIkFk/fr1evLJJzV06NBITAcAAGKE5UGkpqZGN9xwg55++mllZmZaPR0AAIghiVZPMHPmTF155ZWaOHGi7r///uO+1u/3y+/3tzwPBoM6dOiQsrOzZbPZrC4VAAB0g1AopOrqahUUFCgh4fhrHpYGkT/84Q/auHGj1q9ff1KvLykp0b333mtlSQAAIEL27NmjwsLC477GsiCyZ88ezZ49W2+99ZZcLtdJ/Z558+apuLi45bnX61WfPn20Z88epaenW1UqAADoRj6fT0VFRUpLSzvha22hUChkRRGvvvqqpk6dKrvd3jIWCARks9mUkJAgv9/f6lh7fD6fPB6PvF4vQQQAgBjRmc9vy1ZELr74Yn3yySetxqZPn65BgwbpzjvvPGEIAQAAPZ9lQSQtLU1DhgxpNZaSkqLs7Ow24wAAID5xZVUAAGCM5afvHuudd96J5HQAABgRCoXU3NysQCBguhTLJCUldUubRUSDCAAAPV1jY6P279+vuro606VYymazqbCwUKmpqV36OgQRAAC6STAY1I4dO2S321VQUCCHw9EjL8gZCoVUUVGhr776SmeccUaXVkYIIgAAdJPGxkYFg0EVFRUpOTnZdDmW6tWrl3bu3KmmpqYuBRGaVQEA6GYnuqx5T9BdKz09/08KAABELbZmgG7QHAiqvNqvyhq/moMh5aY5lZvmlCORC/cBwPGwIgJ0kb8poNXbKzXpV+/q6sff07d+8zdd8sgqvfLhXvnqm0yXBwCdMn/+fPXr108ul0ujR4/WunXrLJ2PIAJ00Z7D9br1+Q/kPSZ01DcFNPflT7StrNpgZQDQOYsXL1ZxcbHuuecebdy4UcOGDdNll12m8vJyy+YkiABd0BwI6sW1uxQItn/vyP/+6+esigA4JYFgSO9/cVBLNu3V+18c7PDfme70yCOP6LbbbtP06dM1ePBgPfHEE0pOTtazzz5r2Zz0iABd0NAc0NbjrHrsrKxVfVNA6e6kCFYFINYt27xf976+Rfu9DS1j+R6X7pk8WJcPybdkzsbGRm3YsEHz5s1rGUtISNDEiRP1/vvvWzKnxIoI0CXuRLvOOc3T4fHT89KU7KBhFcDJW7Z5v2a8sLFVCJGkMm+DZrywUcs277dk3srKSgUCAeXl5bUaz8vLU1lZmSVzSgQRoEvs9gRdP7JISfb2z6f/0cQzlOZiNQTAyQkEQ7r39S1qbxPmyNi9r2+JyDZNpBBEgC4qzHTrd7eOVm6as2Us3Z2oX19/rs7I7do9GADEl3U7DrVZCTlWSNJ+b4PW7TjU7XPn5OTIbrfrwIEDrcYPHDig3r17d/t8R9AjAnSRI9Gu0f2z9NqsC3Sw1q9gMKTs1PB1RBLtZH0AJ6+8uuMQciqv6wyHw6Hzzz9fy5cv15QpUySF752zfPlyzZo1q9vnO4IgAnQDm82m3h6XentcpksBEMNy007u35CTfV1nFRcXa9q0aRoxYoRGjRqlRx99VLW1tZo+fbol80kEEQAAosao/lnK97hU5m1ot0/EJqm3x6VR/bMsmf+6665TRUWF7r77bpWVlencc8/VsmXL2jSwdifWjQEAiBL2BJvumTxYUjh0HOvI83smD5Y9oXtuONeeWbNmadeuXfL7/Vq7dq1Gjx5t2VwSQQQAgKhy+ZB8LbjxvDZbvb09Li248TzLriNiClszAABEmcuH5OuSwb21bschlVc3KDctvB1j5UqIKQQRAACikD3BpjEDs02XYTm2ZgAAgDHxFUQCzdKhHVLtwaNjh3ZI1Qc6/j0AAMAy8RNEAs3Svg+lBWOk934l1R+WKv8uPXuZ9NoswggAAAbET4+I3ydtXSo11Ut/+5Xk/UratVqqOSDtXhM+nmbdedIAAKCt+AkiyVnS2NulZr+0doH06cvhcWe6NP3PUtZAs/UBABCH4mdrRpJScqTR32891u8CyVMoJcTXHwUAANEgvj59j/SEHGvbn6V3H2ndwAoAACIifoJI3WFp1cPhnhCXR/rBe9LoGeFja+ZL9QQRAED8WrVqlSZPnqyCggLZbDa9+uqrEZk3foJIcqZ0yc+kwVOkW/4s5Q6WLvx3aczt0nf/JHn6mK4QAICwZr+0Y5UU+set70Kh8PNmv2VT1tbWatiwYZo/f75lc7QnfppVJSmtt3TVI5IrM9wTkpIjfeNHUlKKlMTt2wEAUaDZL/3+u9IXfw2v3F/2c+nNedLaJ6SBE6XvLJISnd0+7aRJkzRp0qRu/7onEl9BRJKSs4//HAAAU46EkC9XhJ+vXSDtfFc6sDn8/MsV4eMWhRET4mdrBgCAaLdnbXglJBQ8OnYkhEjh8S/+Ku1ZF/naLEIQAQAgWvT7hjT6B8d/zegZ4UtP9BAEEQAAooXNJl1WIuUNaf943pBwz4jNFtm6LEQQAQAgWoRC4cbUY7djjnVgs/TmXUfPpukB4q9ZFQCAaLXz3fDZMcezdoE06Eqp/ze6deqamhpt37695fmOHTu0adMmZWVlqU8f6y5xYemKyIIFCzR06FClp6crPT1dY8aM0RtvvGHllAAAxK6i0eFTdG3HfDwfu01jSwgfLxrV7VN/8MEHGj58uIYPHy5JKi4u1vDhw3X33Xd3+1zHsjSIFBYW6sEHH9SGDRv0wQcf6KKLLtI111yjTz/91MppAQCITYnO8Km5Ay4KPx89Q/r+u0cbWAdcZNmpu+PHj1coFGrzWLhwYbfPdSxbKBTZjaasrCw9/PDDuvXWW0/4Wp/PJ4/HI6/Xq/T09AhUBwDAqWtoaNCOHTvUv39/uVxduFBmsz98im6/C8KNqaGQtHN1eCUkSq4fcrz/1858fkesRyQQCOiPf/yjamtrNWbMmEhNCwBA7El0tu4Bsdm6vSckWlgeRD755BONGTNGDQ0NSk1NVWlpqQYPHtzua/1+v/z+o9fR9/l8VpcHAAAMsvz03TPPPFObNm3S2rVrNWPGDE2bNk1btmxp97UlJSXyeDwtj6KiIqvLAwAABkW8R2TixIkaOHCgnnzyyTbH2lsRKSoqokcEABATuq1HJAbEXI/IEcFgsFXYOJbT6ZTTGR1NOAAAwHqWBpF58+Zp0qRJ6tOnj6qrq7Vo0SK98847evPNN62cFgAAxAhLg0h5ebluvvlm7d+/Xx6PR0OHDtWbb76pSy65xMppAQBAjLA0iDzzzDNWfnkAABDjuOkdAAAwhiACAABUUlKikSNHKi0tTbm5uZoyZYq2bdtm+bwEEQAAoJUrV2rmzJlas2aN3nrrLTU1NenSSy9VbW2tpfNG/PTdaHC4tlF1jc1KSLApJ9WhJLvddEkAALTY5dul2qa2ASAlKUV90/taMueyZctaPV+4cKFyc3O1YcMGXXjhhZbMKcVZEKlvbNaW/dW6/3+36MPdVUpx2HXD1/tq+rh+yve4TZcHAIB2+XbpqtKrOjy+dOpSy8LIsbxer6TwzWqtFFdbM1v2V+vaJ/6mD3dXSZJqGwN6atWX+sHvNqi8usFscQAASO2uhHTmeHcIBoOaM2eOxo0bpyFDhlg6V9ysiByqbdS9r3+qYDsXtP/oK692VNQqN61nX44XAICTMXPmTG3evFmrV6+2fK64WRGp9Tfr46+8HR5f+XlFBKsBACA6zZo1S0uXLtXbb7+twsJCy+eLmyBiT7DJndRxU2p2qiOC1QAAEF1CoZBmzZql0tJSrVixQv3794/IvHETRHJSnbpuZPvJzmaTLjozN8IVAQAQPWbOnKkXXnhBixYtUlpamsrKylRWVqb6+npL542bIOJITND3vzlQZ+WntRq32aRffnuY8tLpDwEAmJeSlNKl46dqwYIF8nq9Gj9+vPLz81seixcvtmS+I+KmWVWS8j1uLZw+StvLa/TOtnL1SnNq4ll56p3uUrIzrv4oAABRqm96Xy2dujTi1xEJhdo5myMC4u7TNy/dpbx0l8adnmO6FAAA2hWJ64REi7jZmgEAANGHIAIAAIwhiAAAAGMIIgAAwBiCCAAA3czUGSiR1F3/jwQRAAC6SVJSkiSprq7OcCXWa2xslCTZ7R1ftfxkxN3puwAAWMVutysjI0Pl5eWSpOTkZNlsNsNVdb9gMKiKigolJycrMbFrUYIgAqDHqayvVFVDVZvxDFeGctxcQwjW6t27tyS1hJGeKiEhQX369Oly0CKIAOhxqhqqNPW1qW3GS68uJYjAcjabTfn5+crNzVVTU5PpcizjcDiUkND1Dg+CCAAAFrDb7V3un4gHNKsC6HGag+1384fU889kAGINQQRAj3Ko1q+K6oZ2j/mbghGuBsCJEEQA9Cj7qxpU7W9u91h5tV+HahsjXBGA46FHBECPsnp7pXIzXHro679tc8xbk6TqhiZlpTgMVAagPQQRAD2K22HXj37/ZbvH7Ak2rbwjfm6vDsQCtmYA9CjfOD1HHV3W4NLBecpMZjUEiCYEEQA9Sq90l/5z8tltxvPSnZo7aZBSnCwEA9GE78hYVX9YcqRJ9n+8hQ0+KcEuOVLM1gUYlupM1NTzTtOo/ln6/drdKvM16JLBeRo7MEenZbpNlwfgnxBEYlFtpbT6UWnIt6T8YVJjrfTpK1JKL2nABMmRbLpCwKh0V5LS85N07zVnKxAKKbEbrv4IwBp8d8Yaf4207n+k9x+TFl4plX0sbX5Zen22tPhG6cBm0xUCUcNmsxFCgCjHikiscaZKw66TNv1O8n4lPTX+6LEzLpcyOCMAABA7+FEhFmX1l6a/ISW6jo7lD5Ou+bWUlmeuLgAAOokgEosafNL2v0rNx1zGuvLvUtUeKdD+FSUBAIhGBJFY46+RtiyRlv4o/LzvBZKnUGqqC/eMlG8xWx8AAJ1gaRApKSnRyJEjlZaWptzcXE2ZMkXbtm2zcsqeL8kt5Q+VHKnS166Qrn1OmrZU8hRJmf2k5CzTFQIAcNJsoVDIsvtiX3755br++us1cuRINTc366677tLmzZu1ZcsWpaSc+HoXPp9PHo9HXq9X6enpVpUZe4IB6eAXkstztCfk0M7wNUU8hUZLAwCgM5/flgaRf1ZRUaHc3FytXLlSF1544QlfTxABACD2dObzO6Kn73q9XklSVlb72wd+v19+v7/luc/ni0hdAADAjIg1qwaDQc2ZM0fjxo3TkCFD2n1NSUmJPB5Py6OoqChS5QEAAAMitjUzY8YMvfHGG1q9erUKC9vvY2hvRaSoqIitGQAAYkjUbc3MmjVLS5cu1apVqzoMIZLkdDrldDojURIAAIgClgaRUCik22+/XaWlpXrnnXfUv39/K6cDAAAxxtIgMnPmTC1atEhLlixRWlqaysrKJEkej0duN7fjBgAg3lnaI2Kz2dodf+6553TLLbec8Pdz+i4AALEnanpEIniJEgAAEIMieh0RAMDJq6yvVFVDVZvxDFeGctw5kS8IsABBBACiVFVDlaa+NrXNeOnVpQQR9BjcfRcAABhDEAEAAMYQRAAAgDEEEQAAYAzNqgAQpTJcGSq9urTdcaCnIIgAQJTKcedwdgx6PLZmAACAMQQRAABgDEEEAAAYQxABAADGEEQAAIAxcXfWDDeRAgAgesRdEOEmUgAARA+2ZgAAgDEEEQAAYAxBBAAAGEMQAQAAxsRdsyo3kQIAIHrEXRDhJlIAAEQPtmYAAIAxBBEAAGAMQQQAABgTdz0igBW4dQAAnBqCCNANuHUAAJwagkiM4idwAEBPQBCJUfwEDgDoCWhWBQAAxhBEAACAMWzNAN2AWwcAwKkhiMQoPviiC7cOAIBTQxCJUXzwAQB6AnpEAACAMQQRAABgDEEEAAAYY2kQWbVqlSZPnqyCggLZbDa9+uqrVk4HAABijKVBpLa2VsOGDdP8+fOtnAYAAMQoS8+amTRpkiZNmmTlFAAAIIZF1em7fr9ffr+/5bnP5zNYDQAAsFpUNauWlJTI4/G0PIqKikyXBAAALBRVQWTevHnyer0tjz179pguCQAAWCiqtmacTqecTqfpMgAAQIRE1YoIAACIL5auiNTU1Gj79u0tz3fs2KFNmzYpKytLffr0sXJqAAAQAywNIh988IEmTJjQ8ry4uFiSNG3aNC1cuNDKqQEAQAywNIiMHz9eoVDIyikAAEAMo0cEAAAYQxABAADGEEQAAIAxBBEAAGAMQQQAABhDEAEAAMYQRAAAgDEEEQAAYAxBBAAAGEMQAQAAxhBEAACAMQQRAABgDEEEAAAYQxABAADGEEQAAIAxBBEAAGAMQQQAABhDEAEAAMYQRAAAgDEEEQAAYAxBBAAAGEMQAQAAxhBEAACAMYmmCwAAIFZU1leqqqGqzXiGK0M57pzIF9QDEEQAADhJVQ1Vmvra1DbjpVeXEkROEVszAADAGIIIAAAwhiACAACMIYgAAABjaFYFAOAkZbgyVHp1abvjODUEEQAATlKOO4ezY7oZWzMAAMAYgggAADCGIAIAAIwhiAAAAGMIIgAAwJiIBJH58+erX79+crlcGj16tNatWxeJaQEAQJSzPIgsXrxYxcXFuueee7Rx40YNGzZMl112mcrLy62eGgAARDnLg8gjjzyi2267TdOnT9fgwYP1xBNPKDk5Wc8++6zVUwMAgChnaRBpbGzUhg0bNHHixKMTJiRo4sSJev/9962cGgAAxABLr6xaWVmpQCCgvLy8VuN5eXnaunVrm9f7/X75/f6W5z6fz8ryAACAYVF11kxJSYk8Hk/Lo6ioyHRJAADAQpYGkZycHNntdh04cKDV+IEDB9S7d+82r583b568Xm/LY8+ePVaWBwAADLM0iDgcDp1//vlavnx5y1gwGNTy5cs1ZsyYNq93Op1KT09v9QCAuNXcKNVWtB6rrTRTC2ARy7dmiouL9fTTT+v555/XZ599phkzZqi2tlbTp0+3emoAiF3NjdJX66XFN0u+feGx8s+k302RDn1ptDSgO1narCpJ1113nSoqKnT33XerrKxM5557rpYtW9amgRUAcIwGr/TCt6TmBmnxTdIVv5Be/LZUd0h66WbppiVSSrbpKoEus4VCoZDpIjri8/nk8Xjk9XrZpgFw8kIhqbFWcqYeHfPXSs4UczV1VmOdtOMd6Q83SKHg0fHkLOmWN6TcQcZKA06kM5/fUXXWDAB0WSgkVWyVPvmjVO8Nj1Xtlv72q7b9FtHMkSwNmCB9c27r8Rv+RAhBj2L51gwARNThndJzk6T6w1KzXxp8Tbiv4uAXUl2lNOE/wqsKseDwTmndE63H/vcO6foXpPQCIyUB3Y0VEQA9iyNF6j8+/Otld0qPnRcOIXaHNOTbrbdroln1fmnhFeGekOQsafxdki1B2rdB+tOtnD2DLjlU69e2Mp/+/Ml+rd1xUPuq6mWqU4MVEZhVXSYlJEopOeHnNeXh/fC0tteZAU5Kaq50xcNSY420/S2pqS48ftOrUuGIcCCJBYkuaezs8JbSLW9ImX2l/HOkP06XLvoPyUXfHE5NmbdB/+9PH2nV34+G2ZxUh56fPkqDC9Jls9kiWg8rIjDHt09adL309gPhn+5qyqVld0kv/1s4oACnqrleOvxPp7iWfSw11pup51S4M6Xzp0kz3g/3hCS5wys9czZLRSNjJ1AhqjQ0BfT4ir+3CiGSVFnTqBueWat9VZH/HmFFBGY0N0qfvynt/zD8CDZL/hrp01fCx3evkQZNlux2s3Ui9lTtkX43Nbwdk+iUep0l7d8kLZsr2WzS0O9Ibo/pKk+OO7P1c0dy+AGcospqv/644at2j1XVNWl7eY1Oy4zs3zGCCMxIdISbCH17pVUPSxt/e/TYpfdLA8YTQnBqbAlSUnI4hNy0RMo5Q/rff5e2lEquDCmBhWDEL38gKH9zsMPjXx1mRQTxJDlL+vr/DYeQmn/cjyhrgHTuDZI7w2hpiGGe06Tv/EGqKZN6nxPewrjiF9Kof5Pyh0nONNMVAsa4k+zKTE7S4bqmdo8Pyo987xFBBObUlKuy8jNVXf1I6/GDW5QRGKictHwzdSH2eU4LP45IzQ0/gDiXl+7S7Iln6D9f29Lm2Jm9U1WU6Y54TQQRmNHcKG1+RVVZhZr6/rw2h0sve145yblszwBAN7In2HT1sAI1NYf06+V/V7W/WTabdNGZufrZNUOUm+6KeE0EEZiR6JCGTJUOftb+8aRkQggAWCArxalbxvXTFefkq9rfJFeiXdmpDqW5kozUQxCBOal5kv9w+8cS+KsJAFZJsifotEy3pMhvxfwz2sdhFoEDAOIanwIwKsOVodKrS9sdBwD0fAQRGJXjzlGOO8d0GQAAQwgiMKqhKaCKar++OlyvBJt0WqZbuWlOORJpVAWAeEAQgTG++ia9/vE+/ez1LS1X+nMlJeihbw3VxMF5SnHy1xMAejqaVWHM5weq9ZPSza0uN9zQFNTsxZu082CtwcoAAJFCEIERtf4mzX97e4fHn1m9Q/7mQAQrAgCYQBCBEfVNQe0+VNfh8R0VtWpo6vjGTACAnoEgAiNSnHadXdDxrdiHFnmU7OCvJwD0dPxLDyPcSYmaMX6gEmxtjyXZbbr56/2UxCXeAaDHI4jAmH45KXrullHKS3e2jBVmuvXCv41WUZb5yw4DAKzH+ZEwxp1k14Vfy9GSmeN0uK5JNkmZKQ7lGbj7Y5c1N0qySYnH3DSqqV5KIlABwPEQRGCUzWZTb49bvT0x/IHd3Ch9tT5835yC88JhpPwzqWKbdPpEyZlqukIAiFoEEaArgkFp34fS76ZINpt08+uSyyMtvEKqOyRd+7z0tctYGQGADhBEgK5ISJDSekueQunQl9LzV0p2h9RYKyVnSb0GEUKAnqTuUPh7+4jag+HntnY673FSaFYFuiqzr3TTEin9NCnQFA4hjhTpljek3EGmqwPQXQ7vkl7+N6lqd/h5dZn0+g/DW7GhkNnaYhhBBOgOTbVS0zEXaAs0Sg1eqbnJXE0Auk9tpbToWumL5dJvrwmHkj/dKm1d+o+t2IOmK4xZBBGgq8o/C/9DVH9YcmceXRn57WRp30bCCNATOD3S5F9Lic7wNuyvhkq7Voe3ZK78LykxBs/2ixIEEaArQiEpFAw3rSZnSdOXhR9ZA8LHgs2SWLIFYl5iknTa+dJ1L7Yen/gz6WuXc3ZcF9CsCnSFzSblDpam/1my2Y/2hNz0anj/uGC4lOgwWiKAblJ3UFr9aOuxDc9JZ18T7gvDKWFFBOiqI2Hk2MbUzL5S4UhCCNBT1JSHe0KObMeM+N7RbZrfTgn/4IFTQhABukN7p+4l8O0F9BhJydL508Lf6//yjHTJ/dLNr4XDyJBvS3bnib8G2mULhaL3nCOfzyePxyOv16v09HTT5QAA4pm/Rqo/JLmzwj0hzU1S9d5wI2typunqokpnPr/pEQEA4GQ4U1s3pSYmSZn9jJXTU7B2DAAAjLEsiDzwwAMaO3askpOTlZGRYdU0AACgs2orw5cdaHleITU1GCnFsiDS2Nioa6+9VjNmzLBqCgAA0FlVu6UXvy2VbwmHkeoyqfQH0q6/GQkjlvWI3HvvvZKkhQsXWjUFAADojLqD0iu3he8avvAK6cZSacXPpC/fCT/mbJaS8iNaUlQ1q/r9fvn9/pbnPp/PYDUAAPQwydnS1Y+HQ0hNufQ/Fx09NmWB5EyLeElR1axaUlIij8fT8igqKjJdEgAAPUvOGeFroBxrzCxp0FVGLlXfqSAyd+5c2Wy24z62bt16ysXMmzdPXq+35bFnz55T/loAAKAd1WXSG3Nbj334u/BVYo9tYI2QTm3N/PjHP9Ytt9xy3NcMGDDglItxOp1yOrk6HQAAlqitlF6fLe14J/z8wjukjc+Ht2kWXiHNeE/yRHY3olNBpFevXurVq5dVtQAAACu5MqRv/Lu0Y6U0+dfSoCulodeFQ8i5N0pJkb95n2XNqrt379ahQ4e0e/duBQIBbdq0SZJ0+umnKzWV2yUDABBx9sTwXcFnfxy+f44jJdwz8n9WSokuKTkr4iVZFkTuvvtuPf/88y3Phw8fLkl6++23NX78eKumBQAAx2NPlFJzW4+lF5ipRdz0LmZVVvu161Cd/rrlgFKddl16dm/1TncpzZ1kujQAQJzjpnc9XLmvQcUvfaTV2ytbxh7+y+e68/Iz9d3RfeRxOwxWBwDAyYuq64jgxEKhkJZ+vL9VCDnioWXbtPdwvYGqACB+BAJB1fqb1BSI/KmuPRErIjGmosavZ9/b0eHx36/bo/umeCJYEQDEh6bmoPZW1eulD/Zo4+7DGpiTqpvG9lWfrGQlO/g4PVX8ycWYYDAkb11Th8fLq/0KBkNKSLBFsCoA6Pk+2evVd55eI39zeCVkzZeHtGj9bs3/7nmaeFauHIl2wxXGJrZmYkyqM1HjTs/p8PiVQ/MJIQDQzcp9DfrRS5taQsgRoZD073/8SOXV/g5+J06EIBJjUl1JKr70a3LY2751RVlujeybaaAqAOjZDtc1adfBunaP1TUG6M/rAoJIDOqXnaxXZ47TmAHhC884ExP0nZFF+v1tX1d+httwdQDQ8wSCx7/SRfMJjqNj9IjEIEeiXYML0vXETeerpqFZNptNWSkOuZLYnwQAK2SmJKlXmlMV7WzBJNltKspKNlBVz8CKSAzzuB06LTNZBRluQggAWKh3uksPfesc2dppwbvz8kHKSeX6TaeKFREAAE7AZrPp6wOz9fqsC/Tr5X/Xp/t8Kspy64cXnaHBBemcvtsF/MkBAHASkh2JGnKaR49cN0x1/oBcSXalc1uNLiOIAADQCanOJKU6CSDdhR4RAABgDEEEAAAYw9YMgBaV9ZWqaqhqM57hylCOu+Mr+gLAqSKIAGhR1VClqa9NbTNeenUpQQSAJdiaAQAAxhBEAACAMQQRAABgDEEEAAAYQ7MqgBYZrgyVXl3a7jgAWIEgAqBFjjuHs2MARBRbMwAAwBiCCAAAMIYgAgAAjCGIAAAAYwgiAADAGM6aAXBUY63U3CglZ4afBwNSg1dKzjJbVxzz1jfqUE2j6hoDSncnqVeaU64ku+mygG5DEAEQ1lgnffmOVL5VGvE9yZUu7f9IWv+MNPEeKTXXdIVxZ+/hes195WO9+/dKSZLDnqBpY/vq+xcOUE6ay3B1nRRoluyJHT9H3OJvAYCwys+lxTdKoWD4cfrF0sIrpaY6yZkmTbgrHE4QERXVDbrtt+u1ZX91y1hjIKin390hR2KCZl98hhyJMbIyUl0WDrlnXBpeXas9KH2+TDpjopSaZ7o6GEaPCIAwz2nSsO+Gf/32/dLTE8IhxFMojf4+ISTC9nsbWoWQYz27eqfKq/0RrugUVR+QSn8glX5fWrNAqjskrfqFtOT/SkuLpZpy0xXCMFZEAISl9JIuvU86vEPa9V54LMEuTV8mZRSZrS0O7TpY1+Gx+qaAav3NEaymCxLsUtYA6cu3wwHk48VS1a7wsezTw8cR11gRARAWDEiHd0r7N7Ue+3ixVHfYVFVxK9/TcQ9Ikt0mtyNGfo5MyQlv6503Lfz8SAgZc7s0braUnG2uNkQFggiAsIqt0vNXhc+c8RRKX5sUHl9xn/ThC+GzZxAxhZnJOi3D3e6xqcNPU06qI8IVdYVNsie1HqJRFf9AEAEQ5s6U8s4Jh5BpS6VrHpfOvVFypEoDLgz/FxHT2+PSb783Sn2zk1uNX3RmroovOVPJsbIiUlsZ3pJZ/z/h5+kF4f+u/m9pzW/CPSOIazHyNxmA5dILpGsXSgG/lNkvPHbJf0oX/ljK6MtevgEDc1P1x++PUXm1X4drG5Wf4VZ2ikOZKTG0GhJslg58Gv71uDnSBXOk5T+TPnhWKvtECjaZrA5RwBYKhUJWfOGdO3fqvvvu04oVK1RWVqaCggLdeOON+slPfiKH4+S+iXw+nzwej7xer9LT6dgHgJhUXSZ9/hfprKv+cfpupfTZa9KZV0ppnL7bE3Xm89uyFZGtW7cqGAzqySef1Omnn67NmzfrtttuU21trX75y19aNS2ALvA3BVRe7den+7yqbmjWsMIM5aY7lZEcQz+BI/qk9ZbO/c7RPpGUHGn4TW37RhCXLFsRac/DDz+sBQsW6Msvvzyp17MiAkROfVNAqz6v0O2LPlRjINgyfs2wAv3HVYPVK81psDoAsaQzn98RbVb1er3KyuKeFUA02l9VrxkvbGgVQiRpyUf79OdP9iuCP7MAiCMRa1bdvn27HnvsseNuy/j9fvn9R68W6PP5IlEaAEn/+/F+BTvIGk+u/EKThvRWbnqM3d8EQLsq6ytV1VDVZjzDlaEcd05Ea+l0EJk7d64eeuih477ms88+06BBg1qe7927V5dffrmuvfZa3XbbbR3+vpKSEt17772dLQlAN9h5sLbDY+XVfgU6SikAYk5VQ5Wmvja1zXjp1aXRH0R+/OMf65ZbbjnuawYMGNDy63379mnChAkaO3asnnrqqeP+vnnz5qm4uLjluc/nU1ERl5YGIuGbX+ullzfubffY0CIPt54HYIlOB5FevXqpV69eJ/XavXv3asKECTr//PP13HPPKSHh+C0pTqdTTicNcYAJI/plKTfN2e7N1O6adFZsXbsCQMywrFl17969Gj9+vPr06aNf/vKXqqioUFlZmcrKyqyaEkAXFGS49dL3x+gbZxxdli3Kcuu5W0bqrN6ctQbAGpY1q7711lvavn27tm/frsLCwlbH6L4HolO/nBTN/+55OlTXqOZASOmuRBpUAVgqotcR6SyuIwIAQPez+qyZqLiyKgAAiE457pyInx3TEe6+CwAAjCGIAAAAYwgiAADAGIIIAAAwhiACAACMIYgAAABjCCIAAMAYgggAADCGIAIAAIwhiAAAAGMIIgAAwBiCCAAAMIYgAgAAjCGIAAAAYwgiAADAGIIIAAAwhiACAACMIYgAAABjCCIAAMAYgggAADCGIAIAAIwhiAAAAGMIIgAAwBiCCAAAMIYgAgAAjCGIAAAAYwgiAADAGIIIAAAwhiACAACMIYgAAABjCCIAAMAYgggAADCGIAIAAIwhiAAAAGMIIgAAwBhLg8jVV1+tPn36yOVyKT8/XzfddJP27dtn5ZQAACCGWBpEJkyYoJdeeknbtm3Tyy+/rC+++ELf/va3rZwSAADEEFsoFApFarLXXntNU6ZMkd/vV1JS0glf7/P55PF45PV6lZ6eHoEKAQBAV3Xm8ztiPSKHDh3Siy++qLFjx55UCAEAAD2f5UHkzjvvVEpKirKzs7V7924tWbKkw9f6/X75fL5WDwAA0HN1OojMnTtXNpvtuI+tW7e2vP6OO+7Qhx9+qL/85S+y2+26+eab1dFuUElJiTweT8ujqKjo1P/PAABA1Ot0j0hFRYUOHjx43NcMGDBADoejzfhXX32loqIi/e1vf9OYMWPaHPf7/fL7/S3PfT6fioqK6BEBACCGdKZHJLGzX7xXr17q1avXKRUWDAYlqVXYOJbT6ZTT6Tylrw0AAGJPp4PIyVq7dq3Wr1+vCy64QJmZmfriiy/005/+VAMHDmx3NQQAAMQfy5pVk5OT9corr+jiiy/WmWeeqVtvvVVDhw7VypUrWfUAAACSLFwROeecc7RixQqrvjwAAOgBuNcMAAAwhiACAACMIYgAAABjCCIAAMAYgggAADCGIAIAAIwhiAAAAGMIIgAAwBiCCAAAMIYgAgAAjLHsEu8AABxxqNavgzWN8tY3KSPZoZxUhzKSHabLQhQgiAAALLX3cJ22VuyTP1QtSSr3S3trE3V6dp5OS881XB1MI4gAACxzqNav2Ys36XsT3Lpzzc2tjs2/cJFSkzLlcScZqg7RgB4RAIBlDtY06oOdh9s9VtPYrIM1/ghXhGhDEAEAWMZb33Tc49UNzRGqBNGKIAIAsMzxGlJtktLZlol7BBEAgGWyUx0ad3p2u8dSnYnKTuHMmXhnC4VCIdNFdMTn88nj8cjr9So9Pd10OQCAU7C/ql7bKvepLuCTFF4JSXUmakAWZ830VJ35/OasGQCApfIz3Ep2FulgTaOqG5qV7k5SdoqDbRlIIogAACLA43bI42YbBm3RIwIAAIwhiAAAAGMIIgAAwBiCCAAAMIYgAgAAjCGIAAAAYwgiAADAGIIIAAAwhiACAACMIYgAAABjovoS70fux+fz+QxXAgAATtaRz+2Tua9uVAeR6upqSVJRUZHhSgAAQGdVV1fL4/Ec9zW20MnEFUOCwaD27duntLQ02Wy2bv3aPp9PRUVF2rNnzwlvUQzr8X5EF96P6ML7EX14T44vFAqpurpaBQUFSkg4fhdIVK+IJCQkqLCw0NI50tPT+UsURXg/ogvvR3Th/Yg+vCcdO9FKyBE0qwIAAGMIIgAAwJi4DSJOp1P33HOPnE6n6VIg3o9ow/sRXXg/og/vSfeJ6mZVAADQs8XtiggAADCPIAIAAIwhiAAAAGMIIgAAwJi4DCLz589Xv3795HK5NHr0aK1bt850SXGrpKREI0eOVFpamnJzczVlyhRt27bNdFmQ9OCDD8pms2nOnDmmS4lre/fu1Y033qjs7Gy53W6dc845+uCDD0yXFZcCgYB++tOfqn///nK73Ro4cKDuu+++k7qfCjoWd0Fk8eLFKi4u1j333KONGzdq2LBhuuyyy1ReXm66tLi0cuVKzZw5U2vWrNFbb72lpqYmXXrppaqtrTVdWlxbv369nnzySQ0dOtR0KXHt8OHDGjdunJKSkvTGG29oy5Yt+q//+i9lZmaaLi0uPfTQQ1qwYIEef/xxffbZZ3rooYf0i1/8Qo899pjp0mJa3J2+O3r0aI0cOVKPP/64pPD9bIqKinT77bdr7ty5hqtDRUWFcnNztXLlSl144YWmy4lLNTU1Ou+88/Sb3/xG999/v84991w9+uijpsuKS3PnztV7772nd99913QpkHTVVVcpLy9PzzzzTMvYv/zLv8jtduuFF14wWFlsi6sVkcbGRm3YsEETJ05sGUtISNDEiRP1/vvvG6wMR3i9XklSVlaW4Uri18yZM3XllVe2+j6BGa+99ppGjBiha6+9Vrm5uRo+fLiefvpp02XFrbFjx2r58uX6/PPPJUkfffSRVq9erUmTJhmuLLZF9U3vultlZaUCgYDy8vJajefl5Wnr1q2GqsIRwWBQc+bM0bhx4zRkyBDT5cSlP/zhD9q4caPWr19vuhRI+vLLL7VgwQIVFxfrrrvu0vr16/XDH/5QDodD06ZNM11e3Jk7d658Pp8GDRoku92uQCCgBx54QDfccIPp0mJaXAURRLeZM2dq8+bNWr16telS4tKePXs0e/ZsvfXWW3K5XKbLgcLhfMSIEfr5z38uSRo+fLg2b96sJ554giBiwEsvvaQXX3xRixYt0tlnn61NmzZpzpw5Kigo4P3ogrgKIjk5ObLb7Tpw4ECr8QMHDqh3796GqoIkzZo1S0uXLtWqVatUWFhoupy4tGHDBpWXl+u8885rGQsEAlq1apUef/xx+f1+2e12gxXGn/z8fA0ePLjV2FlnnaWXX37ZUEXx7Y477tDcuXN1/fXXS5LOOecc7dq1SyUlJQSRLoirHhGHw6Hzzz9fy5cvbxkLBoNavny5xowZY7Cy+BUKhTRr1iyVlpZqxYoV6t+/v+mS4tbFF1+sTz75RJs2bWp5jBgxQjfccIM2bdpECDFg3LhxbU5n//zzz9W3b19DFcW3uro6JSS0/ti02+0KBoOGKuoZ4mpFRJKKi4s1bdo0jRgxQqNGjdKjjz6q2tpaTZ8+3XRpcWnmzJlatGiRlixZorS0NJWVlUmSPB6P3G634eriS1paWpvenJSUFGVnZ9OzY8iPfvQjjR07Vj//+c/1r//6r1q3bp2eeuopPfXUU6ZLi0uTJ0/WAw88oD59+ujss8/Whx9+qEceeUTf+973TJcW20Jx6LHHHgv16dMn5HA4QqNGjQqtWbPGdElxS1K7j+eee850aQiFQt/85jdDs2fPNl1GXHv99ddDQ4YMCTmdztCgQYNCTz31lOmS4pbP5wvNnj071KdPn5DL5QoNGDAg9JOf/CTk9/tNlxbT4u46IgAAIHrEVY8IAACILgQRAABgDEEEAAAYQxABAADGEEQAAIAxBBEAAGAMQQQAABhDEAEAAMYQRAAAgDEEEQAAYAxBBAAAGEMQAQAAxvx//cG1LhKV0sIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(jnp.average(res['embeddings_1'], axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
