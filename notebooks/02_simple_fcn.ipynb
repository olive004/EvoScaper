{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple representation space tests with an FCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Callable, Dict, Any, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import torch  # https://pytorch.org\n",
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping\n",
    "import ast\n",
    "\n",
    "import equinox as eqx\n",
    "import wandb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "from synbio_morpher.utils.misc.numerical import make_symmetrical_matrix_from_sequence\n",
    "from synbio_morpher.utils.misc.string_handling import convert_liststr_to_list\n",
    "from synbio_morpher.utils.misc.type_handling import flatten_listlike\n",
    "from synbio_morpher.utils.results.analytics.naming import get_true_names_analytics, get_true_interaction_cols\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../data/processed/ensemble_mutation_effect_analysis/2023_07_17_105328/tabulated_mutation_info.csv'\n",
    "data = pd.read_csv(fn)\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "for c in get_true_interaction_cols(data, interaction_attr='binding_sites_idxs', remove_symmetrical=True) + get_true_interaction_cols(\n",
    "        data, interaction_attr='binding_site_group_range', remove_symmetrical=True):\n",
    "    data[c] = data[c].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: network of fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://coderzcolumn.com/tutorials/artificial-intelligence/haiku-cnn\n",
    "\n",
    "class FCN(hk.Module):\n",
    "\n",
    "    def __init__(self, key, in_expected: int, layer_sizes: List[int], n_head: int):\n",
    "        \n",
    "        self.layers = self.create_layers(in_expected, layer_sizes, n_head, key)\n",
    "        \n",
    "        \n",
    "    def create_layers(self, in_expected: int, layer_sizes: List[int], n_head: int, key):\n",
    "        sizes = [in_expected] + layer_sizes + [n_head]\n",
    "        key, *subkeys = jax.random.split(key, len(sizes))\n",
    "        l = []\n",
    "        for i, (si, sj, subkey) in enumerate(zip(sizes[:-1], sizes[1:], subkeys)):\n",
    "            if l:\n",
    "                l.append(jax.nn.relu)\n",
    "                if np.mod(i, 2) == 0:\n",
    "                    l.append(jax.nn.sigmoid)\n",
    "            # if sj == n_head:\n",
    "            #     l.append(eqx.nn.Dropout(p=0.4))\n",
    "            l.append(\n",
    "                hk.Linear(s)\n",
    "            )\n",
    "        l.append(jax.nn.log_softmax)\n",
    "        return l\n",
    "        \n",
    "\n",
    "    def __call__(self, x: Float[Array, \" num_interactions\"], inference: bool = False, seed: int = 0) -> Float[Array, \" n_head\"]:\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            kwargs = {} if not type(layer) == eqx.nn.Dropout else {\n",
    "                'inference': inference, 'key': jax.random.PRNGKey(seed)}\n",
    "\n",
    "            x = layer(x, **kwargs)\n",
    "            \n",
    "            # wandb.log({f'emb_{i}_{type(layer)}': x})\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_BATCHES = 8000\n",
    "TRAIN_SPLIT = int(0.8 * N_BATCHES)\n",
    "TEST_SPLIT = N_BATCHES - TRAIN_SPLIT\n",
    "LEARNING_RATE = 1e-5\n",
    "STEPS = 5000\n",
    "PRINT_EVERY = 200\n",
    "SEED = 0\n",
    "TOTAL_DS = BATCH_SIZE * N_BATCHES\n",
    "INPUT_SPECIES = 'RNA_1'\n",
    "\n",
    "# CNN Architecture\n",
    "N_CHANNELS = 1\n",
    "OUT_CHANNELS = 3\n",
    "KERNEL_SIZE = 1\n",
    "MAX_POOL_KERNEL_SIZE = 1\n",
    "\n",
    "# FCN Architecture\n",
    "LAYER_SIZES = [10, 20, 50, 50, 50, 50]\n",
    "\n",
    "\n",
    "n_samples = len(data['sample_name'].unique())\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "key, subkey = jax.random.split(key, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_scientific_exponent(x): \n",
    "    return int(f'{x:.0e}'.split('e')[1])\n",
    "\n",
    "vectorized_convert_to_scientific_exponent = np.vectorize(convert_to_scientific_exponent)\n",
    "filt = data['sample_name'] == INPUT_SPECIES\n",
    "\n",
    "x = data[filt][get_true_interaction_cols(data, 'binding_rates_dissociation', remove_symmetrical=True)].iloc[:TOTAL_DS].values\n",
    "x = jax.tree_util.tree_map(vectorized_convert_to_scientific_exponent, x)\n",
    "x = jax.random.permutation(key, x, axis=0, independent=True)\n",
    "\n",
    "# Make binding into 2D Interactions\n",
    "# x = np.expand_dims(np.array([make_symmetrical_matrix_from_sequence(xx, n_samples) for xx in x]), axis=1)\n",
    "\n",
    "y = data[filt]['sensitivity_wrt_species-6'].iloc[:TOTAL_DS].to_numpy()\n",
    "y = jax.tree_util.tree_map(vectorized_convert_to_scientific_exponent, y)[None, :]\n",
    "y = jax.random.permutation(key, y, axis=0, independent=True)\n",
    "\n",
    "N_HEAD = len(np.unique(y))\n",
    "\n",
    "\n",
    "if x.shape[0] < TOTAL_DS:\n",
    "    print(f'WARNING: The filtered data is not as large as the requested total dataset size: {x.shape[0]} vs. requested {TOTAL_DS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN(subkey, in_expected=x.shape[1], layer_sizes=LAYER_SIZES, n_head=N_HEAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(\n",
    "    model: FCN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    \n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, y, axis=1)\n",
    "    # pred_y = jnp.take_along_axis(pred_y, y, axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, x[:10], y[:10])\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(model)(x[:10])\n",
    "print(output.shape)  # batch of predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
