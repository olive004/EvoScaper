{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:25.163156Z",
     "iopub.status.busy": "2024-12-19T10:23:25.163045Z",
     "iopub.status.idle": "2024-12-19T10:23:25.175314Z",
     "shell.execute_reply": "2024-12-19T10:23:25.174834Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VAE models systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:25.176902Z",
     "iopub.status.busy": "2024-12-19T10:23:25.176788Z",
     "iopub.status.idle": "2024-12-19T10:23:27.019715Z",
     "shell.execute_reply": "2024-12-19T10:23:27.019203Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from evoscaper.scripts.cvae_scan import main as cvae_scan\n",
    "from evoscaper.utils.preprocess import make_datetime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of all VAE model training settings\n",
    "\n",
    "Parameters for:\n",
    "- Biological dataset generation\n",
    "- Training data\n",
    "    - Input\n",
    "    - Output \n",
    "- Model architecture\n",
    "- Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.023360Z",
     "iopub.status.busy": "2024-12-19T10:23:27.023096Z",
     "iopub.status.idle": "2024-12-19T10:23:27.051026Z",
     "shell.execute_reply": "2024-12-19T10:23:27.050617Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "hpos_architecture = {\n",
    "    'seed_arch': 1,\n",
    "    'hidden_size': 32,\n",
    "    'enc_layers': [64, 64, 64],\n",
    "    'dec_layers': [64, 64, 64],\n",
    "    'model': 'CVAE',\n",
    "    'use_sigmoid_decoder': False,\n",
    "    'enc_init': 'HeNormal',\n",
    "    'dec_init': 'HeNormal',\n",
    "    'init_model_with_random': True,\n",
    "    'activation': 'leaky_relu',\n",
    "}\n",
    "\n",
    "\n",
    "hpos_training = {\n",
    "    'seed_train': 1,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 2000,\n",
    "    'patience': 1000,\n",
    "    'learning_rate': 1e-1,\n",
    "    'loss_func': 'mse',\n",
    "    'use_dropout': False,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_l2_reg': False,\n",
    "    'l2_reg_alpha': 0.01,\n",
    "    'use_kl_div': True,\n",
    "    'kl_weight': 2.5e-4,  # inspired by https://github.com/elttaes/VAE-MNIST-Haiku-Jax/blob/main/cVAE_mnist.ipynb\n",
    "}\n",
    "hpos_training['print_every'] = hpos_training['epochs'] // 100\n",
    "\n",
    "hpos_optimization = {\n",
    "    'seed_opt': 1,\n",
    "    'opt_method': 'sgd',\n",
    "    'opt_min_lr': 1e-6,\n",
    "    'opt_min_delta': 1e-4,\n",
    "    'learning_rate_sched': 'cosine_decay',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 20,\n",
    "}\n",
    "\n",
    "hpos_dataset = {\n",
    "    'seed_dataset': 1,\n",
    "    'include_diffs': False,\n",
    "    'objective_col': 'Log sensitivity',\n",
    "    'output_species': ['RNA_2'],\n",
    "    'signal_species': ['RNA_0'],\n",
    "    'filenames_train_config': [f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config.json'], \n",
    "    'filenames_train_table': [f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'],\n",
    "    'filenames_verify_config': [f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json'], \n",
    "    'filenames_verify_table': [f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'],\n",
    "    'use_test_data': False,\n",
    "    # 'total_ds': None,   # TO BE RECORDED\n",
    "    'total_ds_max': 5e6,\n",
    "    'train_split': 0.8,\n",
    "    'x_type': 'energies',\n",
    "    # XY filtering:\n",
    "    'filt_x_nans': True,\n",
    "    'filt_y_nans': True,\n",
    "    'filt_sensitivity_nans': True,\n",
    "    'filt_precision_nans': True,\n",
    "    'filt_n_same_x_max': 1,\n",
    "    'filt_n_same_x_max_bins': 15,\n",
    "    # XY preprocessing:\n",
    "    'prep_x_standardise': False,\n",
    "    'prep_y_standardise': False,\n",
    "    'prep_x_min_max': False,\n",
    "    'prep_y_min_max': False,\n",
    "    'prep_x_robust_scaling': True,\n",
    "    'prep_y_robust_scaling': True,\n",
    "    'prep_x_logscale': False,\n",
    "    'prep_y_logscale': False,\n",
    "    'prep_x_categorical': False,\n",
    "    'prep_y_categorical': True,\n",
    "    'prep_x_categorical_onehot': False,\n",
    "    'prep_y_categorical_onehot': True,\n",
    "    'prep_x_categorical_n_bins': 10,\n",
    "    'prep_y_categorical_n_bins': 10,\n",
    "    'prep_x_categorical_method': 'quantile',\n",
    "    'prep_y_categorical_method': 'quantile',\n",
    "    'prep_x_negative': True,\n",
    "    'prep_y_negative': False\n",
    "}\n",
    "\n",
    "hpos_biological = {\n",
    "    'n_species': 3,\n",
    "    'sequence_length': 20,\n",
    "    'signal_function': 'step_function',\n",
    "    'signal_target': 2,\n",
    "    'starting_copynumbers_input': [200],\n",
    "    'starting_copynumbers_output': [200],\n",
    "    'starting_copynumbers_other': [200],\n",
    "    'association_binding_rate': 1000000,\n",
    "    'include_prod_deg': False,\n",
    "}\n",
    "\n",
    "hpos_eval = {\n",
    "    'eval_n_to_sample': 1e5\n",
    "}\n",
    "\n",
    "info_to_be_recorded = {\n",
    "    'filename_saved_model': 'TO_BE_RECORDED',\n",
    "    'total_ds': 'TO_BE_RECORDED',\n",
    "    'n_batches': 'TO_BE_RECORDED',\n",
    "    'R2_train': 'TO_BE_RECORDED',\n",
    "    'R2_test': 'TO_BE_RECORDED',\n",
    "    'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
    "    'n_layers_enc': 'TO_BE_RECORDED',\n",
    "    'n_layers_dec': 'TO_BE_RECORDED',\n",
    "    'run_successful': 'TO_BE_RECORDED',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.054017Z",
     "iopub.status.busy": "2024-12-19T10:23:27.053897Z",
     "iopub.status.idle": "2024-12-19T10:23:27.085640Z",
     "shell.execute_reply": "2024-12-19T10:23:27.085278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>dec_layers</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>enc_init</th>\n",
       "      <th>dec_init</th>\n",
       "      <th>init_model_with_random</th>\n",
       "      <th>activation</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_n_to_sample</th>\n",
       "      <th>filename_saved_model</th>\n",
       "      <th>total_ds</th>\n",
       "      <th>n_batches</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>mutual_information_conditionality</th>\n",
       "      <th>n_layers_enc</th>\n",
       "      <th>n_layers_dec</th>\n",
       "      <th>run_successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size    enc_layers    dec_layers model use_sigmoid_decoder  \\\n",
       "0         1          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "\n",
       "   enc_init  dec_init init_model_with_random  activation  ...  \\\n",
       "0  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "\n",
       "  eval_n_to_sample filename_saved_model        total_ds       n_batches  \\\n",
       "0         100000.0       TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "         R2_train         R2_test mutual_information_conditionality  \\\n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED                    TO_BE_RECORDED   \n",
       "\n",
       "     n_layers_enc    n_layers_dec  run_successful  \n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  \n",
       "\n",
       "[1 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos = pd.concat([pd.DataFrame.from_dict(hpos, orient='index').T for hpos in [hpos_architecture, hpos_training, hpos_optimization, hpos_dataset, hpos_eval, info_to_be_recorded]], axis=1)\n",
    "assert df_hpos.columns.duplicated().sum() == 0, 'Change some column names, there are duplicates'\n",
    "basic_setting = df_hpos.copy()\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.111844Z",
     "iopub.status.busy": "2024-12-19T10:23:27.111582Z",
     "iopub.status.idle": "2024-12-19T10:23:27.139996Z",
     "shell.execute_reply": "2024-12-19T10:23:27.139610Z"
    }
   },
   "outputs": [],
   "source": [
    "hpos_to_vary_from_og = {\n",
    "    'seed_arch': [1, 2, 3, 4, 5],\n",
    "}\n",
    "hpos_to_vary_together = {\n",
    "    'total_ds_max': [1e4, 5e4, 1e5],\n",
    "    'hidden_size': [16, 32, 64, 128, 256, 512],\n",
    "    'enc_layers': [[[32, 32]], [[64, 64]], [[32, 32, 32]]],\n",
    "    'dec_layers': [[[32, 32]], [[64, 64]], [[32, 32, 32]]],\n",
    "}\n",
    "hpos_to_vary_together2 = {\n",
    "    'objective_col': ['adaptability', 'sensitivity_wrt_species-6'],\n",
    "    'x_type': ['energies', 'binding_rates_dissociation'],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'use_l2_reg': [True],\n",
    "    'l2_reg_alpha': [0, 1e-2, 1e-3, 1e-4],\n",
    "    'kl_weight': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "df_hpos.loc[df_hpos['objective_col'] == 'sensitivity_wrt_species-6', 'prep_y_logscale'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.141510Z",
     "iopub.status.busy": "2024-12-19T10:23:27.141382Z",
     "iopub.status.idle": "2024-12-19T10:23:27.444282Z",
     "shell.execute_reply": "2024-12-19T10:23:27.443880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting):\n",
    "    keys_vary_together = sorted(hpos_to_vary_together.keys())\n",
    "    for v in itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]):\n",
    "        curr = basic_setting.assign(**{h: vv for h, vv in zip(keys_vary_together, v)})\n",
    "        df_hpos = pd.concat([df_hpos, curr], ignore_index=True)\n",
    "    # print('All good if these are equal: ', len(df_hpos), len(list(itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]))) + 1)\n",
    "    return df_hpos\n",
    "\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting)\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together2, basic_setting)\n",
    "\n",
    "for h, v in hpos_to_vary_from_og.items():\n",
    "    df_hpos = pd.concat([df_hpos] + [basic_setting.assign(**{h: vv}) for vv in v], ignore_index=True)\n",
    "\n",
    "# Only keep architectures where enc_layers == dec_layers\n",
    "df_hpos = df_hpos[df_hpos['enc_layers'] == df_hpos['dec_layers']]\n",
    "\n",
    "# Reorder columns\n",
    "cols_priority = list(hpos_to_vary_from_og.keys()) + list(hpos_to_vary_together.keys()) + list(hpos_to_vary_together2.keys())\n",
    "df_hpos = df_hpos[cols_priority + [c for c in df_hpos.columns if c not in cols_priority]]\n",
    "\n",
    "len(df_hpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use table to create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.446976Z",
     "iopub.status.busy": "2024-12-19T10:23:27.446833Z",
     "iopub.status.idle": "2024-12-19T10:23:27.473680Z",
     "shell.execute_reply": "2024-12-19T10:23:27.472872Z"
    }
   },
   "outputs": [],
   "source": [
    "# fn = '../data/raw/summarise_simulation/2024_11_21_144918/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'\n",
    "# data = pd.read_csv(fn).iloc[:100]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.476452Z",
     "iopub.status.busy": "2024-12-19T10:23:27.476327Z",
     "iopub.status.idle": "2024-12-19T10:23:27.499293Z",
     "shell.execute_reply": "2024-12-19T10:23:27.498703Z"
    }
   },
   "outputs": [],
   "source": [
    "# hpos = df_hpos.reset_index().iloc[0]\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.500687Z",
     "iopub.status.busy": "2024-12-19T10:23:27.500574Z",
     "iopub.status.idle": "2024-12-19T10:23:27.528607Z",
     "shell.execute_reply": "2024-12-19T10:23:27.527732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed_arch': 1,\n",
       " 'total_ds_max': 100000.0,\n",
       " 'hidden_size': 16,\n",
       " 'enc_layers': [32, 32],\n",
       " 'dec_layers': [32, 32],\n",
       " 'objective_col': 'Log sensitivity',\n",
       " 'x_type': 'energies',\n",
       " 'learning_rate': 0.1,\n",
       " 'use_l2_reg': False,\n",
       " 'l2_reg_alpha': 0.01,\n",
       " 'kl_weight': 0.00025,\n",
       " 'model': 'CVAE',\n",
       " 'use_sigmoid_decoder': False,\n",
       " 'enc_init': 'HeNormal',\n",
       " 'dec_init': 'HeNormal',\n",
       " 'init_model_with_random': True,\n",
       " 'activation': 'leaky_relu',\n",
       " 'seed_train': 1,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 2000,\n",
       " 'patience': 1000,\n",
       " 'loss_func': 'mse',\n",
       " 'use_dropout': False,\n",
       " 'dropout_rate': 0.1,\n",
       " 'use_kl_div': True,\n",
       " 'print_every': 20,\n",
       " 'seed_opt': 1,\n",
       " 'opt_method': 'sgd',\n",
       " 'opt_min_lr': 1e-06,\n",
       " 'opt_min_delta': 0.0001,\n",
       " 'learning_rate_sched': 'cosine_decay',\n",
       " 'use_warmup': True,\n",
       " 'warmup_epochs': 20,\n",
       " 'seed_dataset': 1,\n",
       " 'include_diffs': False,\n",
       " 'output_species': ['RNA_2'],\n",
       " 'signal_species': ['RNA_0'],\n",
       " 'filenames_train_config': ['../data/raw/summarise_simulation/2024_12_05_210221/ensemble_config.json'],\n",
       " 'filenames_train_table': ['../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'],\n",
       " 'filenames_verify_config': ['../data/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json'],\n",
       " 'filenames_verify_table': ['../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'],\n",
       " 'use_test_data': False,\n",
       " 'train_split': 0.8,\n",
       " 'filt_x_nans': True,\n",
       " 'filt_y_nans': True,\n",
       " 'filt_sensitivity_nans': True,\n",
       " 'filt_precision_nans': True,\n",
       " 'filt_n_same_x_max': 1,\n",
       " 'filt_n_same_x_max_bins': 15,\n",
       " 'prep_x_standardise': False,\n",
       " 'prep_y_standardise': False,\n",
       " 'prep_x_min_max': False,\n",
       " 'prep_y_min_max': False,\n",
       " 'prep_x_robust_scaling': True,\n",
       " 'prep_y_robust_scaling': True,\n",
       " 'prep_x_logscale': False,\n",
       " 'prep_y_logscale': False,\n",
       " 'prep_x_categorical': False,\n",
       " 'prep_y_categorical': True,\n",
       " 'prep_x_categorical_onehot': False,\n",
       " 'prep_y_categorical_onehot': True,\n",
       " 'prep_x_categorical_n_bins': 10,\n",
       " 'prep_y_categorical_n_bins': 10,\n",
       " 'prep_x_categorical_method': 'quantile',\n",
       " 'prep_y_categorical_method': 'quantile',\n",
       " 'prep_x_negative': True,\n",
       " 'prep_y_negative': False,\n",
       " 'eval_n_to_sample': 100000.0,\n",
       " 'filename_saved_model': 'TO_BE_RECORDED',\n",
       " 'total_ds': 'TO_BE_RECORDED',\n",
       " 'n_batches': 'TO_BE_RECORDED',\n",
       " 'R2_train': 'TO_BE_RECORDED',\n",
       " 'R2_test': 'TO_BE_RECORDED',\n",
       " 'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
       " 'n_layers_enc': 'TO_BE_RECORDED',\n",
       " 'n_layers_dec': 'TO_BE_RECORDED',\n",
       " 'run_successful': 'TO_BE_RECORDED'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos.iloc[3].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:23:27.530502Z",
     "iopub.status.busy": "2024-12-19T10:23:27.530394Z",
     "iopub.status.idle": "2024-12-19T10:42:39.475887Z",
     "shell.execute_reply": "2024-12-19T10:42:39.474856Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xla_bridge.py:backends():900: Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA INFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xla_bridge.py:backends():900: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory INFO\n"
     ]
    }
   ],
   "source": [
    "# REMINDER: Total ds is 3 and the test data is not being used\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n",
    "\n",
    "top_dir = os.path.join('data', make_datetime_str())\n",
    "for i in range(len(df_hpos)):\n",
    "    hpos = df_hpos.reset_index().iloc[i]\n",
    "    try:\n",
    "        hpos = cvae_scan(hpos, top_dir=top_dir)\n",
    "        hpos['run_successful'] = True\n",
    "    except:\n",
    "        hpos['run_successful'] = False\n",
    "    df_hpos.loc[i] = pd.Series(hpos) if type(hpos) == dict else hpos\n",
    "    df_hpos.to_csv(os.path.join(top_dir, 'df_hpos.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T10:42:39.479104Z",
     "iopub.status.busy": "2024-12-19T10:42:39.478975Z",
     "iopub.status.idle": "2024-12-19T10:42:39.503117Z",
     "shell.execute_reply": "2024-12-19T10:42:39.502414Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_fn = partial(VAE_fn, enc_layers=enc_layers, dec_layers=dec_layers, decoder_head=x.shape[-1], \n",
    "#                    HIDDEN_SIZE=HIDDEN_SIZE, decoder_activation_final=jax.nn.sigmoid if USE_SIGMOID_DECODER else jax.nn.leaky_relu, \n",
    "#                    enc_init=ENC_INIT, dec_init=DEC_INIT, activation=get_activation_fn(ACTIVATION))\n",
    "# model_t = hk.multi_transform(model_fn)\n",
    "# dummy_x = jax.random.normal(PRNG, x.shape)\n",
    "# dummy_cond = jax.random.normal(PRNG, cond.shape)\n",
    "# params = model_t.init(PRNG, dummy_x, dummy_cond, deterministic=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
