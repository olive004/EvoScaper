{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional VAE for genetic circuits\n",
    "\n",
    "This notebook follows the previous VAE notebook very closely, but implementing a conditional VAE instead. Loosely following [this blog post](https://agustinus.kristia.de/techblog/2016/12/17/conditional-vae/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "\n",
    "from synbio_morpher.utils.data.data_format_tools.common import load_json_as_dict\n",
    "from synbio_morpher.utils.results.analytics.naming import get_true_interaction_cols\n",
    "from synbio_morpher.utils.data.data_format_tools.common import write_json\n",
    "from synbio_morpher.utils.misc.string_handling import prettify_keys_for_label\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.metrics import r2_score  \n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "                \n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "\n",
    "# if __package__ is None:\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "__package__ = os.path.basename(module_path)\n",
    "\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vae import CVAE\n",
    "from src.models.mlp import MLP\n",
    "from src.models.shared import arrayise\n",
    "from src.losses.losses import loss_wrapper, compute_accuracy_regression, mse_loss\n",
    "from src.utils.data_preprocessing import drop_duplicates_keep_first_n\n",
    "from src.utils.optimiser import make_optimiser\n",
    "from src.utils.train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../data/processed/ensemble_mutation_effect_analysis/2023_07_17_105328/tabulated_mutation_info.csv'\n",
    "fn_test_data = '../data/raw/ensemble_mutation_effect_analysis/2023_10_03_204819/tabulated_mutation_info.csv'\n",
    "data = pd.read_csv(fn)\n",
    "try:\n",
    "    data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_ENC_LAYERS = 3\n",
    "NUM_DEC_LAYERS = 3\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "N_BATCHES = 1200\n",
    "TOTAL_DS = BATCH_SIZE * N_BATCHES\n",
    "MAX_TOTAL_DS = TOTAL_DS\n",
    "TRAIN_SPLIT = 0.8\n",
    "SCALE_X = False\n",
    "LEARNING_RATE = 5e-4\n",
    "LEARNING_RATE_SCHED = 'cosine_decay'\n",
    "# LEARNING_RATE_SCHED = 'constant'\n",
    "WARMUP_EPOCHS = 20\n",
    "L2_REG_ALPHA = 0.01\n",
    "EPOCHS = 2\n",
    "PRINT_EVERY = EPOCHS // 1000\n",
    "SEED = 1\n",
    "USE_CATEGORICAL = False\n",
    "target_circ_func = 'sensitivity_wrt_species-6'\n",
    "input_concat_diffs = False\n",
    "input_concat_axis = 0\n",
    "\n",
    "# Training\n",
    "USE_DROPOUT = False\n",
    "USE_L2_REG = False\n",
    "USE_WARMUP = True\n",
    "\n",
    "loss_fn = partial(\n",
    "    loss_wrapper, loss_f=mse_loss, use_l2_reg=USE_L2_REG) \n",
    "compute_accuracy = compute_accuracy_regression\n",
    "\n",
    "subtask = '_test'\n",
    "save_path = str(datetime.now()).split(' ')[0].replace(\n",
    "    '-', '_') + '__' + str(datetime.now()).split(' ')[-1].split('.')[0].replace(':', '_') + '_saves' + subtask\n",
    "save_path = os.path.join('weight_saves', '09_vae', save_path)\n",
    "\n",
    "rng = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = data['sample_name'] == data['sample_name'].unique()[0]\n",
    "\n",
    "# Balance the dataset\n",
    "df = drop_duplicates_keep_first_n(data[filt], get_true_interaction_cols(\n",
    "    data, 'energies', remove_symmetrical=True), n=100)\n",
    "\n",
    "TOTAL_DS = np.min([TOTAL_DS, MAX_TOTAL_DS, len(df)])\n",
    "N_BATCHES = TOTAL_DS // BATCH_SIZE\n",
    "TOTAL_DS = N_BATCHES * BATCH_SIZE\n",
    "\n",
    "x_cols = [get_true_interaction_cols(data, 'energies', remove_symmetrical=True)]\n",
    "if input_concat_diffs:\n",
    "    k = 'energies'\n",
    "    x_cols = x_cols + \\\n",
    "        [[f'{i}_diffs' for i in get_true_interaction_cols(\n",
    "            data, k, remove_symmetrical=True)]]\n",
    "\n",
    "x = [df[i].iloc[:TOTAL_DS].values[:, :, None] for i in x_cols]\n",
    "x = np.concatenate(x, axis=input_concat_axis+1).squeeze()\n",
    "\n",
    "if SCALE_X:\n",
    "    xscaler = MinMaxScaler()\n",
    "    x = xscaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df[target_circ_func].iloc[:TOTAL_DS].to_numpy()\n",
    "\n",
    "if USE_CATEGORICAL:\n",
    "    from src.utils.math import convert_to_scientific_exponent\n",
    "\n",
    "    vectorized_convert_to_scientific_exponent = np.vectorize(\n",
    "        convert_to_scientific_exponent)\n",
    "    numerical_resolution = 2\n",
    "    cond_map = {k: numerical_resolution for k in np.arange(int(f'{cond[cond != 0].min():.0e}'.split(\n",
    "        'e')[1])-1, np.max([int(f'{cond.max():.0e}'.split('e')[1])+1, 0 + 1]))}\n",
    "    cond_map[-6] = 1\n",
    "    cond_map[-5] = 1\n",
    "    cond_map[-4] = 4\n",
    "    cond_map[-3] = 2\n",
    "    cond_map[-1] = 3\n",
    "    cond = jax.tree_util.tree_map(partial(\n",
    "        vectorized_convert_to_scientific_exponent, numerical_resolution=cond_map), cond)\n",
    "    cond = np.interp(cond, sorted(np.unique(cond)), np.arange(\n",
    "        len(sorted(np.unique(cond))))).astype(int)\n",
    "else:\n",
    "    zero_log_replacement = -10.0\n",
    "    cond = np.where(cond != 0, np.log10(cond), zero_log_replacement)\n",
    "\n",
    "cond = cond[:, None]\n",
    "N_HEAD = x.shape[-1]\n",
    "\n",
    "x, cond = shuffle(x, cond, random_state=SEED)\n",
    "\n",
    "if x.shape[0] < TOTAL_DS:\n",
    "    print(\n",
    "        f'WARNING: The filtered data is not as large as the requested total dataset size: {x.shape[0]} vs. requested {TOTAL_DS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153600, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([x, cond], axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wadh6511/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/initializers.py:126: UserWarning: Explicitly requested dtype float64  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  unscaled = jax.random.truncated_normal(\n",
      "/home/wadh6511/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/base.py:682: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  param = init(shape, dtype)\n"
     ]
    }
   ],
   "source": [
    "enc_layers = [64] * NUM_ENC_LAYERS\n",
    "dec_layers = [64] * NUM_DEC_LAYERS\n",
    "\n",
    "def VAE_fn(enc_layers: list, dec_layers: list, call_kwargs: dict = {}):\n",
    "    encoder = MLP(layer_sizes=enc_layers, n_head=dec_layers[0], use_categorical=False, name='encoder')\n",
    "    decoder = MLP(layer_sizes=dec_layers, n_head=x.shape[-1], use_categorical=False, name='decoder')\n",
    "    model = CVAE(encoder=encoder, decoder=decoder, embed_size=HIDDEN_SIZE)\n",
    "    \n",
    "    def init(x: np.ndarray, cond: np.ndarray, deterministic: bool):\n",
    "        h = model.encoder(np.concatenate([x, cond], axis=1))\n",
    "\n",
    "        mu = model.h2mu(h)\n",
    "        logvar = model.h2logvar(h)\n",
    "        z = model.reparameterize(mu, logvar, hk.next_rng_key(), deterministic)\n",
    "        z_cond = np.concatenate([z, cond], axis=1)\n",
    "\n",
    "        y = model.decoder(z_cond)\n",
    "        return y\n",
    "        \n",
    "    return init, (encoder, decoder, model) #model(x, **call_kwargs)\n",
    "\n",
    "model_fn = partial(VAE_fn, enc_layers=enc_layers, dec_layers=dec_layers, call_kwargs={'key': rng})\n",
    "# model = hk.transform(model_fn)\n",
    "model_t = hk.multi_transform(model_fn)\n",
    "params = model_t.init(rng, x, cond, deterministic=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, model = model_t.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = encoder(params, rng, np.concatenate([x, cond], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.828096  ,  0.44034743,  0.127117  ,  0.22060458,  1.0389135 ,\n",
       "         0.64571387],\n",
       "       [ 1.203476  ,  0.40342674, -0.02293426,  0.40638748,  1.0218014 ,\n",
       "         0.770212  ],\n",
       "       [ 1.2044122 ,  0.5254014 ,  0.05394775,  0.40198803,  0.8121447 ,\n",
       "         0.9488541 ],\n",
       "       ...,\n",
       "       [ 0.8658786 ,  0.39744958,  0.2709294 ,  0.36628583,  0.9357086 ,\n",
       "         0.80208105],\n",
       "       [ 1.1067777 ,  0.11078835,  0.09987341,  0.5400736 ,  0.9874594 ,\n",
       "         0.9807138 ],\n",
       "       [ 1.1594436 ,  0.5366029 ,  0.0519705 ,  0.2567124 ,  0.9820483 ,\n",
       "         0.9324589 ]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(params, rng, x, cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = make_optimiser(LEARNING_RATE_SCHED, LEARNING_RATE,\n",
    "                           EPOCHS, L2_REG_ALPHA, USE_WARMUP, WARMUP_EPOCHS, N_BATCHES)\n",
    "optimiser_state = optimiser.init(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i_batch, xcond, Batches, *content]\n",
    "        \n",
    "x = x.reshape(N_BATCHES, 1, BATCH_SIZE, 1, x.shape[-1])\n",
    "cond = cond.reshape(N_BATCHES, 1, BATCH_SIZE, 1, cond.shape[-1])\n",
    "y = x.reshape(N_BATCHES, 1, BATCH_SIZE, 1, x.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 4, the array at index 0 has size 6 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2277616468363531312d50432d425832333638312d5453227d/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mconcatenate([x, cond], axis\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 4, the array at index 0 has size 6 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "np.concatenate([x, cond], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train = x[:int(TRAIN_SPLIT * N_BATCHES)], x[:int(TRAIN_SPLIT * N_BATCHES)]\n",
    "x_val, y_val = x[int(TRAIN_SPLIT * N_BATCHES):], x[int(TRAIN_SPLIT * N_BATCHES):]\n",
    "xy_train = np.concatenate([x_train, y_train], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CVAE.__call__() missing 1 required positional argument: 'cond'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:85\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, rng, model, xy_train, x_val, y_val, optimiser, optimiser_state, l2_reg_alpha, epochs, compute_accuracy, loss_fn, save_every, include_params_in_saves)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     params, train_loss, val_loss, val_acc, params_stack, grads \u001b[39m=\u001b[39m do_scan()\n\u001b[1;32m     86\u001b[0m     saves \u001b[39m=\u001b[39m make_saves(train_loss, val_loss, val_acc, include_params_in_saves, params_stack, grads)\n",
      "\u001b[0;31mTypeError\u001b[0m: train.<locals>.do_scan() missing 3 required positional arguments: 'params', 'optimiser_state', and 'epochs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2277616468363531312d50432d425832333638312d5453227d/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m params, saves \u001b[39m=\u001b[39m train(params, rng, model, xcond_train, x_val, cond_val, optimiser, optimiser_state,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2277616468363531312d50432d425832333638312d5453227d/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                       l2_reg_alpha\u001b[39m=\u001b[39;49mL2_REG_ALPHA, epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2277616468363531312d50432d425832333638312d5453227d/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                       loss_fn\u001b[39m=\u001b[39;49mloss_fn, compute_accuracy\u001b[39m=\u001b[39;49mcompute_accuracy_regression,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2277616468363531312d50432d425832333638312d5453227d/home/wadh6511/Kode/EvoScaper/notebooks/10_cvae.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                       save_every\u001b[39m=\u001b[39;49mPRINT_EVERY, include_params_in_saves\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:100\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, rng, model, xy_train, x_val, y_val, optimiser, optimiser_state, l2_reg_alpha, epochs, compute_accuracy, loss_fn, save_every, include_params_in_saves)\u001b[0m\n\u001b[1;32m     97\u001b[0m saves \u001b[39m=\u001b[39m {}\n\u001b[1;32m     98\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     99\u001b[0m     (params, optimiser_state), (params_stack, grads, train_loss,\n\u001b[0;32m--> 100\u001b[0m                                 val_loss, val_acc) \u001b[39m=\u001b[39m f((params, optimiser_state), \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmod(e, save_every) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m         saves[e] \u001b[39m=\u001b[39m make_saves(train_loss, val_loss, val_acc, include_params_in_saves, params_stack, grads)\n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:60\u001b[0m, in \u001b[0;36mtrain.<locals>.f\u001b[0;34m(carry, _)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(carry, _):\n\u001b[1;32m     58\u001b[0m     params, optimiser_state \u001b[39m=\u001b[39m carry[\u001b[39m0\u001b[39m], carry[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 60\u001b[0m     params, optimiser_state, train_loss, grads \u001b[39m=\u001b[39m run_batches(\n\u001b[1;32m     61\u001b[0m         params, model, xy_train, rng, l2_reg_alpha, optimiser, optimiser_state, loss_fn)\n\u001b[1;32m     63\u001b[0m     val_acc, val_loss \u001b[39m=\u001b[39m eval_step(\n\u001b[1;32m     64\u001b[0m         params, rng, model, x_val, y_val, l2_reg_alpha, loss_fn, compute_accuracy)\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m (params, optimiser_state), (params, grads, train_loss, val_loss, val_acc)\n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:43\u001b[0m, in \u001b[0;36mrun_batches\u001b[0;34m(params, model, xy_train, rng, l2_reg_alpha, optimiser, optimiser_state, loss_fn)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m (params, optimiser_state), (loss, grads)\n\u001b[1;32m     42\u001b[0m \u001b[39m# for x_batch, y_batch in xy_train:\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m (params, optimiser_state), (train_loss, grads) \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mscan(\n\u001b[1;32m     44\u001b[0m     f, (params, optimiser_state), xy_train)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m params, optimiser_state, train_loss, grads\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:38\u001b[0m, in \u001b[0;36mrun_batches.<locals>.f\u001b[0;34m(carry, inp)\u001b[0m\n\u001b[1;32m     35\u001b[0m params, optimiser_state \u001b[39m=\u001b[39m carry[\u001b[39m0\u001b[39m], carry[\u001b[39m1\u001b[39m]\n\u001b[1;32m     36\u001b[0m x_batch, y_batch \u001b[39m=\u001b[39m inp[\u001b[39m0\u001b[39m], inp[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m params, optimiser_state, loss, grads \u001b[39m=\u001b[39m f_train_step(\n\u001b[1;32m     39\u001b[0m     params, x_batch, y_batch, optimiser_state)\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m (params, optimiser_state), (loss, grads)\n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/utils/train.py:11\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(params, x, y, optimiser_state, model, rng, l2_reg_alpha, optimiser, loss_fn)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(params, x, y, optimiser_state, model, rng, l2_reg_alpha, optimiser, loss_fn):\n\u001b[0;32m---> 11\u001b[0m     loss, grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(loss_fn)(\n\u001b[1;32m     12\u001b[0m         params, rng, model, x, y, l2_reg_alpha\u001b[39m=\u001b[39;49ml2_reg_alpha)\n\u001b[1;32m     14\u001b[0m     updates, optimiser_state \u001b[39m=\u001b[39m optimiser\u001b[39m.\u001b[39mupdate(grads, optimiser_state)\n\u001b[1;32m     15\u001b[0m     params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Kode/EvoScaper/src/losses/losses.py:42\u001b[0m, in \u001b[0;36mloss_wrapper\u001b[0;34m(params, rng, model_f, x, y, loss_f, use_l2_reg, l2_reg_alpha, **model_call_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_wrapper\u001b[39m(\n\u001b[1;32m     35\u001b[0m     params, rng,\n\u001b[1;32m     36\u001b[0m     model_f, x: Float[Array, \u001b[39m\"\u001b[39m\u001b[39m batch n_interactions\u001b[39m\u001b[39m\"\u001b[39m], y: Int[Array, \u001b[39m\"\u001b[39m\u001b[39m batch\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_call_kwargs\n\u001b[1;32m     40\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[Array, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> 42\u001b[0m     pred_y \u001b[39m=\u001b[39m model_f(params, rng, x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_call_kwargs)\n\u001b[1;32m     43\u001b[0m     loss \u001b[39m=\u001b[39m loss_f(y, pred_y)\n\u001b[1;32m     45\u001b[0m     \u001b[39m# Add L2 loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/multi_transform.py:251\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_without_state.<locals>.apply_fn\u001b[0;34m(params, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(params: hk\u001b[39m.\u001b[39mParams, rng, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 251\u001b[0m   out, state \u001b[39m=\u001b[39m orig_apply_fn(params, \u001b[39mNone\u001b[39;49;00m, rng, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    252\u001b[0m   \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    253\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` then use \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    255\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`hk.multi_transform_with_state`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/transform.py:457\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(params\u001b[39m=\u001b[39mparams, state\u001b[39m=\u001b[39mstate, rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    456\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    458\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/multi_transform.py:152\u001b[0m, in \u001b[0;36mmulti_transform_with_state.<locals>.apply_fn_i.<locals>.apply_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    151\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Applies the transformed function at the given inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m   \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mtree_util\u001b[39m.\u001b[39;49mtree_leaves(f()[\u001b[39m1\u001b[39;49m])[i](\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/module.py:465\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[39mif\u001b[39;00m method_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__call__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    463\u001b[0m     f \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mnamed_call(f, name\u001b[39m=\u001b[39mmethod_name)\n\u001b[0;32m--> 465\u001b[0m out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    467\u001b[0m \u001b[39m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/haiku/_src/module.py:306\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 306\u001b[0m   \u001b[39mreturn\u001b[39;00m bound_method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    308\u001b[0m ctx \u001b[39m=\u001b[39m MethodContext(module\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    309\u001b[0m                     method_name\u001b[39m=\u001b[39mmethod_name,\n\u001b[1;32m    310\u001b[0m                     orig_method\u001b[39m=\u001b[39mbound_method,\n\u001b[1;32m    311\u001b[0m                     orig_class\u001b[39m=\u001b[39morig_class)\n\u001b[1;32m    312\u001b[0m interceptor_stack_copy \u001b[39m=\u001b[39m interceptor_stack\u001b[39m.\u001b[39mclone()\n",
      "\u001b[0;31mTypeError\u001b[0m: CVAE.__call__() missing 1 required positional argument: 'cond'"
     ]
    }
   ],
   "source": [
    "params, saves = train(params, rng, model, xy_train, x_val, y_val, optimiser, optimiser_state,\n",
    "                      l2_reg_alpha=L2_REG_ALPHA, epochs=EPOCHS,\n",
    "                      loss_fn=loss_fn, compute_accuracy=compute_accuracy_regression,\n",
    "                      save_every=PRINT_EVERY, include_params_in_saves=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
