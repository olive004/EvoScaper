{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoscaper.scripts.init_from_hpos import init_from_hpos\n",
    "from evoscaper.utils.math import arrayise\n",
    "from evoscaper.utils.preprocess import make_datetime_str\n",
    "from evoscaper.utils.visualise import vis_sampled_histplot\n",
    "from bioreaction.misc.misc import load_json_as_dict\n",
    "from synbio_morpher.utils.results.analytics.timeseries import calculate_adaptation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_write_dir = os.path.join('data', '05_hidden_size', make_datetime_str())\n",
    "os.makedirs(top_write_dir, exist_ok=True)\n",
    "df_hpos = pd.DataFrame(load_json_as_dict(\n",
    "    'data/2025_01_13__16_31_26/df_hpos_main.json'))\n",
    "df_hpos['mi_mean'] = np.nan\n",
    "df_hpos.loc[df_hpos['run_successful'], 'mi_mean'] = df_hpos[df_hpos['run_successful']]['mutual_information_conditionality'].apply(np.array).apply(np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_r2(d):\n",
    "    plt.figure()\n",
    "    sns.lineplot(d, x='hidden_size', y='R2_test')\n",
    "    plt.title('R2 score on test set')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    sns.scatterplot(d, x='hidden_size', y='mi_mean')\n",
    "    plt.title('Mutual information between hidden z and conditional input')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def load_params(fn_saves):\n",
    "    saves_loaded = load_json_as_dict(fn_saves)\n",
    "    params = saves_loaded[str(list(saves_loaded.keys())[-1])]['params']\n",
    "    params = arrayise(params)\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_analytics(hpos):\n",
    "    analytics = load_json_as_dict(os.path.join(os.path.dirname(hpos['filename_saved_model']), 'analytics.json'))\n",
    "    analytics['sensitivity_wrt_species-6'] = np.array(analytics['sensitivity_wrt_species-6'])\n",
    "    analytics['precision_wrt_species-6'] = np.array(analytics['precision_wrt_species-6'])\n",
    "    for k in ['sensitivity_wrt_species-6', 'precision_wrt_species-6']:\n",
    "        # analytics[k] = np.where(np.isnan(\n",
    "        #     analytics[k]), 0, analytics[k])\n",
    "        analytics[f'Log {k.split(\"_\")[0]}'] = np.log10(analytics[k])\n",
    "    analytics['adaptation'] = calculate_adaptation(analytics['sensitivity_wrt_species-6'], analytics['precision_wrt_species-6'])\n",
    "\n",
    "    nbin = hpos['prep_y_categorical_n_bins']\n",
    "    analytics['Log sensitivity'] = analytics['Log sensitivity'].reshape(nbin, analytics['Log sensitivity'].shape[0]//nbin, -1)\n",
    "    return analytics\n",
    "\n",
    "    \n",
    "def plot_bars(analytics, y_datanormaliser, idx_output):\n",
    "    sampled_cond = np.array(list(y_datanormaliser.metadata['Log sensitivity']['category_map'].values()))\n",
    "    means_s = jax.vmap(lambda x, c: jnp.nanmean(x[..., idx_output]) - c)(analytics['Log sensitivity'], sampled_cond)\n",
    "    sns.barplot(means_s)\n",
    "    \n",
    "\n",
    "def vis_sampled_histplot(analytic, y_datanormaliser, idx_output: int, output_species,\n",
    "                         title: str, x_label: str, multiple='fill', show=False, f=sns.histplot, **kwargs):\n",
    "    if f == sns.histplot:\n",
    "        for k, v in zip(('element', 'bins', 'log_scale'), ('step', 20, [True, False])):\n",
    "            kwargs.setdefault(k, v)\n",
    "    category_array = np.array(sorted(y_datanormaliser.metadata[y_datanormaliser.cols_separate[0]][\"category_map\"].values())).repeat(\n",
    "        len(analytic)//len(y_datanormaliser.metadata[y_datanormaliser.cols_separate[0]][\"category_map\"]))\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    fig.subplots_adjust(wspace=0.6)\n",
    "    for i, output_specie in enumerate(output_species):\n",
    "        title_curr = title + f': species {output_specie}'\n",
    "        df_s = pd.DataFrame(columns=[x_label, 'VAE conditional input'],\n",
    "                            data=np.concatenate([analytic[:, idx_output][:, None], category_array[:, None]], axis=-1))\n",
    "        df_s['VAE conditional input'] = df_s['VAE conditional input'].astype(\n",
    "            float).apply(lambda x: f'{x:.2f}')\n",
    "        ax = plt.subplot(1, 2, i+1)\n",
    "        f(df_s, x=x_label,\n",
    "          multiple=multiple, hue='VAE conditional input', palette='viridis',\n",
    "          **kwargs)\n",
    "\n",
    "        sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "        plt.title(title_curr)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def run_hpos(hpos):\n",
    "    (\n",
    "        rng, rng_model, rng_dataset,\n",
    "        config_norm_x, config_norm_y, config_filter, config_optimisation, config_dataset, config_training, config_model,\n",
    "        data, x_cols, df,\n",
    "        x, cond, y, x_train, cond_train, y_train, x_val, cond_val, y_val,\n",
    "        total_ds, n_batches, BATCH_SIZE, x_datanormaliser, x_methods_preprocessing, y_datanormaliser, y_methods_preprocessing,\n",
    "        _, \n",
    "        encoder, decoder, model, h2mu, h2logvar, reparam\n",
    "    ) = init_from_hpos(hpos)\n",
    "\n",
    "\n",
    "    params = load_params(hpos['filename_saved_model'])\n",
    "\n",
    "    h_all = encoder(params, rng, np.concatenate([x, cond], axis=-1))\n",
    "    h_all = h_all.reshape(np.prod(h_all.shape[:-1]), -1)\n",
    "    cond_rev_all = y_datanormaliser.create_chain_preprocessor_inverse(y_methods_preprocessing)(cond, col=config_dataset.objective_col[0]).reshape(np.prod(cond.shape[:-1]), -1).squeeze()\n",
    "    x_rev_all = x_datanormaliser.create_chain_preprocessor_inverse(x_methods_preprocessing)(x).reshape(np.prod(x.shape[:-1]), -1).squeeze()\n",
    "    \n",
    "    d = df_hpos[df_hpos['run_successful']]\n",
    "    vis_r2(d)\n",
    "    \n",
    "    idx_output = -1\n",
    "    analytics = get_analytics(hpos)\n",
    "    plot_bars(analytics, y_datanormaliser, idx_output)\n",
    "\n",
    "    vis_sampled_histplot(analytics['sensitivity_wrt_species-6'], y_datanormaliser, idx_output, config_dataset.output_species,\n",
    "                        title=f'Sensitivity of generated circuits', x_label=f'Log10 of sensitivity to signal {config_dataset.signal_species[0]}', multiple='layer', show=True,\n",
    "                        f=sns.kdeplot, log_scale=[True, False], fill=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hpos \u001b[38;5;129;01min\u001b[39;00m df_hpos:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_successful\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     run_hpos(hpos)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "for hpos in df_hpos:\n",
    "    if not hpos['run_successful']:\n",
    "        continue\n",
    "    \n",
    "    run_hpos(hpos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
