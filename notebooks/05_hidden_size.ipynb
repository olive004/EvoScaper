{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoscaper.scripts.init_from_hpos import init_from_hpos\n",
    "from evoscaper.utils.math import arrayise\n",
    "from evoscaper.utils.preprocess import make_datetime_str\n",
    "from evoscaper.utils.visualise import vis_sampled_histplot\n",
    "from bioreaction.misc.misc import load_json_as_dict\n",
    "from synbio_morpher.utils.results.analytics.timeseries import calculate_adaptation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_write_dir = os.path.join('data', '05_hidden_size', make_datetime_str())\n",
    "os.makedirs(top_write_dir, exist_ok=True)\n",
    "df_hpos = pd.DataFrame(load_json_as_dict(\n",
    "    'data/2025_01_13__16_31_26/df_hpos_main.json'))\n",
    "df_hpos['mi_mean'] = np.nan\n",
    "df_hpos.loc[df_hpos['run_successful'], 'mi_mean'] = df_hpos[df_hpos['run_successful']]['mutual_information_conditionality'].apply(np.array).apply(np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_r2(d, save_path):\n",
    "    plt.figure()\n",
    "    sns.lineplot(d, x='hidden_size', y='R2_test')\n",
    "    plt.title('R2 score on test set')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def vis_mi(d, save_path):\n",
    "    plt.figure()\n",
    "    sns.scatterplot(d, x='hidden_size', y='mi_mean')\n",
    "    plt.title('Mutual information between hidden z and conditional input')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def load_params(fn_saves):\n",
    "    saves_loaded = load_json_as_dict(fn_saves)\n",
    "    params = saves_loaded[str(list(saves_loaded.keys())[-1])]['params']\n",
    "    params = arrayise(params)\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_analytics(hpos):\n",
    "    analytics = load_json_as_dict(os.path.join(\n",
    "        os.path.dirname(hpos['filename_saved_model']), 'analytics.json'))\n",
    "    analytics['sensitivity_wrt_species-6'] = np.array(\n",
    "        analytics['sensitivity_wrt_species-6'])\n",
    "    analytics['precision_wrt_species-6'] = np.array(\n",
    "        analytics['precision_wrt_species-6'])\n",
    "    for k in ['sensitivity_wrt_species-6', 'precision_wrt_species-6']:\n",
    "        # analytics[k] = np.where(np.isnan(\n",
    "        #     analytics[k]), 0, analytics[k])\n",
    "        analytics[f'Log {k.split(\"_\")[0]}'] = np.log10(analytics[k])\n",
    "    analytics['adaptation'] = calculate_adaptation(\n",
    "        analytics['sensitivity_wrt_species-6'], analytics['precision_wrt_species-6'])\n",
    "\n",
    "    nbin = hpos['prep_y_categorical_n_bins']\n",
    "    analytics['Log sensitivity'] = analytics['Log sensitivity'].reshape(\n",
    "        nbin, analytics['Log sensitivity'].shape[0]//nbin, -1)\n",
    "    return analytics\n",
    "\n",
    "\n",
    "def plot_bars(analytics, y_datanormaliser, idx_output, save_path):\n",
    "    sampled_cond = np.array(\n",
    "        list(y_datanormaliser.metadata['Log sensitivity']['category_map'].values()))\n",
    "    means_s = jax.vmap(lambda x, c: jnp.nanmean(\n",
    "        x[..., idx_output]) - c)(analytics['Log sensitivity'], sampled_cond)\n",
    "    sns.barplot(means_s, palette='viridis')\n",
    "    plt.xlabel('Condition input')\n",
    "    plt.ylabel('Difference in sensitivity')\n",
    "    plt.title('Difference in sensitivity of target prompt and mean actual')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def vis_sampled_histplot(analytic, y_datanormaliser, idx_output: int, output_species,\n",
    "                         title: str, x_label: str, multiple='fill', show=False, f=sns.histplot, save_path=None, **kwargs):\n",
    "    if f == sns.histplot:\n",
    "        for k, v in zip(('element', 'bins', 'log_scale'), ('step', 20, [True, False])):\n",
    "            kwargs.setdefault(k, v)\n",
    "    category_array = np.array(sorted(y_datanormaliser.metadata[y_datanormaliser.cols_separate[0]][\"category_map\"].values())).repeat(\n",
    "        len(analytic)//len(y_datanormaliser.metadata[y_datanormaliser.cols_separate[0]][\"category_map\"]))\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    fig.subplots_adjust(wspace=0.6)\n",
    "    for i, output_specie in enumerate(output_species):\n",
    "        title_curr = title + f': species {output_specie}'\n",
    "        df_s = pd.DataFrame(columns=[x_label, 'VAE conditional input'],\n",
    "                            data=np.concatenate([analytic[:, idx_output][:, None], category_array[:, None]], axis=-1))\n",
    "        df_s['VAE conditional input'] = df_s['VAE conditional input'].astype(\n",
    "            float).apply(lambda x: f'{x:.2f}')\n",
    "        ax = plt.subplot(1, 2, i+1)\n",
    "        f(df_s, x=x_label,\n",
    "          multiple=multiple, hue='VAE conditional input', palette='viridis',\n",
    "          **kwargs)\n",
    "\n",
    "        sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "        plt.title(title_curr)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def run_hpos(hpos, dir_save):\n",
    "    (\n",
    "        rng, rng_model, rng_dataset,\n",
    "        config_norm_x, config_norm_y, config_filter, config_optimisation, config_dataset, config_training, config_model,\n",
    "        data, x_cols, df,\n",
    "        x, cond, y, x_train, cond_train, y_train, x_val, cond_val, y_val,\n",
    "        total_ds, n_batches, BATCH_SIZE, x_datanormaliser, x_methods_preprocessing, y_datanormaliser, y_methods_preprocessing,\n",
    "        _,\n",
    "        encoder, decoder, model, h2mu, h2logvar, reparam\n",
    "    ) = init_from_hpos(hpos)\n",
    "\n",
    "    params = load_params(hpos['filename_saved_model'])\n",
    "\n",
    "    h_all = encoder(params, rng, np.concatenate([x, cond], axis=-1))\n",
    "    h_all = h_all.reshape(np.prod(h_all.shape[:-1]), -1)\n",
    "    cond_rev_all = y_datanormaliser.create_chain_preprocessor_inverse(y_methods_preprocessing)(\n",
    "        cond, col=config_dataset.objective_col[0]).reshape(np.prod(cond.shape[:-1]), -1).squeeze()\n",
    "    x_rev_all = x_datanormaliser.create_chain_preprocessor_inverse(\n",
    "        x_methods_preprocessing)(x).reshape(np.prod(x.shape[:-1]), -1).squeeze()\n",
    "\n",
    "    idx_output = -1\n",
    "    analytics = get_analytics(hpos)\n",
    "    plot_bars(analytics, y_datanormaliser, idx_output,\n",
    "              os.path.join(dir_save, 'bars.png'))\n",
    "\n",
    "    vis_sampled_histplot(analytics['sensitivity_wrt_species-6'], y_datanormaliser, idx_output, config_dataset.output_species,\n",
    "                         title=f'Sensitivity of generated circuits', x_label=f'Log10 of sensitivity to signal {config_dataset.signal_species[0]}', multiple='layer', show=False,\n",
    "                         f=sns.kdeplot, log_scale=[True, False], fill=False, save_path=os.path.join(dir_save, f'kde.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(top_write_dir, \u001b[38;5;28mstr\u001b[39m(i)), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrun_hpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_write_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 94\u001b[0m, in \u001b[0;36mrun_hpos\u001b[0;34m(hpos, dir_save)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_hpos\u001b[39m(hpos, dir_save):\n\u001b[1;32m     86\u001b[0m     (\n\u001b[1;32m     87\u001b[0m         rng, rng_model, rng_dataset,\n\u001b[1;32m     88\u001b[0m         config_norm_x, config_norm_y, config_filter, config_optimisation, config_dataset, config_training, config_model,\n\u001b[1;32m     89\u001b[0m         data, x_cols, df,\n\u001b[1;32m     90\u001b[0m         x, cond, y, x_train, cond_train, y_train, x_val, cond_val, y_val,\n\u001b[1;32m     91\u001b[0m         total_ds, n_batches, BATCH_SIZE, x_datanormaliser, x_methods_preprocessing, y_datanormaliser, y_methods_preprocessing,\n\u001b[1;32m     92\u001b[0m         _,\n\u001b[1;32m     93\u001b[0m         encoder, decoder, model, h2mu, h2logvar, reparam\n\u001b[0;32m---> 94\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43minit_from_hpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     params \u001b[38;5;241m=\u001b[39m load_params(hpos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename_saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     98\u001b[0m     h_all \u001b[38;5;241m=\u001b[39m encoder(params, rng, np\u001b[38;5;241m.\u001b[39mconcatenate([x, cond], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/init_from_hpos.py:49\u001b[0m, in \u001b[0;36minit_from_hpos\u001b[0;34m(hpos)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Configs + data\u001b[39;00m\n\u001b[1;32m     47\u001b[0m (config_norm_x, config_norm_y, config_filter, config_optimisation,\n\u001b[1;32m     48\u001b[0m  config_dataset, config_training) \u001b[38;5;241m=\u001b[39m make_configs_initial(hpos)\n\u001b[0;32m---> 49\u001b[0m data, x_cols \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Init data\u001b[39;00m\n\u001b[1;32m     52\u001b[0m (df, x, cond, total_ds, n_batches, BATCH_SIZE, x_datanormaliser, x_methods_preprocessing,\n\u001b[1;32m     53\u001b[0m  y_datanormaliser, y_methods_preprocessing) \u001b[38;5;241m=\u001b[39m init_data(\n\u001b[1;32m     54\u001b[0m      data, x_cols, config_dataset\u001b[38;5;241m.\u001b[39mobjective_col, config_dataset\u001b[38;5;241m.\u001b[39moutput_species, config_dataset\u001b[38;5;241m.\u001b[39mtotal_ds_max,\n\u001b[1;32m     55\u001b[0m      config_training\u001b[38;5;241m.\u001b[39mbatch_size, rng_dataset, config_norm_x, config_norm_y, config_filter)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/init_from_hpos.py:18\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(config_dataset)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(config_dataset: DatasetConfig):\n\u001b[0;32m---> 18\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilenames_train_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     X_COLS \u001b[38;5;241m=\u001b[39m make_xcols(data, config_dataset\u001b[38;5;241m.\u001b[39mx_type,\n\u001b[1;32m     20\u001b[0m                         config_dataset\u001b[38;5;241m.\u001b[39minclude_diffs)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, X_COLS\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[0;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[0;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[1;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[1;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[0;32m-> 2144\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py:2304\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[1;32m   2302\u001b[0m     new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m-> 2304\u001b[0m     bp \u001b[38;5;241m=\u001b[39m \u001b[43mBlockPlacement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [new_block_2d(new_values, placement\u001b[38;5;241m=\u001b[39mbp)], \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;66;03m# can't consolidate --> no merge\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "d = df_hpos[df_hpos['run_successful']]\n",
    "vis_r2(d, save_path=os.path.join(top_write_dir, 'r2.png'))\n",
    "vis_mi(d, save_path=os.path.join(top_write_dir, 'mi.png'))\n",
    "\n",
    "for i, hpos in df_hpos.iterrows():\n",
    "    if not hpos['run_successful'] or not(os.path.exists(os.path.join(os.path.dirname(hpos['filename_saved_model']), 'analytics.json'))):\n",
    "        continue\n",
    "    \n",
    "    os.makedirs(os.path.join(top_write_dir, str(i)), exist_ok=True)\n",
    "    run_hpos(hpos, dir_save=os.path.join(top_write_dir, str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
