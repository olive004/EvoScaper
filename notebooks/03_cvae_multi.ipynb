{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VAE models systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from evoscaper.scripts.cvae_scan import main as cvae_scan\n",
    "from evoscaper.utils.preprocess import make_datetime_str\n",
    "from synbio_morpher.utils.data.data_format_tools.common import write_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of all VAE model training settings\n",
    "\n",
    "Parameters for:\n",
    "- Biological dataset generation\n",
    "- Training data\n",
    "    - Input\n",
    "    - Output \n",
    "- Model architecture\n",
    "- Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "hpos_architecture = {\n",
    "    'seed_arch': 1,\n",
    "    'hidden_size': 16,\n",
    "    'enc_ls': 32,\n",
    "    'dec_ls': 32,\n",
    "    'num_enc_layers': 2,\n",
    "    'num_dec_layers': 2,\n",
    "    'factor_expanding_ls': 1,\n",
    "    'factor_contracting_ls': 1,\n",
    "    'model': 'CVAE',\n",
    "    'use_sigmoid_decoder': False,\n",
    "    'enc_init': 'HeNormal',\n",
    "    'dec_init': 'HeNormal',\n",
    "    'init_model_with_random': True,\n",
    "    'activation': 'leaky_relu',\n",
    "}\n",
    "\n",
    "hpos_training = {\n",
    "    'seed_train': 1,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 3000,\n",
    "    'patience': 500,\n",
    "    'learning_rate': 1e-2,\n",
    "    'loss_func': 'mse',\n",
    "    'accuracy_func': 'accuracy_regression',\n",
    "    'use_dropout': False,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_l2_reg': False,\n",
    "    'l2_reg_alpha': 5e-2,\n",
    "    'use_kl_div': True,\n",
    "    # inspired by https://github.com/elttaes/VAE-MNIST-Haiku-Jax/blob/main/cVAE_mnist.ipynb\n",
    "    'kl_weight': 2.5e-4,\n",
    "    'use_grad_clipping': False\n",
    "}\n",
    "hpos_training['print_every'] = hpos_training['epochs'] // 50\n",
    "\n",
    "hpos_optimization = {\n",
    "    'seed_opt': 1,\n",
    "    'opt_method': 'adam',\n",
    "    'opt_min_lr': 1e-6,\n",
    "    'opt_min_delta': 1e-4,\n",
    "    'learning_rate_sched': 'cosine_decay',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 20,\n",
    "}\n",
    "\n",
    "hpos_dataset = {\n",
    "    'seed_dataset': 1,\n",
    "    'include_diffs': False,\n",
    "    'objective_col': ('Log sensitivity',),\n",
    "    'output_species': ('RNA_2',),\n",
    "    'signal_species': ('RNA_0',),\n",
    "    'filenames_train_config': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config.json',\n",
    "    'filenames_train_table': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv',\n",
    "    'filenames_verify_config': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json',\n",
    "    'filenames_verify_table': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv',\n",
    "    'use_test_data': False,\n",
    "    # 'total_ds': None,   # TO BE RECORDED\n",
    "    'total_ds_max': 5e6,\n",
    "    'train_split': 0.8,\n",
    "    'x_type': 'energies',\n",
    "    # XY filtering:\n",
    "    'filt_x_nans': True,\n",
    "    'filt_y_nans': True,\n",
    "    'filt_sensitivity_nans': True,\n",
    "    'filt_precision_nans': True,\n",
    "    'filt_n_same_x_max': 1,\n",
    "    'filt_n_same_x_max_bins': 50,\n",
    "    # XY preprocessing:\n",
    "    'prep_x_standardise': False,\n",
    "    'prep_y_standardise': False,\n",
    "    'prep_x_min_max': True,\n",
    "    'prep_y_min_max': True,\n",
    "    'prep_x_robust_scaling': True,\n",
    "    'prep_y_robust_scaling': True,\n",
    "    'prep_x_logscale': False,\n",
    "    'prep_y_logscale': False,\n",
    "    'prep_x_categorical': False,\n",
    "    'prep_y_categorical': True,\n",
    "    'prep_x_categorical_onehot': False,\n",
    "    'prep_y_categorical_onehot': True,\n",
    "    'prep_x_categorical_n_bins': 10,\n",
    "    'prep_y_categorical_n_bins': 10,\n",
    "    'prep_x_categorical_method': 'quantile',\n",
    "    'prep_y_categorical_method': 'quantile',\n",
    "    'prep_x_negative': True,\n",
    "    'prep_y_negative': False\n",
    "}\n",
    "\n",
    "hpos_biological = {\n",
    "    'n_species': 3,\n",
    "    'sequence_length': 20,\n",
    "    'signal_function': 'step_function',\n",
    "    'signal_target': 2,\n",
    "    'starting_copynumbers_input': 200,\n",
    "    'starting_copynumbers_output': 200,\n",
    "    'starting_copynumbers_other': 200,\n",
    "    'association_binding_rate': 1000000,\n",
    "    'include_prod_deg': False,\n",
    "}\n",
    "\n",
    "hpos_eval = {\n",
    "    'eval_n_to_sample': 1e3\n",
    "}\n",
    "\n",
    "info_to_be_recorded = {\n",
    "    'filename_saved_model': 'TO_BE_RECORDED',\n",
    "    'total_ds': 'TO_BE_RECORDED',\n",
    "    'n_batches': 'TO_BE_RECORDED',\n",
    "    'R2_train': 'TO_BE_RECORDED',\n",
    "    'R2_test': 'TO_BE_RECORDED',\n",
    "    'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
    "    'n_layers_enc': 'TO_BE_RECORDED',\n",
    "    'n_layers_dec': 'TO_BE_RECORDED',\n",
    "    'run_successful': 'TO_BE_RECORDED',\n",
    "    'info_early_stop': 'TO_BE_RECORDED',\n",
    "    'error_msg': 'TO_BE_RECORDED',\n",
    "}\n",
    "\n",
    "hpos_all = {}\n",
    "for d in [hpos_architecture, hpos_training, hpos_optimization, hpos_dataset, hpos_eval, info_to_be_recorded]:\n",
    "    hpos_all.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_ls</th>\n",
       "      <th>dec_ls</th>\n",
       "      <th>num_enc_layers</th>\n",
       "      <th>num_dec_layers</th>\n",
       "      <th>factor_expanding_ls</th>\n",
       "      <th>factor_contracting_ls</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>...</th>\n",
       "      <th>total_ds</th>\n",
       "      <th>n_batches</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>mutual_information_conditionality</th>\n",
       "      <th>n_layers_enc</th>\n",
       "      <th>n_layers_dec</th>\n",
       "      <th>run_successful</th>\n",
       "      <th>info_early_stop</th>\n",
       "      <th>error_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size enc_ls dec_ls num_enc_layers num_dec_layers  \\\n",
       "0         1          16     32     32              2              2   \n",
       "\n",
       "  factor_expanding_ls factor_contracting_ls model use_sigmoid_decoder  ...  \\\n",
       "0                   1                     1  CVAE               False  ...   \n",
       "\n",
       "         total_ds       n_batches        R2_train         R2_test  \\\n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "  mutual_information_conditionality    n_layers_enc    n_layers_dec  \\\n",
       "0                    TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "   run_successful info_early_stop       error_msg  \n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  \n",
       "\n",
       "[1 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos = pd.DataFrame.from_dict(hpos_all, orient='index').T\n",
    "assert df_hpos.columns.duplicated().sum() == 0, 'Change some column names, there are duplicates'\n",
    "basic_setting = df_hpos.copy()\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ../data/raw/summarise_simulation/2024_12_05_21...\n",
       "Name: filenames_train_config, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k, v in hpos_all.items():\n",
    "#     if type(v) == tuple:\n",
    "#         print(k, v)\n",
    "#         df_hpos[k] = df_hpos[k].apply(lambda x: tuple(x))\n",
    "df_hpos['filenames_train_config']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpos_to_vary_from_og = {\n",
    "    'seed_arch': [1, 2, 3, 4, 5],\n",
    "    'num_enc_layers': [4, 5],\n",
    "}\n",
    "hpos_to_vary_from_og2 = {\n",
    "    'objective_col': [('adaptation',), ('Log sensitivity',), ('Log sensitivity', 'Log precision')],\n",
    "}\n",
    "hpos_to_vary_from_og3 = {\n",
    "    'hidden_size': list(range(1, 33)),\n",
    "}\n",
    "hpos_to_vary_together = {\n",
    "    'hidden_size': [1, 2, 4, 8, 16, 32, 64, 128],\n",
    "    'enc_ls': [4, 8, 16, 32, 64],\n",
    "    'num_enc_layers': [1, 2, 3],\n",
    "    'factor_expanding_ls': [1, 2, 3],\n",
    "}\n",
    "hpos_to_vary_together2 = {\n",
    "    'hidden_size': [16, 32, 64],\n",
    "    'objective_col': [('adaptation',), ('Log sensitivity',)],\n",
    "    'x_type': ['energies', 'binding_rates_dissociation'],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'use_l2_reg': [True],\n",
    "    'l2_reg_alpha': [0, 1e-2, 1e-3, 1e-4],\n",
    "    'kl_weight': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "df_hpos.loc[df_hpos['objective_col'] == 'sensitivity_wrt_species-6', 'prep_y_logscale'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_equal(df):\n",
    "    pairs = {\n",
    "        'enc_ls': 'dec_ls',\n",
    "        'num_enc_layers': 'num_dec_layers',\n",
    "        'factor_expanding_ls': 'factor_contracting_ls',\n",
    "    }\n",
    "    for k1, k2 in pairs.items():\n",
    "        if k1 in df.columns and k2 in df.columns:\n",
    "            df[k2] = df[k1]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting):\n",
    "    keys_vary_together = sorted(hpos_to_vary_together.keys())\n",
    "    for v in itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]):\n",
    "        curr = basic_setting.assign(\n",
    "            **{h: vv for h, vv in zip(keys_vary_together, v)})\n",
    "        df_hpos = pd.concat([df_hpos, curr], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def add_single_hpos(df_hpos, hpos_to_vary_from_og, basic_setting):\n",
    "    for h, v in hpos_to_vary_from_og.items():\n",
    "        try:\n",
    "            df_hpos = pd.concat(\n",
    "                [df_hpos] + [basic_setting.assign(**{h: vv}) for vv in v], ignore_index=True)\n",
    "        except ValueError:\n",
    "            for vv in v:\n",
    "                b = basic_setting.copy()\n",
    "                b.loc[0, h] = vv\n",
    "                df_hpos = pd.concat([df_hpos, b], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def postproc(df_hpos):\n",
    "    df_hpos = keep_equal(df_hpos)\n",
    "    df_hpos.loc[df_hpos['x_type'] ==\n",
    "                'binding_rates_dissociation', 'prep_x_negative'] = False\n",
    "    df_hpos = df_hpos.drop_duplicates().reset_index(drop=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "df_hpos = add_single_hpos(df_hpos, hpos_to_vary_from_og3, basic_setting)\n",
    "df_hpos = add_single_hpos(df_hpos, hpos_to_vary_from_og2, basic_setting)\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting)\n",
    "df_hpos = add_combinatorial_keys(\n",
    "    df_hpos, hpos_to_vary_together2, basic_setting)\n",
    "df_hpos = add_single_hpos(df_hpos, hpos_to_vary_from_og, basic_setting)\n",
    "df_hpos = postproc(df_hpos)\n",
    "\n",
    "# Reorder columns\n",
    "cols_priority = list(set(list(hpos_to_vary_from_og.keys(\n",
    ")) + list(hpos_to_vary_together.keys()) + list(hpos_to_vary_together2.keys())))\n",
    "df_hpos = df_hpos[cols_priority +\n",
    "                  [c for c in df_hpos.columns if c not in cols_priority]]\n",
    "\n",
    "df_hpos.reset_index(drop=True)\n",
    "len(df_hpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use table to create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = '../data/raw/summarise_simulation/2024_11_21_144918/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'\n",
    "# data = pd.read_csv(fn).iloc[:100]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xla_bridge.py:backends():900: Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA INFO\n",
      "xla_bridge.py:backends():900: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory INFO\n",
      "train.py:train():160: Epoch 0 / 3000 -\t\t Train loss: 0.0850759968161583\tVal loss: 0.0551363080739975\tVal accuracy: 0.29670390486717224 INFO\n",
      "train.py:train():160: Epoch 10 / 3000 -\t\t Train loss: 0.030824551358819008\tVal loss: 0.03185836225748062\tVal accuracy: 0.48193779587745667 INFO\n",
      "train.py:train():160: Epoch 20 / 3000 -\t\t Train loss: 0.027099063619971275\tVal loss: 0.02640525996685028\tVal accuracy: 0.5190346240997314 INFO\n",
      "train.py:train():160: Epoch 30 / 3000 -\t\t Train loss: 0.027168527245521545\tVal loss: 0.026873325929045677\tVal accuracy: 0.5115935802459717 INFO\n",
      "train.py:train():160: Epoch 40 / 3000 -\t\t Train loss: 0.024896027520298958\tVal loss: 0.02483229525387287\tVal accuracy: 0.5371261239051819 INFO\n",
      "train.py:train():160: Epoch 50 / 3000 -\t\t Train loss: 0.023048004135489464\tVal loss: 0.02374468557536602\tVal accuracy: 0.5354818105697632 INFO\n",
      "train.py:train():160: Epoch 60 / 3000 -\t\t Train loss: 0.02287459373474121\tVal loss: 0.022974994033575058\tVal accuracy: 0.5591738820075989 INFO\n",
      "train.py:train():160: Epoch 70 / 3000 -\t\t Train loss: 0.022471172735095024\tVal loss: 0.022347992286086082\tVal accuracy: 0.5596371293067932 INFO\n",
      "train.py:train():160: Epoch 80 / 3000 -\t\t Train loss: 0.022000161930918694\tVal loss: 0.021839499473571777\tVal accuracy: 0.5544663667678833 INFO\n",
      "train.py:train():160: Epoch 90 / 3000 -\t\t Train loss: 0.021534474566578865\tVal loss: 0.02140284702181816\tVal accuracy: 0.5607555508613586 INFO\n",
      "train.py:train():160: Epoch 100 / 3000 -\t\t Train loss: 0.021066641435027122\tVal loss: 0.020928042009472847\tVal accuracy: 0.5551883578300476 INFO\n",
      "train.py:train():160: Epoch 110 / 3000 -\t\t Train loss: 0.021222254261374474\tVal loss: 0.0209229476749897\tVal accuracy: 0.5624624490737915 INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.py:train():160: Epoch 120 / 3000 -\t\t Train loss: 0.02116556093096733\tVal loss: 0.0206432081758976\tVal accuracy: 0.5662518739700317 INFO\n",
      "train.py:train():160: Epoch 130 / 3000 -\t\t Train loss: 0.020534861832857132\tVal loss: 0.020283784717321396\tVal accuracy: 0.5772486329078674 INFO\n",
      "train.py:train():160: Epoch 140 / 3000 -\t\t Train loss: 0.021957850083708763\tVal loss: 0.02206609956920147\tVal accuracy: 0.5719943642616272 INFO\n",
      "train.py:train():160: Epoch 150 / 3000 -\t\t Train loss: 0.02367209456861019\tVal loss: 0.022873874753713608\tVal accuracy: 0.5479475855827332 INFO\n",
      "train.py:train():160: Epoch 160 / 3000 -\t\t Train loss: 0.02248680219054222\tVal loss: 0.02300904132425785\tVal accuracy: 0.5405356884002686 INFO\n",
      "train.py:train():160: Epoch 170 / 3000 -\t\t Train loss: 0.0221996009349823\tVal loss: 0.022671859711408615\tVal accuracy: 0.55126953125 INFO\n",
      "train.py:train():160: Epoch 180 / 3000 -\t\t Train loss: 0.02576666884124279\tVal loss: 0.025834882631897926\tVal accuracy: 0.5406650900840759 INFO\n",
      "train.py:train():160: Epoch 190 / 3000 -\t\t Train loss: 0.02427845075726509\tVal loss: 0.02453066222369671\tVal accuracy: 0.5399848222732544 INFO\n",
      "train.py:train():160: Epoch 200 / 3000 -\t\t Train loss: 0.02353961579501629\tVal loss: 0.023312421515583992\tVal accuracy: 0.558518648147583 INFO\n",
      "train.py:train():160: Epoch 210 / 3000 -\t\t Train loss: 0.023679610341787338\tVal loss: 0.022829659283161163\tVal accuracy: 0.5542243123054504 INFO\n",
      "train.py:train():160: Epoch 220 / 3000 -\t\t Train loss: 0.022940002381801605\tVal loss: 0.02288524992763996\tVal accuracy: 0.5489032864570618 INFO\n",
      "E0115 14:12:38.769202 2490921 pjrt_stream_executor_client.cc:2985] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Failed to allocate request for 4.88MiB (5111808B) on device ordinal 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RESOURCE_EXHAUSTED: Failed to allocate request for 4.88MiB (5111808B) on device ordinal 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m top_write_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(top_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvae_scan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhpo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhpos[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m hpos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_grad_clipping\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m hpos \u001b[38;5;241m=\u001b[39m \u001b[43mcvae_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_write_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_write_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     hpos.loc['run_successful'] = False\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     hpos.loc['error_msg'] = 'sys exit'\u001b[39;00m\n\u001b[1;32m     32\u001b[0m df_hpos_main\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(hpos) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(hpos) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m hpos\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/cvae_scan.py:168\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(hpos, top_write_dir)\u001b[0m\n\u001b[1;32m    164\u001b[0m loss_fn, compute_accuracy \u001b[38;5;241m=\u001b[39m make_loss(\n\u001b[1;32m    165\u001b[0m     config_training\u001b[38;5;241m.\u001b[39mloss_func, config_training\u001b[38;5;241m.\u001b[39muse_l2_reg, config_training\u001b[38;5;241m.\u001b[39muse_kl_div, config_training\u001b[38;5;241m.\u001b[39mkl_weight)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m params, saves, save_path, r2_train, info_early_stop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mconfig_optimisation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_hpo_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_write_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_write_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Test & Visualise\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dataset\u001b[38;5;241m.\u001b[39muse_test_data:\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/cvae_scan.py:56\u001b[0m, in \u001b[0;36mtrain_full\u001b[0;34m(params, rng, model, x_train, cond_train, y_train, x_val, cond_val, y_val, config_optimisation, config_training, loss_fn, compute_accuracy, n_batches, task, top_write_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m optimiser, optimiser_state \u001b[38;5;241m=\u001b[39m init_optimiser(params, config_optimisation\u001b[38;5;241m.\u001b[39mlearning_rate_sched, config_training\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m     53\u001b[0m                                             config_training\u001b[38;5;241m.\u001b[39mepochs, config_training\u001b[38;5;241m.\u001b[39ml2_reg_alpha, config_optimisation\u001b[38;5;241m.\u001b[39muse_warmup,\n\u001b[1;32m     54\u001b[0m                                             config_optimisation\u001b[38;5;241m.\u001b[39mwarmup_epochs, n_batches, config_optimisation\u001b[38;5;241m.\u001b[39mopt_method)\n\u001b[1;32m     55\u001b[0m tstart \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 56\u001b[0m params, saves, info_early_stop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43muse_l2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_l2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2_reg_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_params_in_all_saves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43muse_grad_clipping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_grad_clipping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining complete:\u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m tstart)\n\u001b[1;32m     67\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m model(params, rng, x_train, cond\u001b[38;5;241m=\u001b[39mcond_train)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/utils/train.py:153\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, rng, model, x_train, cond_train, y_train, x_val, cond_val, y_val, optimiser, optimiser_state, use_l2_reg, l2_reg_alpha, epochs, loss_fn, compute_accuracy, save_every, include_params_in_all_saves, use_grad_clipping, patience)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (params, optimiser_state), (params, grads, train_loss, val_loss, val_acc, aux_loss, aux_val_loss)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[1;32m    152\u001b[0m (params, optimiser_state), (params_stack, grads, train_loss,\n\u001b[0;32m--> 153\u001b[0m                             val_loss, val_acc, aux_loss, aux_val_loss) \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmod(epoch, save_every) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/workdir/src/evoscaper/utils/train.py:146\u001b[0m, in \u001b[0;36mtrain.<locals>.f\u001b[0;34m(carry, _)\u001b[0m\n\u001b[1;32m    141\u001b[0m params, optimiser_state \u001b[38;5;241m=\u001b[39m carry[\u001b[38;5;241m0\u001b[39m], carry[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    143\u001b[0m params, optimiser_state, train_loss, grads, aux_loss \u001b[38;5;241m=\u001b[39m run_batches(\n\u001b[1;32m    144\u001b[0m     params, model, rng, x_train, y_train, cond_train, use_l2_reg, l2_reg_alpha, optimiser, optimiser_state, loss_fn, use_grad_clipping)\n\u001b[0;32m--> 146\u001b[0m val_acc, val_loss, aux_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_l2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (params, optimiser_state), (params, grads, train_loss, val_loss, val_acc, aux_loss, aux_val_loss)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/utils/train.py:28\u001b[0m, in \u001b[0;36meval_step\u001b[0;34m(params, rng, model, x, y, cond, use_l2_reg, l2_reg_alpha, loss_fn, compute_accuracy)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_step\u001b[39m(params, rng, model, x, y, cond, use_l2_reg, l2_reg_alpha, loss_fn, compute_accuracy):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return the average of loss and accuracy on validation data \"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     loss, aux \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_l2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_l2_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[43ml2_reg_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_reg_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     pred_y \u001b[38;5;241m=\u001b[39m model(params, rng, x, cond\u001b[38;5;241m=\u001b[39mcond)\n\u001b[1;32m     31\u001b[0m     acc \u001b[38;5;241m=\u001b[39m compute_accuracy(pred_y, y)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/model/loss.py:44\u001b[0m, in \u001b[0;36mloss_wrapper\u001b[0;34m(params, rng, model, x, y, loss_f, use_l2_reg, l2_reg_alpha, use_kl_div, kl_weight, **model_call_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_wrapper\u001b[39m(\n\u001b[1;32m     35\u001b[0m     params, rng, model,\n\u001b[1;32m     36\u001b[0m     x: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch n_interactions\u001b[39m\u001b[38;5;124m\"\u001b[39m], y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_call_kwargs\n\u001b[1;32m     42\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 44\u001b[0m     pred_y, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_muvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_call_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_f(y, pred_y)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Add L2 loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/multi_transform.py:251\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_without_state.<locals>.apply_fn\u001b[0;34m(params, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fn\u001b[39m(params: hk\u001b[38;5;241m.\u001b[39mParams, rng, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 251\u001b[0m   out, state \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` then use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`hk.multi_transform_with_state`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/transform.py:456\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(params\u001b[38;5;241m=\u001b[39mparams, state\u001b[38;5;241m=\u001b[39mstate, rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/multi_transform.py:152\u001b[0m, in \u001b[0;36mmulti_transform_with_state.<locals>.apply_fn_i.<locals>.apply_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the transformed function at the given inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_leaves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/workdir/src/evoscaper/model/vae.py:74\u001b[0m, in \u001b[0;36mCVAE.__call__\u001b[0;34m(self, x, cond, deterministic, inference, return_muvar, logging)\u001b[0m\n\u001b[1;32m     71\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, logvar, hk\u001b[38;5;241m.\u001b[39mnext_rng_key(), deterministic)\n\u001b[1;32m     72\u001b[0m z_cond \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mconcatenate([z, cond], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_muvar:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y, mu, logvar\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/workdir/src/evoscaper/model/mlp.py:63\u001b[0m, in \u001b[0;36mMLPWithActivation.__call__\u001b[0;34m(self, inputs, rng, inference, logging)\u001b[0m\n\u001b[1;32m     59\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(layer) \u001b[38;5;241m==\u001b[39m eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout \u001b[38;5;28;01melse\u001b[39;00m {\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m: inference, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m: rng}\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout not implemented\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     65\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/basic.py:181\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, inputs, precision)\u001b[0m\n\u001b[1;32m    178\u001b[0m   w_init \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39minitializers\u001b[38;5;241m.\u001b[39mTruncatedNormal(stddev\u001b[38;5;241m=\u001b[39mstddev)\n\u001b[1;32m    179\u001b[0m w \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39mget_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, [input_size, output_size], dtype, init\u001b[38;5;241m=\u001b[39mw_init)\n\u001b[0;32m--> 181\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_bias:\n\u001b[1;32m    184\u001b[0m   b \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39mget_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size], dtype, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_init)\n",
      "\u001b[0;31mValueError\u001b[0m: RESOURCE_EXHAUSTED: Failed to allocate request for 4.88MiB (5111808B) on device ordinal 0"
     ]
    }
   ],
   "source": [
    "top_dir = os.path.join('data', make_datetime_str())\n",
    "df_hpos_main = df_hpos.iloc[2:32]\n",
    "for i in range(len(df_hpos_main)):\n",
    "    hpos = df_hpos_main.reset_index().iloc[i]\n",
    "    top_write_dir = os.path.join(top_dir, 'cvae_scan', f'hpo_{hpos[\"index\"]}')\n",
    "    hpos['use_grad_clipping'] = True\n",
    "    hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\n",
    "    # try:\n",
    "    #     try:\n",
    "    #         hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\n",
    "    #         hpos.loc['run_successful'] = True\n",
    "    #         hpos.loc['error_msg'] = ''\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "    #         if 'nan' in e.lower() and (hpos['use_grad_clipping'] == False):\n",
    "    #             try:\n",
    "    #                 hpos['use_grad_clipping'] = True\n",
    "    #                 hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\n",
    "    #                 hpos.loc['run_successful'] = True\n",
    "    #                 hpos.loc['error_msg'] = ''\n",
    "    #             except Exception as e:\n",
    "    #                 print(e)\n",
    "    #                 hpos.loc['run_successful'] = False\n",
    "    #                 hpos.loc['error_msg'] = str(e)\n",
    "    #         else:\n",
    "    #             hpos.loc['run_successful'] = False\n",
    "    #             hpos.loc['error_msg'] = str(e)\n",
    "    # except:\n",
    "    #     hpos.loc['run_successful'] = False\n",
    "    #     hpos.loc['error_msg'] = 'sys exit'\n",
    "        \n",
    "    df_hpos_main.loc[i] = pd.Series(hpos) if type(hpos) == dict else hpos.drop('index')\n",
    "    # df_hpos_main.loc[i] = pd.DataFrame.from_dict(hpos).drop('index')\n",
    "    if not os.path.exists(top_dir):\n",
    "        os.makedirs(top_dir)\n",
    "    df_hpos_main.to_csv(os.path.join(top_dir, 'df_hpos_main.csv'))\n",
    "    write_json(df_hpos_main.to_dict(), os.path.join(top_dir, 'df_hpos_main.json'), overwrite=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
