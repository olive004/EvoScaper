{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VAE models systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "from evoscaper.scripts.cvae_scan import main as cvae_scan\n",
    "from evoscaper.utils.preprocess import make_datetime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of all VAE model training settings\n",
    "\n",
    "Parameters for:\n",
    "- Biological dataset generation\n",
    "- Training data\n",
    "    - Input\n",
    "    - Output \n",
    "- Model architecture\n",
    "- Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "hpos_architecture = {\n",
    "    'seed_arch': 1,\n",
    "    'hidden_size': 32,\n",
    "    'enc_layers': [64, 64, 64],\n",
    "    'dec_layers': [64, 64, 64],\n",
    "    'model': 'CVAE',\n",
    "    'use_sigmoid_decoder': False,\n",
    "    'enc_init': 'HeNormal',\n",
    "    'dec_init': 'HeNormal',\n",
    "    'init_model_with_random': True,\n",
    "    'activation': 'leaky_relu',\n",
    "}\n",
    "\n",
    "\n",
    "hpos_training = {\n",
    "    'seed_train': 1,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 2000,\n",
    "    'patience': 1000,\n",
    "    'learning_rate': 1e-1,\n",
    "    'loss_func': 'mse',\n",
    "    'use_dropout': False,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_l2_reg': False,\n",
    "    'l2_reg_alpha': 0.01,\n",
    "    'use_kl_div': True,\n",
    "    'kl_weight': 0.00025,  # inspired by https://github.com/elttaes/VAE-MNIST-Haiku-Jax/blob/main/cVAE_mnist.ipynb\n",
    "}\n",
    "hpos_training['print_every'] = hpos_training['epochs'] // 100\n",
    "\n",
    "hpos_optimization = {\n",
    "    'seed_opt': 1,\n",
    "    'opt_method': 'adam',\n",
    "    'opt_min_lr': 1e-6,\n",
    "    'opt_min_delta': 1e-4,\n",
    "    'learning_rate_sched': 'cosine_decay',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 20,\n",
    "}\n",
    "\n",
    "hpos_dataset = {\n",
    "    'seed_dataset': 1,\n",
    "    'include_diffs': False,\n",
    "    'objective_col': 'Log sensitivity',\n",
    "    'output_species': ['RNA_2'],\n",
    "    'signal_species': ['RNA_0'],\n",
    "    'filenames_train_config': [f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config.json'], \n",
    "    'filenames_train_table': [f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'],\n",
    "    'filenames_verify_config': [f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json'], \n",
    "    'filenames_verify_table': [f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'],\n",
    "    'use_test_data': False,\n",
    "    # 'total_ds': None,   # TO BE RECORDED\n",
    "    'total_ds_max': 3e6,\n",
    "    'train_split': 0.8,\n",
    "    'x_type': 'energies',\n",
    "    # XY filtering:\n",
    "    'filt_x_nans': True,\n",
    "    'filt_y_nans': True,\n",
    "    'filt_sensitivity_nans': True,\n",
    "    'filt_precision_nans': True,\n",
    "    'filt_n_same_x_max': 1,\n",
    "    'filt_n_same_x_max_bins': 15,\n",
    "    # XY preprocessing:\n",
    "    'prep_x_standardise': False,\n",
    "    'prep_y_standardise': False,\n",
    "    'prep_x_min_max': False,\n",
    "    'prep_y_min_max': False,\n",
    "    'prep_x_robust_scaling': True,\n",
    "    'prep_y_robust_scaling': True,\n",
    "    'prep_x_logscale': False,\n",
    "    'prep_y_logscale': False,\n",
    "    'prep_x_categorical': False,\n",
    "    'prep_y_categorical': True,\n",
    "    'prep_x_categorical_onehot': False,\n",
    "    'prep_y_categorical_onehot': True,\n",
    "    'prep_x_categorical_n_bins': 10,\n",
    "    'prep_y_categorical_n_bins': 10,\n",
    "    'prep_x_categorical_method': 'quantile',\n",
    "    'prep_y_categorical_method': 'quantile',\n",
    "    'prep_x_negative': True,\n",
    "    'prep_y_negative': False\n",
    "}\n",
    "\n",
    "hpos_biological = {\n",
    "    'n_species': 3,\n",
    "    'sequence_length': 20,\n",
    "    'signal_function': 'step_function',\n",
    "    'signal_target': 2,\n",
    "    'starting_copynumbers_input': [200],\n",
    "    'starting_copynumbers_output': [200],\n",
    "    'starting_copynumbers_other': [200],\n",
    "    'association_binding_rate': 1000000,\n",
    "    'include_prod_deg': False,\n",
    "}\n",
    "\n",
    "hpos_eval = {\n",
    "    'eval_n_to_sample': 1e5\n",
    "}\n",
    "\n",
    "info_to_be_recorded = {\n",
    "    'filename_saved_model': 'TO_BE_RECORDED',\n",
    "    'total_ds': 'TO_BE_RECORDED',\n",
    "    'n_batches': 'TO_BE_RECORDED',\n",
    "    'R2_train': 'TO_BE_RECORDED',\n",
    "    'R2_test': 'TO_BE_RECORDED',\n",
    "    'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
    "    'n_layers_enc': 'TO_BE_RECORDED',\n",
    "    'n_layers_dec': 'TO_BE_RECORDED',\n",
    "    'run_successful': 'TO_BE_RECORDED',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>dec_layers</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>enc_init</th>\n",
       "      <th>dec_init</th>\n",
       "      <th>init_model_with_random</th>\n",
       "      <th>activation</th>\n",
       "      <th>...</th>\n",
       "      <th>prep_y_categorical</th>\n",
       "      <th>prep_x_categorical_onehot</th>\n",
       "      <th>prep_y_categorical_onehot</th>\n",
       "      <th>prep_x_categorical_n_bins</th>\n",
       "      <th>prep_y_categorical_n_bins</th>\n",
       "      <th>prep_x_categorical_method</th>\n",
       "      <th>prep_y_categorical_method</th>\n",
       "      <th>prep_x_negative</th>\n",
       "      <th>prep_y_negative</th>\n",
       "      <th>eval_n_to_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size    enc_layers    dec_layers model use_sigmoid_decoder  \\\n",
       "0         1          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "\n",
       "   enc_init  dec_init init_model_with_random  activation  ...  \\\n",
       "0  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "\n",
       "  prep_y_categorical prep_x_categorical_onehot prep_y_categorical_onehot  \\\n",
       "0               True                     False                      True   \n",
       "\n",
       "  prep_x_categorical_n_bins prep_y_categorical_n_bins  \\\n",
       "0                        10                        10   \n",
       "\n",
       "  prep_x_categorical_method prep_y_categorical_method prep_x_negative  \\\n",
       "0                  quantile                  quantile            True   \n",
       "\n",
       "  prep_y_negative eval_n_to_sample  \n",
       "0           False         100000.0  \n",
       "\n",
       "[1 rows x 68 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos = pd.concat([pd.DataFrame.from_dict(hpos, orient='index').T for hpos in [hpos_architecture, hpos_training, hpos_optimization, hpos_dataset, hpos_eval]], axis=1)\n",
    "assert df_hpos.columns.duplicated().sum() == 0, 'Change some column names, there are duplicates'\n",
    "basic_setting = df_hpos.copy()\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpos_to_vary_from_og = {\n",
    "    'seed_arch': [1, 2, 3, 4, 5],\n",
    "}\n",
    "hpos_to_vary_together = {\n",
    "    'total_ds_max': [1e4, 5e4, 1e5],\n",
    "    'hidden_size': [16, 32, 64, 128, 256, 512],\n",
    "}\n",
    "hpos_to_vary_together2 = {\n",
    "    'objective_col': ['adaptability', 'sensitivity_wrt_species-6'],\n",
    "    'x_type': ['energies', 'binding_rates_dissociation'],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'use_l2_reg': [True],\n",
    "    'l2_reg_alpha': [0, 1e-2, 1e-3, 1e-4],\n",
    "    'kl_weight': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "df_hpos.loc[df_hpos['objective_col'] == 'sensitivity_wrt_species-6', 'prep_y_logscale'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>dec_layers</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>enc_init</th>\n",
       "      <th>dec_init</th>\n",
       "      <th>init_model_with_random</th>\n",
       "      <th>activation</th>\n",
       "      <th>...</th>\n",
       "      <th>prep_y_categorical</th>\n",
       "      <th>prep_x_categorical_onehot</th>\n",
       "      <th>prep_y_categorical_onehot</th>\n",
       "      <th>prep_x_categorical_n_bins</th>\n",
       "      <th>prep_y_categorical_n_bins</th>\n",
       "      <th>prep_x_categorical_method</th>\n",
       "      <th>prep_y_categorical_method</th>\n",
       "      <th>prep_x_negative</th>\n",
       "      <th>prep_y_negative</th>\n",
       "      <th>eval_n_to_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>[64, 64, 64]</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>HeNormal</td>\n",
       "      <td>True</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>quantile</td>\n",
       "      <td>quantile</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size    enc_layers    dec_layers model use_sigmoid_decoder  \\\n",
       "0         1          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "1         1          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "2         2          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "3         3          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "4         4          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "5         5          32  [64, 64, 64]  [64, 64, 64]  CVAE               False   \n",
       "\n",
       "   enc_init  dec_init init_model_with_random  activation  ...  \\\n",
       "0  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "1  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "2  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "3  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "4  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "5  HeNormal  HeNormal                   True  leaky_relu  ...   \n",
       "\n",
       "  prep_y_categorical prep_x_categorical_onehot prep_y_categorical_onehot  \\\n",
       "0               True                     False                      True   \n",
       "1               True                     False                      True   \n",
       "2               True                     False                      True   \n",
       "3               True                     False                      True   \n",
       "4               True                     False                      True   \n",
       "5               True                     False                      True   \n",
       "\n",
       "  prep_x_categorical_n_bins prep_y_categorical_n_bins  \\\n",
       "0                        10                        10   \n",
       "1                        10                        10   \n",
       "2                        10                        10   \n",
       "3                        10                        10   \n",
       "4                        10                        10   \n",
       "5                        10                        10   \n",
       "\n",
       "  prep_x_categorical_method prep_y_categorical_method prep_x_negative  \\\n",
       "0                  quantile                  quantile            True   \n",
       "1                  quantile                  quantile            True   \n",
       "2                  quantile                  quantile            True   \n",
       "3                  quantile                  quantile            True   \n",
       "4                  quantile                  quantile            True   \n",
       "5                  quantile                  quantile            True   \n",
       "\n",
       "  prep_y_negative eval_n_to_sample  \n",
       "0           False         100000.0  \n",
       "1           False         100000.0  \n",
       "2           False         100000.0  \n",
       "3           False         100000.0  \n",
       "4           False         100000.0  \n",
       "5           False         100000.0  \n",
       "\n",
       "[6 rows x 68 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for h, v in hpos_to_vary_from_og.items():\n",
    "    df_hpos = pd.concat([df_hpos] + [basic_setting.assign(**{h: vv}) for vv in v], ignore_index=True)\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good if these are equal:  24 24\n",
      "All good if these are equal:  264 246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting):\n",
    "    keys_vary_together = sorted(hpos_to_vary_together.keys())\n",
    "    for v in itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]):\n",
    "        curr = basic_setting.assign(**{h: vv for h, vv in zip(keys_vary_together, v)})\n",
    "        df_hpos = pd.concat([df_hpos, curr], ignore_index=True)\n",
    "    print('All good if these are equal: ', len(df_hpos), len(list(itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]))) + np.sum([len(v) for v in hpos_to_vary_from_og.values()]) + 1)\n",
    "    return df_hpos\n",
    "\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting)\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together2, basic_setting)\n",
    "\n",
    "len(df_hpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use table to create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fn = '../data/raw/summarise_simulation/2024_11_21_144918/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'\n",
    "# data = pd.read_csv(fn).iloc[:100]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hpos = df_hpos.reset_index().iloc[0]\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: Total ds is 3 and the test data is not being used\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n",
    "\n",
    "top_dir = os.path.join('data', make_datetime_str())\n",
    "for i in range(len(df_hpos)):\n",
    "    hpos = df_hpos.reset_index().iloc[i]\n",
    "    try:\n",
    "        hpos = cvae_scan(hpos, top_dir=top_dir)\n",
    "        hpos['run_successful'] = True\n",
    "    except:\n",
    "        hpos['run_successful'] = False\n",
    "    df_hpos.loc[i] = pd.Series(hpos) if type(hpos) == dict else hpos\n",
    "    df_hpos.to_csv(os.path.join(top_dir, 'df_hpos.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn = partial(VAE_fn, enc_layers=enc_layers, dec_layers=dec_layers, decoder_head=x.shape[-1], \n",
    "#                    HIDDEN_SIZE=HIDDEN_SIZE, decoder_activation_final=jax.nn.sigmoid if USE_SIGMOID_DECODER else jax.nn.leaky_relu, \n",
    "#                    enc_init=ENC_INIT, dec_init=DEC_INIT, activation=get_activation_fn(ACTIVATION))\n",
    "# model_t = hk.multi_transform(model_fn)\n",
    "# dummy_x = jax.random.normal(PRNG, x.shape)\n",
    "# dummy_cond = jax.random.normal(PRNG, cond.shape)\n",
    "# params = model_t.init(PRNG, dummy_x, dummy_cond, deterministic=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
