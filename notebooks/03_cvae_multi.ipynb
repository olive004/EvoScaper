{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VAE models systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xla_bridge.py:backends():900: Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA INFO\n",
      "xla_bridge.py:backends():900: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory INFO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[cuda(id=0), cuda(id=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "from evoscaper.scripts.cvae_scan import cvae_scan_single\n",
    "from evoscaper.utils.preprocess import make_datetime_str\n",
    "from synbio_morpher.utils.data.data_format_tools.common import write_json\n",
    "from bioreaction.misc.misc import flatten_listlike\n",
    "\n",
    "import jax\n",
    "\n",
    "USE_ONLY_ONE_GPU = False\n",
    "\n",
    "if USE_ONLY_ONE_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 0 or 1\n",
    "\n",
    "# devices = jax.devices()\n",
    "# if devices:\n",
    "#     devices = [devices[0]]\n",
    "#     os.environ['CUDA_VISIBLE_DEVICES'] = str(devices[0].id)\n",
    "\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "jax.devices()\n",
    "\n",
    "# jupyter nbconvert --to notebook --execute 03_cvae_multi.ipynb --output=03_cvae_multi_2.ipynb --ExecutePreprocessor.timeout=-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of all VAE model training settings\n",
    "\n",
    "Parameters for:\n",
    "- Biological dataset generation\n",
    "- Training data\n",
    "    - Input\n",
    "    - Output \n",
    "- Model architecture\n",
    "- Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "hpos_architecture = {\n",
    "    'seed_arch': 1,\n",
    "    'hidden_size': 16,\n",
    "    'enc_ls': 32,\n",
    "    'dec_ls': 32,\n",
    "    'num_enc_layers': 2,\n",
    "    'num_dec_layers': 2,\n",
    "    'factor_expanding_ls': 1,\n",
    "    'factor_contracting_ls': 1,\n",
    "    'model': 'CVAE',\n",
    "    'use_sigmoid_decoder': False,\n",
    "    'enc_init': 'HeNormal',\n",
    "    'dec_init': 'HeNormal',\n",
    "    'init_model_with_random': True,\n",
    "    'activation': 'leaky_relu',\n",
    "}\n",
    "\n",
    "hpos_training = {\n",
    "    'seed_train': 1,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 100,\n",
    "    'patience': 500,\n",
    "    'threshold_early_val_acc': 0.95,\n",
    "    'learning_rate': 1e-2,\n",
    "    'loss_func': 'mse',\n",
    "    'accuracy_func': 'accuracy_regression',\n",
    "    'use_dropout': False,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_l2_reg': False,\n",
    "    'l2_reg_alpha': 5e-2,\n",
    "    'use_kl_div': True,\n",
    "    # inspired by https://github.com/elttaes/VAE-MNIST-Haiku-Jax/blob/main/cVAE_mnist.ipynb\n",
    "    'kl_weight': 2.5e-4,\n",
    "    'use_grad_clipping': False,\n",
    "    'use_contrastive_loss': False,\n",
    "    'temperature': 1.5,\n",
    "    'contrastive_func': 'info_nce',\n",
    "    'threshold_similarity': 0.9,\n",
    "    'power_factor_distance': 3\n",
    "}\n",
    "hpos_training['print_every'] = hpos_training['epochs'] // 50\n",
    "\n",
    "hpos_optimization = {\n",
    "    'seed_opt': 1,\n",
    "    'opt_method': 'adam',\n",
    "    'opt_min_lr': 1e-6,\n",
    "    'opt_min_delta': 1e-4,\n",
    "    'learning_rate_sched': 'cosine_decay',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 20,\n",
    "}\n",
    "\n",
    "hpos_dataset = {\n",
    "    'seed_dataset': 1,\n",
    "    'include_diffs': False,\n",
    "    # 'objective_col': ('Log sensitivity', 'Log precision'),\n",
    "    # 'objective_col': 'adaptation',\n",
    "    'objective_col': ('Log sensitivity',),\n",
    "    'output_species': ('RNA_2',),\n",
    "    'signal_species': ('RNA_0',),\n",
    "    'filenames_train_config': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config_update.json',\n",
    "    'filenames_train_table': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv',\n",
    "    'filenames_verify_config': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json',\n",
    "    'filenames_verify_table': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv',\n",
    "    'use_test_data': False,\n",
    "    # 'total_ds': None,   # TO BE RECORDED\n",
    "    'total_ds_max': 5e6,\n",
    "    'train_split': 0.8,\n",
    "    'x_type': 'energies',\n",
    "    # XY filtering:\n",
    "    'filt_x_nans': True,\n",
    "    'filt_y_nans': True,\n",
    "    'filt_sensitivity_nans': True,\n",
    "    'filt_precision_nans': True,\n",
    "    'filt_n_same_x_max': 1,\n",
    "    'filt_n_same_x_max_bins': None,\n",
    "    'filt_response_time_high': True,\n",
    "    'filt_response_time_perc_max': 0.8,\n",
    "    # XY preprocessing:\n",
    "    'prep_x_standardise': False,\n",
    "    'prep_y_standardise': False,\n",
    "    'prep_x_min_max': True,\n",
    "    'prep_y_min_max': True,\n",
    "    'prep_x_robust_scaling': True,\n",
    "    'prep_y_robust_scaling': True,\n",
    "    'prep_x_logscale': False,\n",
    "    'prep_y_logscale': False,\n",
    "    'prep_x_categorical': False,\n",
    "    'prep_y_categorical': False,\n",
    "    'prep_x_categorical_onehot': False,\n",
    "    'prep_y_categorical_onehot': False,\n",
    "    'prep_x_categorical_n_bins': 10,\n",
    "    'prep_y_categorical_n_bins': 10,\n",
    "    'prep_x_categorical_method': 'quantile',\n",
    "    'prep_y_categorical_method': 'quantile',\n",
    "    'prep_x_negative': True,\n",
    "    'prep_y_negative': False\n",
    "}\n",
    "\n",
    "hpos_biological = {\n",
    "    'n_species': 3,\n",
    "    'sequence_length': 20,\n",
    "    'signal_function': 'step_function',\n",
    "    'signal_target': 2,\n",
    "    'starting_copynumbers_input': 200,\n",
    "    'starting_copynumbers_output': 200,\n",
    "    'starting_copynumbers_other': 200,\n",
    "    'association_binding_rate': 1000000,\n",
    "    'include_prod_deg': False,\n",
    "}\n",
    "\n",
    "hpos_eval = {\n",
    "    'eval_n_to_sample': 1e3,\n",
    "    'eval_cond_min': -0.2,\n",
    "    'eval_cond_max': 1.2,\n",
    "}\n",
    "\n",
    "info_to_be_recorded = {\n",
    "    'filename_saved_model': 'TO_BE_RECORDED',\n",
    "    'total_ds': 'TO_BE_RECORDED',\n",
    "    'n_batches': 'TO_BE_RECORDED',\n",
    "    'R2_train': 'TO_BE_RECORDED',\n",
    "    'R2_test': 'TO_BE_RECORDED',\n",
    "    'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
    "    'n_layers_enc': 'TO_BE_RECORDED',\n",
    "    'n_layers_dec': 'TO_BE_RECORDED',\n",
    "    'run_successful': 'TO_BE_RECORDED',\n",
    "    'info_early_stop': 'TO_BE_RECORDED',\n",
    "    'error_msg': 'TO_BE_RECORDED',\n",
    "}\n",
    "\n",
    "hpos_all = {}\n",
    "for d in [hpos_architecture, hpos_training, hpos_optimization, hpos_dataset, hpos_eval, info_to_be_recorded]:\n",
    "    hpos_all.update(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_ls</th>\n",
       "      <th>dec_ls</th>\n",
       "      <th>num_enc_layers</th>\n",
       "      <th>num_dec_layers</th>\n",
       "      <th>factor_expanding_ls</th>\n",
       "      <th>factor_contracting_ls</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>...</th>\n",
       "      <th>total_ds</th>\n",
       "      <th>n_batches</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>mutual_information_conditionality</th>\n",
       "      <th>n_layers_enc</th>\n",
       "      <th>n_layers_dec</th>\n",
       "      <th>run_successful</th>\n",
       "      <th>info_early_stop</th>\n",
       "      <th>error_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size enc_ls dec_ls num_enc_layers num_dec_layers  \\\n",
       "0         1          16     32     32              2              2   \n",
       "\n",
       "  factor_expanding_ls factor_contracting_ls model use_sigmoid_decoder  ...  \\\n",
       "0                   1                     1  CVAE               False  ...   \n",
       "\n",
       "         total_ds       n_batches        R2_train         R2_test  \\\n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "  mutual_information_conditionality    n_layers_enc    n_layers_dec  \\\n",
       "0                    TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "   run_successful info_early_stop       error_msg  \n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  \n",
       "\n",
       "[1 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos = pd.DataFrame.from_dict(hpos_all, orient='index').T\n",
    "assert df_hpos.columns.duplicated().sum() == 0, 'Change some column names, there are duplicates'\n",
    "basic_setting = df_hpos.copy()\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ../data/raw/summarise_simulation/2024_12_05_21...\n",
       "Name: filenames_train_config, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k, v in hpos_all.items():\n",
    "#     if type(v) == tuple:\n",
    "#         print(k, v)\n",
    "#         df_hpos[k] = df_hpos[k].apply(lambda x: tuple(x))\n",
    "df_hpos['filenames_train_config']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpos_to_vary_from_og = [{\n",
    "    'hidden_size': np.arange(2, 32, 2),\n",
    "    'learning_rate': [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "}]\n",
    "hpos_to_vary_together = [{\n",
    "    'objective_col': [('adaptation',), ('Log sensitivity',), ('Log sensitivity', 'Log precision')],\n",
    "    'prep_y_categorical': [False, True],\n",
    "    'use_kl_div': [True],\n",
    "    'kl_weight': [5e-5, 1e-4, 2.5e-4, 4e-4, 5e-4],\n",
    "    'threshold_early_val_acc': [0.995, 0.98, 0.96, 0.9],\n",
    "},\n",
    "    {\n",
    "    'use_contrastive_loss': [True],\n",
    "    'temperature': [0.1, 0.5, 1, 1.5, 2, 4, 8],\n",
    "    'threshold_similarity': [0.95, 0.9, 0.7, 0.5, 0.3, 0.1],\n",
    "    'power_factor_distance': [3, 4],\n",
    "    'threshold_early_val_acc': [0.995, 0.9]\n",
    "}\n",
    "]\n",
    "\n",
    "df_hpos.loc[df_hpos['objective_col'] ==\n",
    "            'sensitivity_wrt_species-6', 'prep_y_logscale'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_equal(df):\n",
    "    pairs = {\n",
    "        'enc_ls': 'dec_ls',\n",
    "        'num_enc_layers': 'num_dec_layers',\n",
    "        'factor_expanding_ls': 'factor_contracting_ls',\n",
    "    }\n",
    "    for k1, k2 in pairs.items():\n",
    "        if k1 in df.columns and k2 in df.columns:\n",
    "            df[k2] = df[k1]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting):\n",
    "    keys_vary_together = sorted(hpos_to_vary_together.keys())\n",
    "    for i, v in enumerate(itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together])):\n",
    "        curr = basic_setting.assign(\n",
    "            **{h: [vv] if type(vv) == tuple else vv for h, vv in zip(keys_vary_together, v)})\n",
    "        df_hpos = pd.concat([df_hpos, curr], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def add_single_hpos(df_hpos, hpos_to_vary_from_og, basic_setting):\n",
    "    for h, v in hpos_to_vary_from_og.items():\n",
    "        try:\n",
    "            df_hpos = pd.concat(\n",
    "                [df_hpos] + [basic_setting.assign(**{h: vv}) for vv in v], ignore_index=True)\n",
    "        except ValueError:\n",
    "            for vv in v:\n",
    "                b = basic_setting.copy()\n",
    "                b.loc[0, h] = vv\n",
    "                df_hpos = pd.concat([df_hpos, b], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def postproc(df_hpos):\n",
    "    df_hpos = keep_equal(df_hpos)\n",
    "    df_hpos.loc[df_hpos['x_type'] ==\n",
    "                'binding_rates_dissociation', 'prep_x_negative'] = False\n",
    "    df_hpos = df_hpos.drop_duplicates().reset_index(drop=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "for h in hpos_to_vary_from_og:\n",
    "    df_hpos = add_single_hpos(df_hpos, h, basic_setting)\n",
    "for h in hpos_to_vary_together:\n",
    "    df_hpos = add_combinatorial_keys(df_hpos, h, basic_setting)\n",
    "\n",
    "df_hpos = postproc(df_hpos)\n",
    "\n",
    "# Reorder columns\n",
    "cols_priority = list(set(flatten_listlike([list(h.keys(\n",
    ")) for h in hpos_to_vary_from_og] + [list(h.keys()) for h in hpos_to_vary_together])))\n",
    "df_hpos = df_hpos[cols_priority +\n",
    "                  [c for c in df_hpos.columns if c not in cols_priority]]\n",
    "\n",
    "df_hpos.reset_index(drop=True)\n",
    "len(df_hpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use table to create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = '../data/raw/summarise_simulation/2024_11_21_144918/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'\n",
    "# data = pd.read_csv(fn).iloc[:100]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prep_y_categorical                True\n",
       "use_contrastive_loss             False\n",
       "threshold_similarity               0.9\n",
       "kl_weight                       0.0004\n",
       "learning_rate                     0.01\n",
       "                             ...      \n",
       "n_layers_enc            TO_BE_RECORDED\n",
       "n_layers_dec            TO_BE_RECORDED\n",
       "run_successful          TO_BE_RECORDED\n",
       "info_early_stop         TO_BE_RECORDED\n",
       "error_msg               TO_BE_RECORDED\n",
       "Name: 111, Length: 95, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos_main = df_hpos.iloc[111:]\n",
    "i = 0\n",
    "df_hpos_main.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.py:train():187: Epoch 0 / 100 -\t\t Train loss: 0.13409481942653656\tVal loss: 0.08627603948116302\tVal accuracy: 0.33696308732032776 INFO\n",
      "train.py:train():197: Early stopping triggered after 4 epochs:\n",
      "Train loss: 0.006510940380394459\n",
      "Val loss: 0.005444837734103203\n",
      "Val accuracy: 0.9848565459251404\n",
      "Epochs no improvement: 0 WARNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete: 0:00:04.385205\n",
      "Warning: not using the test data for evaluation, but the training data instead of ../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv\n",
      "The R2 score is  0.9675635695457458\n",
      "The R2 score with weighted variance is  0.9675636291503906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.py:train():187: Epoch 0 / 100 -\t\t Train loss: 0.13641704618930817\tVal loss: 0.08738697320222855\tVal accuracy: 0.33766764402389526 INFO\n",
      "train.py:train():197: Early stopping triggered after 8 epochs:\n",
      "Train loss: 0.003953842446208\n",
      "Val loss: 0.0037797028198838234\n",
      "Val accuracy: 0.995861828327179\n",
      "Epochs no improvement: 0 WARNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete: 0:00:09.456265\n",
      "Warning: not using the test data for evaluation, but the training data instead of ../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv\n",
      "The R2 score is  0.97612065076828\n",
      "The R2 score with weighted variance is  0.9761207103729248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/workdir/src/evoscaper/scripts/cvae_scan.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  config_bio = prep_cfg(config_bio, input_species)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['TO_BE_RECORDED', 'TO_BE_RECORDED'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     16\u001b[0m config_multisim \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal_species\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNA_0\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_species\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNA_2\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilenames_train_table\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     25\u001b[0m write_json(config_multisim, fn_config_multisim)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mcvae_scan_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_hpos_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_config_multisim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/cvae_scan.py:414\u001b[0m, in \u001b[0;36mcvae_scan_multi\u001b[0;34m(df_hpos, fn_config_multisim, top_write_dir, debug)\u001b[0m\n\u001b[1;32m    409\u001b[0m model_brn, qreactions, postprocs, ordered_species \u001b[38;5;241m=\u001b[39m setup_model_brn(\n\u001b[1;32m    410\u001b[0m     config_bio, input_species)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Simulate successful runs all in one go\u001b[39;00m\n\u001b[1;32m    413\u001b[0m all_fake_circuits, all_forward_rates, all_reverse_rates, all_sampled_cond \u001b[38;5;241m=\u001b[39m generate_all_fake_circuits(\n\u001b[0;32m--> 414\u001b[0m     df_hpos[df_hpos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_successful\u001b[39m\u001b[38;5;124m'\u001b[39m]], datasets, input_species, postprocs)\n\u001b[1;32m    415\u001b[0m analytics, ys, ts, y0m, y00s, ts0 \u001b[38;5;241m=\u001b[39m run_sim_multi(\n\u001b[1;32m    416\u001b[0m     all_fake_circuits, all_forward_rates, all_reverse_rates, df_hpos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal_species\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], config_bio, model_brn, qreactions, ordered_species)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['TO_BE_RECORDED', 'TO_BE_RECORDED'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# from bioreaction.misc.misc import load_json_as_dict\n",
    "from src.evoscaper.scripts.cvae_scan import cvae_scan_multi\n",
    "\n",
    "top_dir = os.path.join('data', '03_cvae_multi', make_datetime_str())\n",
    "os.makedirs(top_dir, exist_ok=True)\n",
    "\n",
    "# df_hpos2 = pd.DataFrame(load_json_as_dict(\n",
    "#     'data/03_cvae_multi/2025_01_15__10_59_22/df_hpos_main.json'))\n",
    "# df_hpos_main = df_hpos.iloc[df_hpos2[df_hpos2['run_successful'].isin(\n",
    "#     [False, 'TO_BE_RECORDED'])].index]\n",
    "df_hpos_main = df_hpos.iloc[61:63]\n",
    "\n",
    "# loop_scans(df_hpos_main, top_dir)\n",
    "\n",
    "fn_config_multisim = os.path.join(top_dir, 'config_multisim.json')\n",
    "config_multisim = {\n",
    "    'signal_species': ('RNA_0',),\n",
    "    'output_species': ('RNA_2',),\n",
    "    'eval_n_to_sample': 2e3,\n",
    "    'eval_cond_min': -0.2,\n",
    "    'eval_cond_max': 1.2,\n",
    "    'filenames_train_config': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config_update.json',\n",
    "    'filenames_train_table': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv',\n",
    "}\n",
    "write_json(config_multisim, fn_config_multisim)\n",
    "cvae_scan_multi(df_hpos_main, fn_config_multisim, top_dir, debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
