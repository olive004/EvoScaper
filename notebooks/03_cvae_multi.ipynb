{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VAE models systematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from evoscaper.scripts.cvae_scan import main as cvae_scan\n",
    "from evoscaper.utils.preprocess import make_datetime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of all VAE model training settings\n",
    "\n",
    "Parameters for:\n",
    "- Biological dataset generation\n",
    "- Training data\n",
    "    - Input\n",
    "    - Output \n",
    "- Model architecture\n",
    "- Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "hpos_architecture = {\n",
    "    'seed_arch': 1,\n",
    "    'hidden_size': 16,\n",
    "    'enc_ls': 32,\n",
    "    'dec_ls': 32,\n",
    "    'num_enc_layers': 2,\n",
    "    'num_dec_layers': 2,\n",
    "    'factor_expanding_ls': 1,\n",
    "    'factor_contracting_ls': 1,\n",
    "    'model': 'CVAE',\n",
    "    'use_sigmoid_decoder': False,\n",
    "    'enc_init': 'HeNormal',\n",
    "    'dec_init': 'HeNormal',\n",
    "    'init_model_with_random': True,\n",
    "    'activation': 'leaky_relu',\n",
    "}\n",
    "\n",
    "hpos_training = {\n",
    "    'seed_train': 1,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 2000,\n",
    "    'patience': 500,\n",
    "    'learning_rate': 1e-2,\n",
    "    'loss_func': 'mse',\n",
    "    'accuracy_func': 'accuracy_regression',\n",
    "    'use_dropout': False,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_l2_reg': False,\n",
    "    'l2_reg_alpha': 1e-2,\n",
    "    'use_kl_div': True,\n",
    "    # inspired by https://github.com/elttaes/VAE-MNIST-Haiku-Jax/blob/main/cVAE_mnist.ipynb\n",
    "    'kl_weight': 2.5e-4,\n",
    "}\n",
    "hpos_training['print_every'] = hpos_training['epochs'] // 50\n",
    "\n",
    "hpos_optimization = {\n",
    "    'seed_opt': 1,\n",
    "    'opt_method': 'adam',\n",
    "    'opt_min_lr': 1e-6,\n",
    "    'opt_min_delta': 1e-4,\n",
    "    'learning_rate_sched': 'cosine_decay',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 20,\n",
    "}\n",
    "\n",
    "hpos_dataset = {\n",
    "    'seed_dataset': 1,\n",
    "    'include_diffs': False,\n",
    "    'objective_col': 'Log sensitivity',\n",
    "    'output_species': ('RNA_2',),\n",
    "    'signal_species': ('RNA_0',),\n",
    "    'filenames_train_config': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/ensemble_config.json',\n",
    "    'filenames_train_table': f'{data_dir}/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv',\n",
    "    'filenames_verify_config': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/ensemble_config.json',\n",
    "    'filenames_verify_table': f'{data_dir}/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv',\n",
    "    'use_test_data': False,\n",
    "    # 'total_ds': None,   # TO BE RECORDED\n",
    "    'total_ds_max': 5e6,\n",
    "    'train_split': 0.8,\n",
    "    'x_type': 'energies',\n",
    "    # XY filtering:\n",
    "    'filt_x_nans': True,\n",
    "    'filt_y_nans': True,\n",
    "    'filt_sensitivity_nans': True,\n",
    "    'filt_precision_nans': True,\n",
    "    'filt_n_same_x_max': 1,\n",
    "    'filt_n_same_x_max_bins': 50,\n",
    "    # XY preprocessing:\n",
    "    'prep_x_standardise': False,\n",
    "    'prep_y_standardise': False,\n",
    "    'prep_x_min_max': True,\n",
    "    'prep_y_min_max': True,\n",
    "    'prep_x_robust_scaling': True,\n",
    "    'prep_y_robust_scaling': True,\n",
    "    'prep_x_logscale': False,\n",
    "    'prep_y_logscale': False,\n",
    "    'prep_x_categorical': False,\n",
    "    'prep_y_categorical': True,\n",
    "    'prep_x_categorical_onehot': False,\n",
    "    'prep_y_categorical_onehot': True,\n",
    "    'prep_x_categorical_n_bins': 10,\n",
    "    'prep_y_categorical_n_bins': 10,\n",
    "    'prep_x_categorical_method': 'quantile',\n",
    "    'prep_y_categorical_method': 'quantile',\n",
    "    'prep_x_negative': True,\n",
    "    'prep_y_negative': False\n",
    "}\n",
    "\n",
    "hpos_biological = {\n",
    "    'n_species': 3,\n",
    "    'sequence_length': 20,\n",
    "    'signal_function': 'step_function',\n",
    "    'signal_target': 2,\n",
    "    'starting_copynumbers_input': 200,\n",
    "    'starting_copynumbers_output': 200,\n",
    "    'starting_copynumbers_other': 200,\n",
    "    'association_binding_rate': 1000000,\n",
    "    'include_prod_deg': False,\n",
    "}\n",
    "\n",
    "hpos_eval = {\n",
    "    'eval_n_to_sample': 1e2\n",
    "}\n",
    "\n",
    "info_to_be_recorded = {\n",
    "    'filename_saved_model': 'TO_BE_RECORDED',\n",
    "    'total_ds': 'TO_BE_RECORDED',\n",
    "    'n_batches': 'TO_BE_RECORDED',\n",
    "    'R2_train': 'TO_BE_RECORDED',\n",
    "    'R2_test': 'TO_BE_RECORDED',\n",
    "    'mutual_information_conditionality': 'TO_BE_RECORDED',\n",
    "    'n_layers_enc': 'TO_BE_RECORDED',\n",
    "    'n_layers_dec': 'TO_BE_RECORDED',\n",
    "    'run_successful': 'TO_BE_RECORDED',\n",
    "    'error_msg': 'TO_BE_RECORDED',\n",
    "}\n",
    "\n",
    "hpos_all = {}\n",
    "for d in [hpos_architecture, hpos_training, hpos_optimization, hpos_dataset, hpos_eval, info_to_be_recorded]:\n",
    "    hpos_all.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_arch</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>enc_ls</th>\n",
       "      <th>dec_ls</th>\n",
       "      <th>num_enc_layers</th>\n",
       "      <th>num_dec_layers</th>\n",
       "      <th>factor_expanding_ls</th>\n",
       "      <th>factor_contracting_ls</th>\n",
       "      <th>model</th>\n",
       "      <th>use_sigmoid_decoder</th>\n",
       "      <th>...</th>\n",
       "      <th>filename_saved_model</th>\n",
       "      <th>total_ds</th>\n",
       "      <th>n_batches</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>mutual_information_conditionality</th>\n",
       "      <th>n_layers_enc</th>\n",
       "      <th>n_layers_dec</th>\n",
       "      <th>run_successful</th>\n",
       "      <th>error_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CVAE</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "      <td>TO_BE_RECORDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed_arch hidden_size enc_ls dec_ls num_enc_layers num_dec_layers  \\\n",
       "0         1          16     32     32              2              2   \n",
       "\n",
       "  factor_expanding_ls factor_contracting_ls model use_sigmoid_decoder  ...  \\\n",
       "0                   1                     1  CVAE               False  ...   \n",
       "\n",
       "  filename_saved_model        total_ds       n_batches        R2_train  \\\n",
       "0       TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "          R2_test mutual_information_conditionality    n_layers_enc  \\\n",
       "0  TO_BE_RECORDED                    TO_BE_RECORDED  TO_BE_RECORDED   \n",
       "\n",
       "     n_layers_dec  run_successful       error_msg  \n",
       "0  TO_BE_RECORDED  TO_BE_RECORDED  TO_BE_RECORDED  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpos = pd.DataFrame.from_dict(hpos_all, orient='index').T\n",
    "assert df_hpos.columns.duplicated().sum() == 0, 'Change some column names, there are duplicates'\n",
    "basic_setting = df_hpos.copy()\n",
    "df_hpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ../data/raw/summarise_simulation/2024_12_05_21...\n",
       "Name: filenames_train_config, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k, v in hpos_all.items():\n",
    "#     if type(v) == tuple:\n",
    "#         print(k, v)\n",
    "#         df_hpos[k] = df_hpos[k].apply(lambda x: tuple(x))\n",
    "df_hpos['filenames_train_config']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpos_to_vary_from_og = {\n",
    "    'seed_arch': [1, 2, 3, 4, 5],\n",
    "    'num_enc_layers': [4, 5]\n",
    "}\n",
    "hpos_to_vary_together = {\n",
    "    'hidden_size': [1, 2, 4, 8, 16, 32, 64, 128],\n",
    "    'enc_ls': [4, 8, 16, 32, 64],\n",
    "    'num_enc_layers': [1, 2, 3],\n",
    "    'factor_expanding_ls': [1, 2, 3],\n",
    "}\n",
    "hpos_to_vary_together2 = {\n",
    "    'hidden_size': [16, 32, 64],\n",
    "    'objective_col': ['adaptability', 'sensitivity_wrt_species-6'],\n",
    "    'x_type': ['energies', 'binding_rates_dissociation'],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'use_l2_reg': [True],\n",
    "    'l2_reg_alpha': [0, 1e-2, 1e-3, 1e-4],\n",
    "    'kl_weight': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "df_hpos.loc[df_hpos['objective_col'] == 'sensitivity_wrt_species-6', 'prep_y_logscale'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_equal(df):\n",
    "    pairs = {\n",
    "        'enc_ls': 'dec_ls',\n",
    "        'num_enc_layers': 'num_dec_layers',\n",
    "        'factor_expanding_ls': 'factor_contracting_ls',\n",
    "    }\n",
    "    for k1, k2 in pairs.items():\n",
    "        if k1 in df.columns and k2 in df.columns:\n",
    "            df[k2] = df[k1]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting):\n",
    "    keys_vary_together = sorted(hpos_to_vary_together.keys())\n",
    "    for v in itertools.product(*[hpos_to_vary_together[h] for h in keys_vary_together]):\n",
    "        curr = basic_setting.assign(\n",
    "            **{h: vv for h, vv in zip(keys_vary_together, v)})\n",
    "        df_hpos = pd.concat([df_hpos, curr], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def add_single_hpos(df_hpos, hpos_to_vary_from_og, basic_setting):\n",
    "    for h, v in hpos_to_vary_from_og.items():\n",
    "        df_hpos = pd.concat(\n",
    "            [df_hpos] + [basic_setting.assign(**{h: vv}) for vv in v], ignore_index=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "def postproc(df_hpos):\n",
    "    df_hpos = keep_equal(df_hpos)\n",
    "    df_hpos.loc[df_hpos['x_type'] ==\n",
    "                'binding_rates_dissociation', 'prep_x_negative'] = False\n",
    "    df_hpos = df_hpos.drop_duplicates().reset_index(drop=True)\n",
    "    return df_hpos\n",
    "\n",
    "\n",
    "df_hpos = add_combinatorial_keys(df_hpos, hpos_to_vary_together, basic_setting)\n",
    "df_hpos = add_combinatorial_keys(\n",
    "    df_hpos, hpos_to_vary_together2, basic_setting)\n",
    "df_hpos = add_single_hpos(df_hpos, hpos_to_vary_from_og, basic_setting)\n",
    "df_hpos = postproc(df_hpos)\n",
    "\n",
    "# Reorder columns\n",
    "cols_priority = list(set(list(hpos_to_vary_from_og.keys(\n",
    ")) + list(hpos_to_vary_together.keys()) + list(hpos_to_vary_together2.keys())))\n",
    "df_hpos = df_hpos[cols_priority +\n",
    "                  [c for c in df_hpos.columns if c not in cols_priority]]\n",
    "\n",
    "df_hpos.reset_index(drop=True)\n",
    "len(df_hpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use table to create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = '../data/raw/summarise_simulation/2024_11_21_144918/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv'\n",
    "# # fn = '../data/raw/summarise_simulation/2024_12_05_210221/tabulated_mutation_info.csv'\n",
    "# data = pd.read_csv(fn).iloc[:100]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hpos = df_hpos.reset_index().iloc[0]\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "train.py:train():121: Epoch 0 / 10 -\t\t Train loss: 0.15568256378173828\tVal loss: 0.149612694978714\tVal accuracy: 0.30994176864624023 INFO\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n",
      "/workdir/src/evoscaper/utils/train.py:117: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if np.mod(epoch, save_every) == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete: 0:00:10.953263\n",
      "Warning: not using the test data for evaluation, but the training data instead of ../data/raw/summarise_simulation/2024_11_21_160955/tabulated_mutation_info.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/src/core-bioreaction-simulation/src/bioreaction/model/data_containers.py:230: FutureWarning: None encountered in jnp.array(); this is currently treated as NaN. In the future this will result in an error.\n",
      "  forward_rates = jnp.array([r.forward_rate for r in model.reactions])\n",
      "/workdir/src/core-bioreaction-simulation/src/bioreaction/model/data_containers.py:231: FutureWarning: None encountered in jnp.array(); this is currently treated as NaN. In the future this will result in an error.\n",
      "  reverse_rates = jnp.array([r.reverse_rate for r in model.reactions])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Simulation failed - some runs (98.0 %) go to nan. Try lowering dt.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m hpos \u001b[38;5;241m=\u001b[39m df_hpos\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m      7\u001b[0m top_write_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(top_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvae_scan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhpo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhpos[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m hpos \u001b[38;5;241m=\u001b[39m \u001b[43mcvae_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_write_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_write_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         hpos = cvae_scan(hpos, top_dir=top_write_dir)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     hpos.loc['run_successful'] = False\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     hpos.loc['error_msg'] = 'sys exit'\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df_hpos\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(hpos) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(hpos) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m hpos\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/cvae_scan.py:201\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(hpos, top_write_dir)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [kk \u001b[38;5;28;01mfor\u001b[39;00m kk \u001b[38;5;129;01min\u001b[39;00m val_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_configs_ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvis\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kk]:\n\u001b[1;32m    200\u001b[0m         config_bio\u001b[38;5;241m.\u001b[39mupdate(val_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_configs_ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m][k])\n\u001b[0;32m--> 201\u001b[0m     \u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m           \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m           \u001b[49m\u001b[43mconfig_bio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m           \u001b[49m\u001b[43mconfig_norm_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m           \u001b[49m\u001b[43mconfig_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m           \u001b[49m\u001b[43mconfig_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m           \u001b[49m\u001b[43mx_datanormaliser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_methods_preprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m           \u001b[49m\u001b[43my_datanormaliser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m           \u001b[49m\u001b[43moutput_species\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_species\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m           \u001b[49m\u001b[43msignal_species\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_species\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m           \u001b[49m\u001b[43minput_species\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m           \u001b[49m\u001b[43mn_to_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_n_to_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m           \u001b[49m\u001b[43mvisualise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m           \u001b[49m\u001b[43mtop_write_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_write_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hpos\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/verify.py:220\u001b[0m, in \u001b[0;36mverify\u001b[0;34m(params, rng, decoder, df, cond, config_bio, config_norm_y, config_dataset, config_model, x_datanormaliser, x_methods_preprocessing, y_datanormaliser, output_species, signal_species, input_species, n_to_sample, visualise, top_write_dir, return_relevant, data_writer)\u001b[0m\n\u001b[1;32m    214\u001b[0m forward_rates, reverse_rates \u001b[38;5;241m=\u001b[39m make_rates(\n\u001b[1;32m    215\u001b[0m     config_dataset\u001b[38;5;241m.\u001b[39mx_type, fake_circuits_reshaped, postproc)\n\u001b[1;32m    217\u001b[0m signal_onehot, signal_target, y00, t0, t1, dt0, dt1, save_steps, max_steps, forward_rates, reverse_rates \u001b[38;5;241m=\u001b[39m prep_sim(\n\u001b[1;32m    218\u001b[0m     signal_species, qreactions, fake_circuits_reshaped, config_bio, forward_rates, reverse_rates)\n\u001b[0;32m--> 220\u001b[0m analytics, ys, ts, y0m, y00s, ts0 \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[43m(\u001b[49m\u001b[43my00\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_rates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mqreactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msignal_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m analytics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensitivity_wrt_species-6\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    227\u001b[0m     analytics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensitivity_wrt_species-6\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    228\u001b[0m analytics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_wrt_species-6\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    229\u001b[0m     analytics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_wrt_species-6\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/workdir/src/evoscaper/scripts/verify.py:91\u001b[0m, in \u001b[0;36msim\u001b[0;34m(y00, forward_rates, reverse_rates, qreactions, signal_onehot, signal_target, t0, t1, dt0, dt1, save_steps, max_steps)\u001b[0m\n\u001b[1;32m     76\u001b[0m sim_func \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(jax\u001b[38;5;241m.\u001b[39mvmap(partial(bioreaction_sim_dfx_expanded,\n\u001b[1;32m     77\u001b[0m                             t0\u001b[38;5;241m=\u001b[39mt0, t1\u001b[38;5;241m=\u001b[39mt1, dt0\u001b[38;5;241m=\u001b[39mdt0,\n\u001b[1;32m     78\u001b[0m                             signal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, signal_onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m                                 t0\u001b[38;5;241m=\u001b[39mt0, t1\u001b[38;5;241m=\u001b[39mt1, dt0\u001b[38;5;241m=\u001b[39mdt0, dt1\u001b[38;5;241m=\u001b[39mdt1)\n\u001b[1;32m     88\u001b[0m                             )))\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Concentrations should be in the form [circuits, time, species] \"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m y00s, ts0 \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_steady_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my00\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreverse_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m y0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y00s[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\u001b[38;5;241m.\u001b[39mreshape(y00\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteady states found. Now calculating signal response\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/synbio_morpher/utils/modelling/solvers.py:116\u001b[0m, in \u001b[0;36msimulate_steady_states\u001b[0;34m(y0, total_time, sim_func, t0, t1, threshold, disable_logging, **sim_kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     ys \u001b[38;5;241m=\u001b[39m ys\n\u001b[1;32m    114\u001b[0m     ts \u001b[38;5;241m=\u001b[39m ts \u001b[38;5;241m+\u001b[39m ti\n\u001b[0;32m--> 116\u001b[0m \u001b[43mdid_sim_break\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ti \u001b[38;5;241m==\u001b[39m t0:\n\u001b[1;32m    119\u001b[0m     ys_full \u001b[38;5;241m=\u001b[39m ys\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/synbio_morpher/utils/modelling/solvers.py:71\u001b[0m, in \u001b[0;36mdid_sim_break\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdid_sim_break\u001b[39m(y):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39misnan(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimulation failed - some runs (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39misnan(y))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msize(y)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %) go to nan. Try lowering dt.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39minf) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimulation failed - some runs (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(y\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39mnp\u001b[38;5;241m.\u001b[39minf)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msize(y)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %) go to inf. Try lowering dt.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Simulation failed - some runs (98.0 %) go to nan. Try lowering dt."
     ]
    }
   ],
   "source": [
    "# REMINDER: Total ds is 3 and the test data is not being used\n",
    "# cvae_scan(hpos, top_dir=os.path.join('data', make_datetime_str()))\n",
    "\n",
    "top_dir = os.path.join('data', make_datetime_str())\n",
    "for i in range(len(df_hpos)):\n",
    "    hpos = df_hpos.reset_index().iloc[i]\n",
    "    top_write_dir = os.path.join(top_dir, 'cvae_scan', f'hpo_{hpos[\"index\"]}')\n",
    "    # hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\n",
    "    try:\n",
    "        try:\n",
    "            hpos = cvae_scan(hpos, top_write_dir=top_write_dir)\n",
    "            hpos.loc['run_successful'] = True\n",
    "            hpos.loc['error_msg'] = ''\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            hpos.loc['run_successful'] = False\n",
    "            hpos.loc['error_msg'] = str(e)\n",
    "    except:\n",
    "        hpos.loc['run_successful'] = False\n",
    "        hpos.loc['error_msg'] = 'sys exit'\n",
    "        \n",
    "    df_hpos.loc[i] = pd.Series(hpos) if type(hpos) == dict else hpos.drop('index')\n",
    "    # df_hpos.loc[i] = pd.DataFrame.from_dict(hpos).drop('index')\n",
    "    if not os.path.exists(top_dir):\n",
    "        os.makedirs(top_dir)\n",
    "    df_hpos.to_csv(os.path.join(top_dir, 'df_hpos.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
