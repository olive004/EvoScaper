{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqCt_GhvCnwY"
      },
      "source": [
        "# VQ-VAE training example\n",
        "\n",
        "Demonstration of how to train the model specified in https://arxiv.org/abs/1711.00937, using Haiku / JAX.\n",
        "\n",
        "On Mac and Linux, simply execute each cell in turn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O_8gPxwAq_3W"
      },
      "outputs": [],
      "source": [
        "# Uncomment the line below if running on colab.research.google.com\n",
        "# !pip install dm-haiku optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "95YuC82P35Of"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 12:58:59.920865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX version 0.4.13\n",
            "Haiku version 0.0.10\n",
            "TF version 2.13.0\n"
          ]
        }
      ],
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "print(\"JAX version {}\".format(jax.__version__))\n",
        "print(\"Haiku version {}\".format(hk.__version__))\n",
        "print(\"TF version {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DT8fKmqQC35h"
      },
      "source": [
        "# Download Cifar10 data\n",
        "This requires a connection to the internet and will download ~160MB.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pobKFxUGBD6-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': 'uint8[60000, 32, 32, 3]'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cifar10 = tfds.as_numpy(tfds.load(\"cifar10\", split=\"train+test\", batch_size=-1))\n",
        "del cifar10[\"id\"], cifar10[\"label\"]\n",
        "jax.tree_util.tree_map(lambda x: f'{x.dtype.name}{list(x.shape)}', cifar10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lUgvEhfJyQLZ"
      },
      "source": [
        "# Load the data into Numpy\n",
        "We compute the variance of the whole training set to normalise the Mean Squared Error below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9C-V2D6RSQwl"
      },
      "outputs": [],
      "source": [
        "train_data_dict = jax.tree_util.tree_map(lambda x: x[:40000], cifar10)\n",
        "valid_data_dict = jax.tree_util.tree_map(lambda x: x[40000:50000], cifar10)\n",
        "test_data_dict = jax.tree_util.tree_map(lambda x: x[50000:], cifar10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cIRl2ZtxoKNz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data variance: 0.06327039811675479\n"
          ]
        }
      ],
      "source": [
        "def cast_and_normalise_images(data_dict):\n",
        "  \"\"\"Convert images to floating point with the range [-0.5, 0.5]\"\"\"\n",
        "  data_dict['image'] = (tf.cast(data_dict['image'], tf.float32) / 255.0) - 0.5\n",
        "  return data_dict\n",
        "\n",
        "train_data_variance = np.var(train_data_dict['image'] / 255.0)\n",
        "print('train data variance: %s' % train_data_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jse__pEBAkvI"
      },
      "source": [
        "# Encoder & Decoder Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1gwD36Vr6KqA"
      },
      "outputs": [],
      "source": [
        "class ResidualStack(hk.Module):\n",
        "  def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "               name=None):\n",
        "    super(ResidualStack, self).__init__(name=name)\n",
        "    self._num_hiddens = num_hiddens\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._num_residual_hiddens = num_residual_hiddens\n",
        "\n",
        "    self._layers = []\n",
        "    for i in range(num_residual_layers):\n",
        "      conv3 = hk.Conv2D(\n",
        "          output_channels=num_residual_hiddens,\n",
        "          kernel_shape=(3, 3),\n",
        "          stride=(1, 1),\n",
        "          name=\"res3x3_%d\" % i)\n",
        "      conv1 = hk.Conv2D(\n",
        "          output_channels=num_hiddens,\n",
        "          kernel_shape=(1, 1),\n",
        "          stride=(1, 1),\n",
        "          name=\"res1x1_%d\" % i)\n",
        "      self._layers.append((conv3, conv1))\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    h = inputs\n",
        "    for conv3, conv1 in self._layers:\n",
        "      conv3_out = conv3(jax.nn.relu(h))\n",
        "      conv1_out = conv1(jax.nn.relu(conv3_out))\n",
        "      h += conv1_out\n",
        "    return jax.nn.relu(h)  # Resnet V1 style\n",
        "\n",
        "\n",
        "class Encoder(hk.Module):\n",
        "  def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "               name=None):\n",
        "    super(Encoder, self).__init__(name=name)\n",
        "    self._num_hiddens = num_hiddens\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._num_residual_hiddens = num_residual_hiddens\n",
        "\n",
        "    self._enc_1 = hk.Conv2D(\n",
        "        output_channels=self._num_hiddens // 2,\n",
        "        kernel_shape=(4, 4),\n",
        "        stride=(2, 2),\n",
        "        name=\"enc_1\")\n",
        "    self._enc_2 = hk.Conv2D(\n",
        "        output_channels=self._num_hiddens,\n",
        "        kernel_shape=(4, 4),\n",
        "        stride=(2, 2),\n",
        "        name=\"enc_2\")\n",
        "    self._enc_3 = hk.Conv2D(\n",
        "        output_channels=self._num_hiddens,\n",
        "        kernel_shape=(3, 3),\n",
        "        stride=(1, 1),\n",
        "        name=\"enc_3\")\n",
        "    self._residual_stack = ResidualStack(\n",
        "        self._num_hiddens,\n",
        "        self._num_residual_layers,\n",
        "        self._num_residual_hiddens)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    h = jax.nn.relu(self._enc_1(x))\n",
        "    h = jax.nn.relu(self._enc_2(h))\n",
        "    h = jax.nn.relu(self._enc_3(h))\n",
        "    return self._residual_stack(h)\n",
        "\n",
        "\n",
        "class Decoder(hk.Module):\n",
        "  def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "               name=None):\n",
        "    super(Decoder, self).__init__(name=name)\n",
        "    self._num_hiddens = num_hiddens\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._num_residual_hiddens = num_residual_hiddens\n",
        "\n",
        "    self._dec_1 = hk.Conv2D(\n",
        "        output_channels=self._num_hiddens,\n",
        "        kernel_shape=(3, 3),\n",
        "        stride=(1, 1),\n",
        "        name=\"dec_1\")\n",
        "    self._residual_stack = ResidualStack(\n",
        "        self._num_hiddens,\n",
        "        self._num_residual_layers,\n",
        "        self._num_residual_hiddens)\n",
        "    self._dec_2 = hk.Conv2DTranspose(\n",
        "        output_channels=self._num_hiddens // 2,\n",
        "        # output_shape=None,\n",
        "        kernel_shape=(4, 4),\n",
        "        stride=(2, 2),\n",
        "        name=\"dec_2\")\n",
        "    self._dec_3 = hk.Conv2DTranspose(\n",
        "        output_channels=3,\n",
        "        # output_shape=None,\n",
        "        kernel_shape=(4, 4),\n",
        "        stride=(2, 2),\n",
        "        name=\"dec_3\")\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    h = self._dec_1(x)\n",
        "    h = self._residual_stack(h)\n",
        "    h = jax.nn.relu(self._dec_2(h))\n",
        "    x_recon = self._dec_3(h)\n",
        "    return x_recon\n",
        "    \n",
        "\n",
        "class VQVAEModel(hk.Module):\n",
        "  def __init__(self, encoder, decoder, vqvae, pre_vq_conv1, \n",
        "               data_variance, name=None):\n",
        "    super(VQVAEModel, self).__init__(name=name)\n",
        "    self._encoder = encoder\n",
        "    self._decoder = decoder\n",
        "    self._vqvae = vqvae\n",
        "    self._pre_vq_conv1 = pre_vq_conv1\n",
        "    self._data_variance = data_variance\n",
        "\n",
        "  def __call__(self, inputs, is_training):\n",
        "    z = self._pre_vq_conv1(self._encoder(inputs))\n",
        "    vq_output = self._vqvae(z, is_training=is_training)\n",
        "    x_recon = self._decoder(vq_output['quantize'])\n",
        "    recon_error = jnp.mean((x_recon - inputs) ** 2) / self._data_variance\n",
        "    loss = recon_error + vq_output['loss']\n",
        "    return {\n",
        "        'z': z,\n",
        "        'x_recon': x_recon,\n",
        "        'loss': loss,\n",
        "        'recon_error': recon_error,\n",
        "        'vq_output': vq_output,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FF7WaOn-s7En"
      },
      "source": [
        "# Build Model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "owGEoOkO4ttk"
      },
      "outputs": [],
      "source": [
        "# Set hyper-parameters.\n",
        "batch_size = 32\n",
        "image_size = 32\n",
        "\n",
        "# 100k steps should take < 30 minutes on a modern (>= 2017) GPU.\n",
        "num_training_updates = 100000\n",
        "\n",
        "num_hiddens = 128\n",
        "num_residual_hiddens = 32\n",
        "num_residual_layers = 2\n",
        "# These hyper-parameters define the size of the model (number of parameters and layers).\n",
        "# The hyper-parameters in the paper were (For ImageNet):\n",
        "# batch_size = 128\n",
        "# image_size = 128\n",
        "# num_hiddens = 128\n",
        "# num_residual_hiddens = 32\n",
        "# num_residual_layers = 2\n",
        "\n",
        "# This value is not that important, usually 64 works.\n",
        "# This will not change the capacity in the information-bottleneck.\n",
        "embedding_dim = 64\n",
        "\n",
        "# The higher this value, the higher the capacity in the information bottleneck.\n",
        "num_embeddings = 512\n",
        "\n",
        "# commitment_cost should be set appropriately. It's often useful to try a couple\n",
        "# of values. It mostly depends on the scale of the reconstruction cost\n",
        "# (log p(x|z)). So if the reconstruction cost is 100x higher, the\n",
        "# commitment_cost should also be multiplied with the same amount.\n",
        "commitment_cost = 0.25\n",
        "\n",
        "# Use EMA updates for the codebook (instead of the Adam optimizer).\n",
        "# This typically converges faster, and makes the model less dependent on choice\n",
        "# of the optimizer. In the VQ-VAE paper EMA updates were not used (but was\n",
        "# developed afterwards). See Appendix of the paper for more details.\n",
        "vq_use_ema = True\n",
        "\n",
        "# This is only used for EMA updates.\n",
        "decay = 0.99\n",
        "\n",
        "learning_rate = 3e-4\n",
        "\n",
        "\n",
        "# # Data Loading.\n",
        "train_dataset = tfds.as_numpy(\n",
        "    tf.data.Dataset.from_tensor_slices(train_data_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .shuffle(10000)\n",
        "    .repeat(-1)  # repeat indefinitely\n",
        "    .batch(batch_size, drop_remainder=True)\n",
        "    .prefetch(-1))\n",
        "valid_dataset = tfds.as_numpy(\n",
        "    tf.data.Dataset.from_tensor_slices(valid_data_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .repeat(1)  # 1 epoch\n",
        "    .batch(batch_size)\n",
        "    .prefetch(-1))\n",
        "\n",
        "# # Build modules.\n",
        "def forward(data, is_training):\n",
        "  encoder = Encoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
        "  decoder = Decoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
        "  pre_vq_conv1 = hk.Conv2D(\n",
        "      output_channels=embedding_dim,\n",
        "      kernel_shape=(1, 1),\n",
        "      stride=(1, 1),\n",
        "      name=\"to_vq\")\n",
        "\n",
        "  if vq_use_ema:\n",
        "    vq_vae = hk.nets.VectorQuantizerEMA(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_embeddings=num_embeddings,\n",
        "        commitment_cost=commitment_cost,\n",
        "        decay=decay)\n",
        "  else:\n",
        "    vq_vae = hk.nets.VectorQuantizer(\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_embeddings=num_embeddings,\n",
        "        commitment_cost=commitment_cost)\n",
        "    \n",
        "  model = VQVAEModel(encoder, decoder, vq_vae, pre_vq_conv1,\n",
        "                     data_variance=train_data_variance)\n",
        "\n",
        "  return model(data['image'], is_training)\n",
        "\n",
        "forward = hk.transform_with_state(forward)\n",
        "optimizer = optax.adam(learning_rate)\n",
        "\n",
        "@jax.jit\n",
        "def train_step(params, state, opt_state, data):\n",
        "  def adapt_forward(params, state, data):\n",
        "    # Pack model output and state together.\n",
        "    model_output, state = forward.apply(params, state, None, data, is_training=True)\n",
        "    loss = model_output['loss']\n",
        "    return loss, (model_output, state)\n",
        "\n",
        "  grads, (model_output, state) = (\n",
        "      jax.grad(adapt_forward, has_aux=True)(params, state, data))\n",
        "\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "\n",
        "  return params, state, opt_state, model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d7edmrBbJZy-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 12:59:49.865364: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:407] There was an error before creating cudnn handle (2): cudaErrorMemoryAllocation : out of memory\n"
          ]
        },
        {
          "ename": "XlaRuntimeError",
          "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/random.py:160\u001b[0m, in \u001b[0;36mPRNGKey\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(seed):\n\u001b[1;32m    158\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPRNGKey accepts a scalar seed, but was given an array of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(seed)\u001b[39m}\u001b[39;00m\u001b[39m != (). Use jax.vmap for batching\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m key \u001b[39m=\u001b[39m prng\u001b[39m.\u001b[39;49mseed_with_impl(impl, seed)\n\u001b[1;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m _return_prng_keys(\u001b[39mTrue\u001b[39;00m, key)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/prng.py:406\u001b[0m, in \u001b[0;36mseed_with_impl\u001b[0;34m(impl, seed)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseed_with_impl\u001b[39m(impl: PRNGImpl, seed: Union[\u001b[39mint\u001b[39m, Array]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PRNGKeyArrayImpl:\n\u001b[0;32m--> 406\u001b[0m   \u001b[39mreturn\u001b[39;00m random_seed(seed, impl\u001b[39m=\u001b[39;49mimpl)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/prng.py:690\u001b[0m, in \u001b[0;36mrandom_seed\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   seeds_arr \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(seeds)\n\u001b[0;32m--> 690\u001b[0m \u001b[39mreturn\u001b[39;00m random_seed_p\u001b[39m.\u001b[39;49mbind(seeds_arr, impl\u001b[39m=\u001b[39;49mimpl)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/core.py:380\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    378\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    379\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 380\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/core.py:383\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 383\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    384\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/core.py:815\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 815\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/prng.py:702\u001b[0m, in \u001b[0;36mrandom_seed_impl\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m@random_seed_p\u001b[39m\u001b[39m.\u001b[39mdef_impl\n\u001b[1;32m    701\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[0;32m--> 702\u001b[0m   base_arr \u001b[39m=\u001b[39m random_seed_impl_base(seeds, impl\u001b[39m=\u001b[39;49mimpl)\n\u001b[1;32m    703\u001b[0m   \u001b[39mreturn\u001b[39;00m PRNGKeyArrayImpl(impl, base_arr)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/prng.py:707\u001b[0m, in \u001b[0;36mrandom_seed_impl_base\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl_base\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[1;32m    706\u001b[0m   seed \u001b[39m=\u001b[39m iterated_vmap_unary(seeds\u001b[39m.\u001b[39mndim, impl\u001b[39m.\u001b[39mseed)\n\u001b[0;32m--> 707\u001b[0m   \u001b[39mreturn\u001b[39;00m seed(seeds)\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/prng.py:936\u001b[0m, in \u001b[0;36mthreefry_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthreefry_seed\u001b[39m(seed: typing\u001b[39m.\u001b[39mArray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mArray:\n\u001b[1;32m    925\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Create a single raw threefry PRNG key from an integer seed.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m    first padding out with zeros).\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m   \u001b[39mreturn\u001b[39;00m _threefry_seed(seed)\n",
            "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
            "File \u001b[0;32m~/Kode/env_evo/lib/python3.10/site-packages/jax/_src/dispatch.py:465\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    461\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    462\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
            "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses = []\n",
        "train_recon_errors = []\n",
        "train_perplexities = []\n",
        "train_vqvae_loss = []\n",
        "\n",
        "rng = jax.random.PRNGKey(42)\n",
        "train_dataset_iter = iter(train_dataset)\n",
        "params, state = forward.init(rng, next(train_dataset_iter), is_training=True)\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "for step in range(1, num_training_updates + 1):\n",
        "  data = next(train_dataset_iter)\n",
        "  params, state, opt_state, train_results = (\n",
        "      train_step(params, state, opt_state, data))\n",
        "\n",
        "  train_results = jax.device_get(train_results)\n",
        "  train_losses.append(train_results['loss'])\n",
        "  train_recon_errors.append(train_results['recon_error'])\n",
        "  train_perplexities.append(train_results['vq_output']['perplexity'])\n",
        "  train_vqvae_loss.append(train_results['vq_output']['loss'])\n",
        "\n",
        "  if step % 100 == 0:\n",
        "    print(f'[Step {step}/{num_training_updates}] ' + \n",
        "          ('train loss: %f ' % np.mean(train_losses[-100:])) +\n",
        "          ('recon_error: %.3f ' % np.mean(train_recon_errors[-100:])) +\n",
        "          ('perplexity: %.3f ' % np.mean(train_perplexities[-100:])) +\n",
        "          ('vqvae loss: %.3f' % np.mean(train_vqvae_loss[-100:])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m2hNyAnhs-1f"
      },
      "source": [
        "# Plot loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2vo-lDyRomKD"
      },
      "outputs": [],
      "source": [
        "f = plt.figure(figsize=(16,8))\n",
        "ax = f.add_subplot(1,2,1)\n",
        "ax.plot(train_recon_errors)\n",
        "ax.set_yscale('log')\n",
        "ax.set_title('NMSE.')\n",
        "\n",
        "ax = f.add_subplot(1,2,2)\n",
        "ax.plot(train_perplexities)\n",
        "ax.set_title('Average codebook usage (perplexity).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lyj1CCKptCZz"
      },
      "source": [
        "# View reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rM9zj7ZiPZBG"
      },
      "outputs": [],
      "source": [
        "# Reconstructions\n",
        "train_batch = next(iter(train_dataset))\n",
        "valid_batch = next(iter(valid_dataset))\n",
        "\n",
        "# Put data through the model with is_training=False, so that in the case of \n",
        "# using EMA the codebook is not updated.\n",
        "train_reconstructions = forward.apply(params, state, rng, train_batch, is_training=False)[0]['x_recon']\n",
        "valid_reconstructions = forward.apply(params, state, rng, valid_batch, is_training=False)[0]['x_recon']\n",
        "\n",
        "\n",
        "def convert_batch_to_image_grid(image_batch):\n",
        "  reshaped = (image_batch.reshape(4, 8, 32, 32, 3)\n",
        "              .transpose([0, 2, 1, 3, 4])\n",
        "              .reshape(4 * 32, 8 * 32, 3))\n",
        "  return reshaped + 0.5\n",
        "\n",
        "\n",
        "\n",
        "f = plt.figure(figsize=(16,8))\n",
        "ax = f.add_subplot(2,2,1)\n",
        "ax.imshow(convert_batch_to_image_grid(train_batch['image']),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('training data originals')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,2)\n",
        "ax.imshow(convert_batch_to_image_grid(train_reconstructions),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('training data reconstructions')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,3)\n",
        "ax.imshow(convert_batch_to_image_grid(valid_batch['image']),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('validation data originals')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,4)\n",
        "ax.imshow(convert_batch_to_image_grid(valid_reconstructions),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('validation data reconstructions')\n",
        "plt.axis('off')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "private"
      },
      "name": "JAX VQ-VAE training example",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
